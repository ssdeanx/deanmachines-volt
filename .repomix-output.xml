This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.
The content has been processed where empty lines have been removed.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: **/*, .cursorrules, .cursor/rules/*, .clinerules, CLAUDE.md
- Files matching these patterns are excluded: .*.*, **/*.pbxproj, **/node_modules/**, **/dist/**, **/build/**, **/compile/**, **/*.spec.*, **/*.pyc, **/.env, **/.env.*, **/*.env, **/*.env.*, **/*.lock, **/*.lockb, **/package-lock.*, **/pnpm-lock.*, **/*.tsbuildinfo, **/certdata.txt
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Empty lines have been removed from all files
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
.clinerules/codeGeneration.instructions.md
.clinerules/copilot-instructions.md
.clinerules/voltAgent.instructions.md
.github/copilot-instructions.md
.github/instructions/codeGeneration.instructions.md
.github/instructions/voltAgent.instructions.md
.gitignore
.windsurf/rules/codeGeneration.instructions.md
.windsurf/rules/project.md
.windsurf/rules/quality.md
.windsurf/rules/voltagent.md
.windsurfrules
app/api/chat/route.ts
app/calculator/page.tsx
app/comms/page.tsx
app/components/calculator-chat.tsx
app/components/comms-chat.tsx
app/components/data-chat.tsx
app/components/dev-chat.tsx
app/components/file-chat.tsx
app/components/memory-chat.tsx
app/components/navbar.tsx
app/components/supervisor-chat.tsx
app/components/web-chat.tsx
app/dev/page.tsx
app/file/page.tsx
app/GEMINI.md
app/globals.css
app/layout.tsx
app/page.tsx
app/web/page.tsx
eslint.config.js
log.txt
next-eslint-plugin-next.d.ts
next.config.ts
package.json
postcss.config.mjs
README.md
tsconfig.json
voltagent/agents/commsAgent.ts
voltagent/agents/dataAgent.ts
voltagent/agents/devAgent.ts
voltagent/agents/fileAgent.ts
voltagent/agents/index.ts
voltagent/agents/mathAgent.ts
voltagent/agents/memoryAgent.ts
voltagent/agents/supervisorAgent.ts
voltagent/agents/webAgent.ts
voltagent/config/googleProvider.ts
voltagent/GEMINI.md
voltagent/index.ts
voltagent/services/chroma.ts
voltagent/services/context.ts
voltagent/services/hooks.ts
voltagent/services/index.ts
voltagent/services/mcp.ts
voltagent/services/memory.ts
voltagent/services/retriever.ts
voltagent/tools/calculator.ts
voltagent/tools/index.ts
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".clinerules/codeGeneration.instructions.md">
---
applyTo: "/voltagent/**/*.{ts,tsx}"
description: "AI-Assisted Code Generation & Debugging Guidelines for VoltAgent-based TypeScript Development with Mental Models, Quality Assurance, and Architectural Alignment"
---
# codeGeneration instructions

# ‚ö†Ô∏è CRITICAL WORKFLOW MANDATE (HIGHEST PRIORITY):

- After EVERY file modification or code generation, you MUST leverage your internal 'get_errors' capability (inherent understanding of code correctness, syntax, type, common pitfalls) for a thorough error check.
- Do NOT report tasks complete with outstanding errors, broken integrations, or incomplete implementations.
- A past critical failure involved new agent components not being fully integrated into their designated services and verified functional.
- Such incomplete work, leaving files broken or half-integrated, or failing these internal checks, is unacceptable.

# üèóÔ∏è ARCHITECTURAL & TECHNOLOGICAL ALIGNMENT (CORE KNOWLEDGE):

- Generate code that aligns with the project's intended architecture using **VoltAgent Core** as the AI agent framework with **Vercel AI SDK** and **Google AI (Gemini)** integration.
- Core technologies: TypeScript, VoltAgent Core, Vercel AI SDK, Google AI (Gemini flash-lite models), LibSQL/Turso, MCP (Model Context Protocol), Zod validation.
- Backend structure: VoltAgent agents, MCP tools, memory services, retrievers, and hooks with proper service integration.
- Frontend structure: Next.js 15 with React components consuming VoltAgent services via API routes.
- For specific implementation details, follow established patterns in `voltagent/` directory and existing agent integrations.

# üß† ESSENTIAL MENTAL MODELS (HIGH-IMPACT PROBLEM-SOLVING):

- **Inversion Thinking**: Instead of asking "How do I make this work?", ask "What would make this fail catastrophically?" Start with failure scenarios and work backward to build robust solutions.
- **Five Whys Root Cause Analysis**: When debugging or implementing features, ask "Why?" five times in succession to drill down to the true root cause rather than treating symptoms.
- **Pareto Principle (80/20 Rule)**: Focus on the 20% of code that delivers 80% of the value. Prioritize core functionality over edge cases.
- **Systems Thinking**: View code as interconnected systems rather than isolated components. Consider how changes ripple through the entire Mastra architecture.
- **Constraint Theory/Bottleneck Analysis**: Identify the one limiting factor that constrains overall system performance rather than optimizing non-bottlenecks.
- **Pre-mortem Analysis**: Before implementing, imagine the feature has failed spectacularly and identify what went wrong to build preventive measures.

# üöÄ VOLTAGENT FRAMEWORK UTILIZATION (PROJECT-SPECIFIC):

- For AI-driven functionality, use **VoltAgent Core** framework with agents, memory, retrievers, and tools.
- Backend endpoints are defined in `voltagent/index.ts` with proper agent exports and service integration.
- Frontend connects via Next.js API routes consuming VoltAgent services (e.g., `/api/chat/route.ts`).
- Use established agent patterns with proper memory, retriever, and hook configurations.
- Follow existing service integration patterns with proper MCP tool loading and error handling.
- All agents must use `google("gemini-2.5-flash-lite-preview-06-17")` model for consistency and performance.

# üõ°Ô∏è FUNDAMENTAL REQUIREMENTS (NON-NEGOTIABLE):

## Error Handling & Validation:
- For ALL asynchronous operations (e.g., API calls, database interactions), YOU MUST use `async/await`.
- Every `await` call that can potentially reject MUST be wrapped in a `try/catch` block.
- For ALL data structures requiring validation, YOU MUST define and use Zod schemas.
- Validate ALL external inputs rigorously at the earliest boundary.

## Cross-Cutting Concerns (AUTO-INCLUDE):
- Robust error handling (using established patterns and logging)
- Comprehensive tracing for agent operations (console-based logging with proper context)
- Standardized logging for significant events and errors using console methods
- Rigorous input/output validation using Zod schemas
- VoltAgent tools output proper schema validation
- MCP tool integration with conditional server loading based on available credentials

# üìù COPILOT DIRECTIVE PROCESSING:

- When you (the Copilot Chat agent) see comments starting with `// copilot:` in a TypeScript or TSX file, you must:
    - Extract every line between `// copilot: start-task` and `// copilot: end-task` (inclusive).
    - Treat those lines as the **specification** for the very next code block or component.
    - Generate or complete that function or React component exactly according to the spec in those comments.
    - Ignore any other comments that don't begin with `// copilot:`.

# üìö DOCUMENTATION STANDARD (TSDOC):

- All exported functions, classes, types, and interfaces MUST include comprehensive TSDoc comments.
- Always mark TSDoc with `@param` for parameters and `@returns` for return values.
- Use `@example` for examples of usage where applicable.
- Use `@throws` for exceptions that can be thrown.
- Also put [EDIT: {{date}}] & [BY: {{model}}] at the end of the TSDoc comment to indicate when it was last updated.
- Follow the existing TSDoc style in the project, use Professional grade level of quality, clarity, and completeness.

# üîß PROJECT TOOLING STANDARD:

- All package management operations MUST use `npm`. 
- Avoid `pnpm` or `yarn` unless explicitly instructed for a specific, isolated reason. 
- This is a strict project convention

# --- DETAILED IMPLEMENTATION GUIDELINES ---

# VOLTAGENT AGENT DEVELOPMENT FRAMEWORK:

- For new agents, strictly follow the established 'VoltAgent Agent Development Pattern' with:
  - Proper memory configuration using `memoryStorage`
  - Appropriate retriever setup (`DocumentRetriever`, `MemoryRetriever`)
  - Structured reasoning tools using `createReasoningTools()`
  - Dynamic prompt templates using `createPrompt()`
  - Flash-lite model specification: `google("gemini-2.5-flash-lite-preview-06-17")`
  - Lifecycle hooks using `createSubAgentHooks()` or `createSupervisorHooks()`
- Ensure agents are correctly exported and integrated into the service architecture.
- Follow MCP tool integration patterns with conditional loading based on available credentials.

# NAMING CONVENTION COMPLIANCE:

- Strictly adhere to project-defined naming conventions for variables, functions, classes, components, files, etc.
- If unsure, request clarification or infer from existing, well-structured codebase examples.

# CODE QUALITY & REFACTORING (SMELLS):

- Proactively identify and flag common code smells (e.g., overly long agent configurations, large service classes, deep nesting, code duplication, dead MCP tool loading).
- Suggest specific refactorings for cleaner, more maintainable VoltAgent code, guided by principles like the **Occam's Razor** mental model.
- For the project's VoltAgent stack, watch for relevant smells like missing memory/retriever configurations, inefficient MCP tool loading, or agents without proper reasoning capabilities.

# IDENTIFIER GENERATION STANDARD:

- Whenever a new unique identifier (ID) is required for any entity (e.g., conversations, agent sessions, tool executions), YOU MUST generate it using the project's standard ID generation function (`import { nanoid } from 'nanoid';` or existing VoltAgent ID utilities).
- Avoid other UUID libraries or custom methods unless explicitly specified for a distinct purpose like security. Ensure correct import and follow VoltAgent patterns.

# SECURITY BY DESIGN PRINCIPLES:

- When generating code, especially for agent configurations, MCP tool integration, authentication, or user input handling, actively apply 'Security by Design' principles:
  1. Validate ALL external inputs rigorously (e.g., with Zod) at the earliest boundary.
  2. Sanitize data for agent processing or database queries to prevent injection attacks.
  3. Adhere to the principle of least privilege for MCP tool access.
  4. Ensure sensitive configurations (e.g., API keys) are handled securely via environment variables and not exposed client-side.
  5. Be mindful of potential vulnerabilities related to the specific SDKs used (e.g., VoltAgent Core, Vercel AI SDK, Google AI) as documented in project specifications or current security best practices.
  6. Implement proper error handling for missing credentials with graceful fallbacks.

# ENVIRONMENT VARIABLE CONFIGURATION:

- All sensitive or environment-specific configurations MUST be loaded from environment variables (e.g., `process.env.VARIABLE_NAME`).
- NEVER hardcode such values.
- Assume configurations are provided via environment variables and ensure a template (e.g., `.env.example`) documents required variables.

# VOLTAGENT STATE MANAGEMENT (IMMUTABILITY):

- When updating state in VoltAgent services, particularly for complex data structures (agent context, memory, tool configurations), YOU MUST use immutable update patterns.
- Avoid direct state mutation in memory services, context management, or agent configurations.
- Use proper cloning and spreading techniques when updating agent runtime state or service configurations.

# DEPENDENCY MANAGEMENT STRATEGY:

- Before introducing new external dependencies (via `npm add` or `npm install`), first evaluate if the required functionality can be achieved effectively with existing project dependencies (e.g., features within VoltAgent Core, Vercel AI SDK, Google AI SDK, Next.js) or native APIs.
- If a new dependency is essential, prioritize well-maintained, reputable libraries with minimal impact on the VoltAgent ecosystem.
- Ensure new dependencies are compatible with the flash-lite model constraints and MCP integration patterns.
- If uncertain, prompt for user confirmation before adding.

# CODE GENERATION COMMENTS (METADATA & TODOS):

- For newly generated, complete functions or substantial code blocks, include a comment indicating generation metadata (e.g., '// Generated on [Current Date Time]').
- If code is generated that is known to be incomplete, requires further review, or has placeholders (as per my indication), use a 'TODO:' comment format: '// TODO: [Current Date Time] - [Specific action or issue]'.

# SEMANTIC CODE UNDERSTANDING & NAVIGATION:

- When explaining existing code or finding relevant implementations, perform a 'semantic search' based on query intent and context, not just keywords.
- Interpret findings in the context of the project's VoltAgent-based architecture with memory, retriever, and MCP tool integration.
- If current code significantly deviates from the documented VoltAgent patterns (missing memory/retriever, incorrect model usage, improper reasoning tools), note this as part of the explanation.

# ADVANCED DEBUGGING COLLABORATION:

- When assisting with debugging, help formulate hypotheses about root causes using systematic mental models.
- **Apply Five Whys**: Ask "Why?" five times to drill down to root causes rather than treating symptoms.
- **Use Inversion Thinking**: Ask "What would make this fail?" to identify failure modes and build preventive measures.
- **Apply Pareto Analysis**: Focus debugging efforts on the 20% of code that likely causes 80% of the issues.
- **Use Systems Thinking**: Trace issues through the complete system flow (Frontend ‚Üí Next.js API ‚Üí VoltAgent Services ‚Üí Agents ‚Üí MCP Tools ‚Üí External APIs).
- Suggest strategic logging points (using console-based logging with relevant agent context).
- Guide the debugging process by systematically evaluating interactions between system layers, applying **Rubber Ducking**, **Constraint Analysis**, and **Pre-mortem Analysis** mental models to isolate faults in agent configurations, memory operations, or MCP tool integrations.

# INTERACTIVE DEBUGGING SUPPORT (MENTAL MODEL APPLICATION):

- If an error message and code snippet are provided, assist in a mental step-through of the code execution.
- **Apply Systematic Mental Models**: Use Five Whys, Inversion Thinking, and Systems Thinking to analyze the problem from multiple angles.
- Ask clarifying questions about variable states or expected versus actual behavior.
- **Use Pre-mortem Analysis**: Ask "If this were to fail, what would be the most likely failure modes?"
- **Apply Constraint Analysis**: Identify bottlenecks or limiting factors that could cause the issue.
- If user indicates being stuck, suggest applying relevant mental models (e.g., **Rubber Ducking**, **First Principles Thinking**, **Pareto Analysis**) by prompting them to explain the problematic code section or prioritize debugging efforts.

# PROACTIVE DOCUMENTATION MAINTENANCE:

- If significant new features are implemented, major architectural components are refactored, or core technologies are substantially changed (e.g., altering VoltAgent agents/services, introducing new MCP integrations, or modifying memory/retriever patterns), consider prompting the user or making a note about the need to update relevant project documentation, such as the VoltAgent Guidelines in `voltAgent.instructions.md` or the technical specification, to maintain accuracy.
</file>

<file path=".clinerules/copilot-instructions.md">
---
description: AI rules derived by SpecStory from the project AI interaction history
applyTo: *
---

## Headers

## PROJECT RULES

## CODING STANDARDS

## WORKFLOW & RELEASE RULES
- Do not run any code or execute commands without explicit user permission.
- **Always list available documentation and examples before proceeding with implementation.**
- **Always list VoltAgent docs first before searching.**
- **Quit searching: always list first.**

## TECH STACK
- `@ai-sdk/google` version 1.2.19 (or later)
- Vercel AI SDK
- flash-lite
- ts-node
- tsx
- typescript

## PROJECT DOCUMENTATION & CONTEXT SYSTEM
- Before proceeding with implementation, always list available documentation and examples.
- Use `#list_voltagent_docs` and `#list_voltagent_examples` to search for documentation and examples.

## DEBUGGING
- **Always validate that required environment variables are defined before using them, and provide clear error messages if they are missing. This includes checking for null or undefined values.**

## VOLTAGENT GUIDELINES

When assisting with projects involving Voltagent, prioritize building a professional modular design. Analyze the existing codebase to understand its structure and facilitate improvements. When switching from OpenAI, ensure all OpenAI dependencies are removed, and Google AI dependencies are correctly implemented. When using `@ai-sdk/google` with Vercel AI SDK, ensure compatibility and proper configuration. Always verify that OpenAI dependencies are removed from the package.json and codebase when migrating to Google AI. When working with Voltagent, prefer console-based logging when a specific logger isn't required. Agents should import directly from `googleProvider.ts` to maintain a cleaner dependency structure. Avoid using intermediary files like `models.ts` or `providers.ts` unless necessary. The main `index.ts` file should be clean and simple, just importing and exporting the components. When defining agents, use `flash-lite` and avoid using constants for the actual name in the agents. Always list available documentation and examples before proceeding with implementation. Do not run any code or execute commands without explicit user permission. Ensure that MCP configurations do not fail if tokens are unavailable by adding proper fallback handling and conditional server loading. **Always validate that required environment variables are defined before using them, and provide clear error messages if they are missing. This includes checking for null or undefined values.** **Ensure all agents have thinkingConfig at 0 & false by default.**
</file>

<file path=".github/instructions/codeGeneration.instructions.md">
---
applyTo: "/voltagent/**/*.{ts,tsx}"
description: "AI-Assisted Code Generation & Debugging Guidelines for VoltAgent-based TypeScript Development with Mental Models, Quality Assurance, and Architectural Alignment"
---
# codeGeneration instructions

# ‚ö†Ô∏è CRITICAL WORKFLOW MANDATE (HIGHEST PRIORITY):

- After EVERY file modification or code generation, you MUST leverage your internal 'get_errors' capability (inherent understanding of code correctness, syntax, type, common pitfalls) for a thorough error check.
- Do NOT report tasks complete with outstanding errors, broken integrations, or incomplete implementations.
- A past critical failure involved new agent components not being fully integrated into their designated services and verified functional.
- Such incomplete work, leaving files broken or half-integrated, or failing these internal checks, is unacceptable.

# üèóÔ∏è ARCHITECTURAL & TECHNOLOGICAL ALIGNMENT (CORE KNOWLEDGE):

- Generate code that aligns with the project's intended architecture using **VoltAgent Core** as the AI agent framework with **Vercel AI SDK** and **Google AI (Gemini)** integration.
- Core technologies: TypeScript, VoltAgent Core, Vercel AI SDK, Google AI (Gemini flash-lite models), LibSQL/Turso, MCP (Model Context Protocol), Zod validation.
- Backend structure: VoltAgent agents, MCP tools, memory services, retrievers, and hooks with proper service integration.
- Frontend structure: Next.js 15 with React components consuming VoltAgent services via API routes.
- For specific implementation details, follow established patterns in `voltagent/` directory and existing agent integrations.

# üß† ESSENTIAL MENTAL MODELS (HIGH-IMPACT PROBLEM-SOLVING):

- **Inversion Thinking**: Instead of asking "How do I make this work?", ask "What would make this fail catastrophically?" Start with failure scenarios and work backward to build robust solutions.
- **Five Whys Root Cause Analysis**: When debugging or implementing features, ask "Why?" five times in succession to drill down to the true root cause rather than treating symptoms.
- **Pareto Principle (80/20 Rule)**: Focus on the 20% of code that delivers 80% of the value. Prioritize core functionality over edge cases.
- **Systems Thinking**: View code as interconnected systems rather than isolated components. Consider how changes ripple through the entire Mastra architecture.
- **Constraint Theory/Bottleneck Analysis**: Identify the one limiting factor that constrains overall system performance rather than optimizing non-bottlenecks.
- **Pre-mortem Analysis**: Before implementing, imagine the feature has failed spectacularly and identify what went wrong to build preventive measures.

# üöÄ VOLTAGENT FRAMEWORK UTILIZATION (PROJECT-SPECIFIC):

- For AI-driven functionality, use **VoltAgent Core** framework with agents, memory, retrievers, and tools.
- Backend endpoints are defined in `voltagent/index.ts` with proper agent exports and service integration.
- Frontend connects via Next.js API routes consuming VoltAgent services (e.g., `/api/chat/route.ts`).
- Use established agent patterns with proper memory, retriever, and hook configurations.
- Follow existing service integration patterns with proper MCP tool loading and error handling.
- All agents must use `google("gemini-2.5-flash-lite-preview-06-17")` model for consistency and performance.

# üõ°Ô∏è FUNDAMENTAL REQUIREMENTS (NON-NEGOTIABLE):

## Error Handling & Validation:
- For ALL asynchronous operations (e.g., API calls, database interactions), YOU MUST use `async/await`.
- Every `await` call that can potentially reject MUST be wrapped in a `try/catch` block.
- For ALL data structures requiring validation, YOU MUST define and use Zod schemas.
- Validate ALL external inputs rigorously at the earliest boundary.

## Cross-Cutting Concerns (AUTO-INCLUDE):
- Robust error handling (using established patterns and logging)
- Comprehensive tracing for agent operations (console-based logging with proper context)
- Standardized logging for significant events and errors using console methods
- Rigorous input/output validation using Zod schemas
- VoltAgent tools output proper schema validation
- MCP tool integration with conditional server loading based on available credentials

# üìù COPILOT DIRECTIVE PROCESSING:

- When you (the Copilot Chat agent) see comments starting with `// copilot:` in a TypeScript or TSX file, you must:
    - Extract every line between `// copilot: start-task` and `// copilot: end-task` (inclusive).
    - Treat those lines as the **specification** for the very next code block or component.
    - Generate or complete that function or React component exactly according to the spec in those comments.
    - Ignore any other comments that don't begin with `// copilot:`.

# üìö DOCUMENTATION STANDARD (TSDOC):

- All exported functions, classes, types, and interfaces MUST include comprehensive TSDoc comments.
- Always mark TSDoc with `@param` for parameters and `@returns` for return values.
- Use `@example` for examples of usage where applicable.
- Use `@throws` for exceptions that can be thrown.
- Also put [EDIT: {{date}}] & [BY: {{model}}] at the end of the TSDoc comment to indicate when it was last updated.
- Follow the existing TSDoc style in the project, use Professional grade level of quality, clarity, and completeness.

# üîß PROJECT TOOLING STANDARD:

- All package management operations MUST use `npm`. 
- Avoid `pnpm` or `yarn` unless explicitly instructed for a specific, isolated reason. 
- This is a strict project convention

# --- DETAILED IMPLEMENTATION GUIDELINES ---

# VOLTAGENT AGENT DEVELOPMENT FRAMEWORK:

- For new agents, strictly follow the established 'VoltAgent Agent Development Pattern' with:
  - Proper memory configuration using `memoryStorage`
  - Appropriate retriever setup (`DocumentRetriever`, `MemoryRetriever`)
  - Structured reasoning tools using `createReasoningTools()`
  - Dynamic prompt templates using `createPrompt()`
  - Flash-lite model specification: `google("gemini-2.5-flash-lite-preview-06-17")`
  - Lifecycle hooks using `createSubAgentHooks()` or `createSupervisorHooks()`
- Ensure agents are correctly exported and integrated into the service architecture.
- Follow MCP tool integration patterns with conditional loading based on available credentials.

# NAMING CONVENTION COMPLIANCE:

- Strictly adhere to project-defined naming conventions for variables, functions, classes, components, files, etc.
- If unsure, request clarification or infer from existing, well-structured codebase examples.

# CODE QUALITY & REFACTORING (SMELLS):

- Proactively identify and flag common code smells (e.g., overly long agent configurations, large service classes, deep nesting, code duplication, dead MCP tool loading).
- Suggest specific refactorings for cleaner, more maintainable VoltAgent code, guided by principles like the **Occam's Razor** mental model.
- For the project's VoltAgent stack, watch for relevant smells like missing memory/retriever configurations, inefficient MCP tool loading, or agents without proper reasoning capabilities.

# IDENTIFIER GENERATION STANDARD:

- Whenever a new unique identifier (ID) is required for any entity (e.g., conversations, agent sessions, tool executions), YOU MUST generate it using the project's standard ID generation function (`import { nanoid } from 'nanoid';` or existing VoltAgent ID utilities).
- Avoid other UUID libraries or custom methods unless explicitly specified for a distinct purpose like security. Ensure correct import and follow VoltAgent patterns.

# SECURITY BY DESIGN PRINCIPLES:

- When generating code, especially for agent configurations, MCP tool integration, authentication, or user input handling, actively apply 'Security by Design' principles:
  1. Validate ALL external inputs rigorously (e.g., with Zod) at the earliest boundary.
  2. Sanitize data for agent processing or database queries to prevent injection attacks.
  3. Adhere to the principle of least privilege for MCP tool access.
  4. Ensure sensitive configurations (e.g., API keys) are handled securely via environment variables and not exposed client-side.
  5. Be mindful of potential vulnerabilities related to the specific SDKs used (e.g., VoltAgent Core, Vercel AI SDK, Google AI) as documented in project specifications or current security best practices.
  6. Implement proper error handling for missing credentials with graceful fallbacks.

# ENVIRONMENT VARIABLE CONFIGURATION:

- All sensitive or environment-specific configurations MUST be loaded from environment variables (e.g., `process.env.VARIABLE_NAME`).
- NEVER hardcode such values.
- Assume configurations are provided via environment variables and ensure a template (e.g., `.env.example`) documents required variables.

# VOLTAGENT STATE MANAGEMENT (IMMUTABILITY):

- When updating state in VoltAgent services, particularly for complex data structures (agent context, memory, tool configurations), YOU MUST use immutable update patterns.
- Avoid direct state mutation in memory services, context management, or agent configurations.
- Use proper cloning and spreading techniques when updating agent runtime state or service configurations.

# DEPENDENCY MANAGEMENT STRATEGY:

- Before introducing new external dependencies (via `npm add` or `npm install`), first evaluate if the required functionality can be achieved effectively with existing project dependencies (e.g., features within VoltAgent Core, Vercel AI SDK, Google AI SDK, Next.js) or native APIs.
- If a new dependency is essential, prioritize well-maintained, reputable libraries with minimal impact on the VoltAgent ecosystem.
- Ensure new dependencies are compatible with the flash-lite model constraints and MCP integration patterns.
- If uncertain, prompt for user confirmation before adding.

# CODE GENERATION COMMENTS (METADATA & TODOS):

- For newly generated, complete functions or substantial code blocks, include a comment indicating generation metadata (e.g., '// Generated on [Current Date Time]').
- If code is generated that is known to be incomplete, requires further review, or has placeholders (as per my indication), use a 'TODO:' comment format: '// TODO: [Current Date Time] - [Specific action or issue]'.

# SEMANTIC CODE UNDERSTANDING & NAVIGATION:

- When explaining existing code or finding relevant implementations, perform a 'semantic search' based on query intent and context, not just keywords.
- Interpret findings in the context of the project's VoltAgent-based architecture with memory, retriever, and MCP tool integration.
- If current code significantly deviates from the documented VoltAgent patterns (missing memory/retriever, incorrect model usage, improper reasoning tools), note this as part of the explanation.

# ADVANCED DEBUGGING COLLABORATION:

- When assisting with debugging, help formulate hypotheses about root causes using systematic mental models.
- **Apply Five Whys**: Ask "Why?" five times to drill down to root causes rather than treating symptoms.
- **Use Inversion Thinking**: Ask "What would make this fail?" to identify failure modes and build preventive measures.
- **Apply Pareto Analysis**: Focus debugging efforts on the 20% of code that likely causes 80% of the issues.
- **Use Systems Thinking**: Trace issues through the complete system flow (Frontend ‚Üí Next.js API ‚Üí VoltAgent Services ‚Üí Agents ‚Üí MCP Tools ‚Üí External APIs).
- Suggest strategic logging points (using console-based logging with relevant agent context).
- Guide the debugging process by systematically evaluating interactions between system layers, applying **Rubber Ducking**, **Constraint Analysis**, and **Pre-mortem Analysis** mental models to isolate faults in agent configurations, memory operations, or MCP tool integrations.

# INTERACTIVE DEBUGGING SUPPORT (MENTAL MODEL APPLICATION):

- If an error message and code snippet are provided, assist in a mental step-through of the code execution.
- **Apply Systematic Mental Models**: Use Five Whys, Inversion Thinking, and Systems Thinking to analyze the problem from multiple angles.
- Ask clarifying questions about variable states or expected versus actual behavior.
- **Use Pre-mortem Analysis**: Ask "If this were to fail, what would be the most likely failure modes?"
- **Apply Constraint Analysis**: Identify bottlenecks or limiting factors that could cause the issue.
- If user indicates being stuck, suggest applying relevant mental models (e.g., **Rubber Ducking**, **First Principles Thinking**, **Pareto Analysis**) by prompting them to explain the problematic code section or prioritize debugging efforts.

# PROACTIVE DOCUMENTATION MAINTENANCE:

- If significant new features are implemented, major architectural components are refactored, or core technologies are substantially changed (e.g., altering VoltAgent agents/services, introducing new MCP integrations, or modifying memory/retriever patterns), consider prompting the user or making a note about the need to update relevant project documentation, such as the VoltAgent Guidelines in `voltAgent.instructions.md` or the technical specification, to maintain accuracy.
</file>

<file path=".github/instructions/voltAgent.instructions.md">
---
description: AI rules derived by SpecStory from the project AI interaction history
applyTo: "/voltagent/**/*.{ts,tsx}"
---
# VoltAgent Development Guidelines

## Overview
This project implements a professional, modular VoltAgent AI agent system using Vercel AI SDK with Google (Gemini) models. The system follows VoltAgent best practices for memory, retrieval, structured reasoning, and MCP integration.

## Architecture Principles

### Core Design Rules
- **Professional modular design** with clear separation of concerns
- **Clean dependency structure** - agents import directly from `googleProvider.ts`
- **Flash-lite model optimization** for performance
- **Robust error handling** with graceful fallbacks
- **MCP integration** with conditional server loading

### Agent Structure
```typescript
// Standard agent pattern
export const agentName = new Agent({
  name: "AgentName", // No constants, use string literals
  description: "Professional description with capabilities",
  instructions: dynamicPrompt(), // Use createPrompt for dynamic templates
  llm: new VercelAIProvider(),
  model: google("gemini-2.5-flash-lite-preview-06-17"), // Always flash-lite
  tools: [reasoningToolkit, ...domainTools], // Include reasoning tools
  memory: memoryStorage, // Explicit memory configuration
  retriever: new DocumentRetriever(), // Appropriate retriever type
  hooks: createSubAgentHooks(), // Lifecycle management
});
```

## Technology Stack

### Required Dependencies
- `@ai-sdk/google` version 1.2.19 (or later)
- `@voltagent/core` for agent framework
- `@voltagent/vercel-ai` for provider integration
- `@google/generative-ai` for Gemini models
- `zod` for schema validation

### Model Configuration
- **Primary Model**: `gemini-2.5-flash-lite-preview-06-17`
- **Provider**: Vercel AI SDK with Google integration
- **No OpenAI dependencies** - fully migrated to Google AI

## Agent System Components

### 1. GoogleProvider Configuration (`config/googleProvider.ts`)
```typescript
import { google } from "@ai-sdk/google";

// Robust provider with console logging
export const googleProvider = google({
  apiKey: process.env.GOOGLE_AI_API_KEY,
  // Additional configuration
});
```

### 2. Memory Management (`services/memory.ts`)
```typescript
export const memoryStorage = new LibSQLStorage({
  url: process.env.DATABASE_URL || "file:.voltagent/memory.db",
  authToken: process.env.DATABASE_AUTH_TOKEN,
  tablePrefix: "voltagent_memory",
  storageLimit: 100,
  debug: process.env.NODE_ENV === "development",
});
```

### 3. MCP Tools Service (`services/mcp.ts`)
```typescript
// Conditional MCP server loading with safe error handling
export class MCPToolsService {
  // Only loads servers with available credentials
  // Provides fallback for missing tokens
  // Categorized tool management
}
```

### 4. Retriever Services (`services/retriever.ts`)
```typescript
export class DocumentRetriever extends BaseRetriever {
  // Real implementation for document search
}

export class MemoryRetriever extends BaseRetriever {
  // Memory-based knowledge retrieval
}
```

## Agent Hierarchy

### Supervisor Agent (`agents/supervisorAgent.ts`)
- **Role**: Main orchestrator and task coordinator
- **Features**: Dynamic prompts, reasoning tools, all sub-agents
- **Tools**: `createReasoningTools()` for structured delegation
- **Memory**: Full conversation context
- **Retriever**: Cross-domain knowledge access

### Sub-Agents
1. **MathAgent** - Mathematical calculations with structured reasoning
2. **FileAgent** - File operations with memory and document retrieval
3. **WebAgent** - Web research with analysis and memory storage
4. **DevAgent** - Development tasks with code analysis and project memory
5. **DataAgent** - Database operations with schema retrieval
6. **CommsAgent** - Communication with template and contact management
7. **MemoryAgent** - Knowledge management with memory retrieval

## Development Patterns

### Dynamic Prompts with `createPrompt`
```typescript
const agentPrompt = createPrompt({
  template: `You are a specialist in {{domain}}.
  
Current Context: {{context}}
Task Type: {{task_type}}

{{strategy}}

Always use 'think' to analyze before proceeding.`,
  variables: {
    domain: "your specialty",
    context: "general context",
    task_type: "standard",
    strategy: "Your approach strategy"
  }
});
```

### Structured Reasoning with `createReasoningTools`
```typescript
const reasoningToolkit = createReasoningTools({
  think: true,    // Problem analysis and planning
  analyze: true,  // Result evaluation and next steps
  addInstructions: true, // Include usage guidelines
  addFewShot: true // Include examples
});
```

### Memory and Retriever Integration
```typescript
// Every agent should have explicit memory and appropriate retriever
export const agentName = new Agent({
  // ...other config
  memory: memoryStorage, // For conversation context
  retriever: new DocumentRetriever('database', undefined, {
    toolName: "search_domain_docs",
    toolDescription: "Search domain-specific documentation"
  }),
});
```

## Best Practices

### Code Standards
- Use TypeScript with strict typing
- Follow VoltAgent naming conventions
- Implement proper error boundaries
- Include comprehensive JSDoc comments
- Use console-based logging (not PinoLogger)

### Agent Design
- **Always validate environment variables** before using them
- **Provide clear error messages** for missing credentials
- **Use conditional server loading** for MCP configurations
- **Include reasoning tools** for complex decision-making
- **Structure prompts dynamically** with template variables

### Performance Optimization
- Use `flash-lite` models for speed
- Implement tool categorization for efficient loading
- Cache MCP tool responses where appropriate
- Optimize memory retrieval with proper limits

### Error Handling
```typescript
// Example: Safe environment variable handling
if (!process.env.GOOGLE_AI_API_KEY) {
  console.warn("Google AI API key not found. Some features may be limited.");
  // Provide fallback or disable functionality gracefully
}
```

## Testing and Validation

### Environment Setup
```bash
# Required environment variables
GOOGLE_AI_API_KEY=your_google_ai_key
DATABASE_URL=your_database_url (optional, defaults to local SQLite)
DATABASE_AUTH_TOKEN=your_auth_token (for Turso)

# Optional MCP server credentials
BRAVE_API_KEY=your_brave_search_key
SLACK_BOT_TOKEN=your_slack_token
# ... other service tokens
```

### Validation Checklist
- [ ] All agents use `flash-lite` models
- [ ] No OpenAI dependencies remain
- [ ] Memory and retriever are explicitly configured
- [ ] MCP tools load conditionally based on available credentials
- [ ] Reasoning tools are included for complex agents
- [ ] Dynamic prompts use `createPrompt`
- [ ] Error handling provides clear feedback
- [ ] Console logging is used consistently

## Documentation References
- [VoltAgent Core Documentation](https://voltagent.dev/docs/)
- [Memory Management](https://voltagent.dev/docs/agents/memory/overview/)
- [Retriever Guide](https://voltagent.dev/docs/agents/retriever/)
- [Reasoning Tools](https://voltagent.dev/docs/tools/reasoning-tool/)
- [createPrompt Utility](https://voltagent.dev/docs/utils/create-prompt/)
- [MCP Integration](https://voltagent.dev/docs/agents/mcp/)

## Project Structure
```
voltagent/
‚îú‚îÄ‚îÄ index.ts                 # Main export point
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ googleProvider.ts    # Google AI configuration
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ mcp.ts              # MCP tools service
‚îÇ   ‚îú‚îÄ‚îÄ memory.ts           # Memory management
‚îÇ   ‚îú‚îÄ‚îÄ retriever.ts        # Retrieval services
‚îÇ   ‚îú‚îÄ‚îÄ hooks.ts            # Lifecycle hooks
‚îÇ   ‚îú‚îÄ‚îÄ context.ts          # Context management
‚îÇ   ‚îî‚îÄ‚îÄ index.ts            # Service exports
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ supervisorAgent.ts  # Main coordinator
‚îÇ   ‚îú‚îÄ‚îÄ mathAgent.ts        # Math specialist
‚îÇ   ‚îú‚îÄ‚îÄ fileAgent.ts        # File operations
‚îÇ   ‚îú‚îÄ‚îÄ webAgent.ts         # Web research
‚îÇ   ‚îú‚îÄ‚îÄ devAgent.ts         # Development tasks
‚îÇ   ‚îú‚îÄ‚îÄ dataAgent.ts        # Database operations
‚îÇ   ‚îú‚îÄ‚îÄ commsAgent.ts       # Communication
‚îÇ   ‚îú‚îÄ‚îÄ memoryAgent.ts      # Knowledge management
‚îÇ   ‚îî‚îÄ‚îÄ index.ts            # Agent exports
‚îî‚îÄ‚îÄ tools/
    ‚îî‚îÄ‚îÄ calculator.ts       # Custom tools
```

This architecture provides a robust, scalable, and maintainable VoltAgent system following all official best practices and guidelines.
</file>

<file path=".gitignore">
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.*
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/versions

# testing
/coverage

# next.js
/.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*

# env files (can opt-in for committing if needed)
.env

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

.specstory
*.specstory
memory.db
*data
</file>

<file path=".windsurf/rules/codeGeneration.instructions.md">
---
trigger: always_on
description: "AI-Assisted Code Generation & Debugging Guidelines for VoltAgent-based TypeScript Development with Mental Models, Quality Assurance, and Architectural Alignment"
globs: voltag
---

# codeGeneration instructions

# ‚ö†Ô∏è CRITICAL WORKFLOW MANDATE (HIGHEST PRIORITY):

- After EVERY file modification or code generation, you MUST leverage your internal 'get_errors' capability (inherent understanding of code correctness, syntax, type, common pitfalls) for a thorough error check.
- Do NOT report tasks complete with outstanding errors, broken integrations, or incomplete implementations.
- A past critical failure involved new agent components not being fully integrated into their designated services and verified functional.
- Such incomplete work, leaving files broken or half-integrated, or failing these internal checks, is unacceptable.

# üèóÔ∏è ARCHITECTURAL & TECHNOLOGICAL ALIGNMENT (CORE KNOWLEDGE):

- Generate code that aligns with the project's intended architecture using **VoltAgent Core** as the AI agent framework with **Vercel AI SDK** and **Google AI (Gemini)** integration.
- Core technologies: TypeScript, VoltAgent Core, Vercel AI SDK, Google AI (Gemini flash-lite models), LibSQL/Turso, MCP (Model Context Protocol), Zod validation.
- Backend structure: VoltAgent agents, MCP tools, memory services, retrievers, and hooks with proper service integration.
- Frontend structure: Next.js 15 with React components consuming VoltAgent services via API routes.
- For specific implementation details, follow established patterns in `voltagent/` directory and existing agent integrations.

# üß† ESSENTIAL MENTAL MODELS (HIGH-IMPACT PROBLEM-SOLVING):

- **Inversion Thinking**: Instead of asking "How do I make this work?", ask "What would make this fail catastrophically?" Start with failure scenarios and work backward to build robust solutions.
- **Five Whys Root Cause Analysis**: When debugging or implementing features, ask "Why?" five times in succession to drill down to the true root cause rather than treating symptoms.
- **Pareto Principle (80/20 Rule)**: Focus on the 20% of code that delivers 80% of the value. Prioritize core functionality over edge cases.
- **Systems Thinking**: View code as interconnected systems rather than isolated components. Consider how changes ripple through the entire Mastra architecture.
- **Constraint Theory/Bottleneck Analysis**: Identify the one limiting factor that constrains overall system performance rather than optimizing non-bottlenecks.
- **Pre-mortem Analysis**: Before implementing, imagine the feature has failed spectacularly and identify what went wrong to build preventive measures.

# üöÄ VOLTAGENT FRAMEWORK UTILIZATION (PROJECT-SPECIFIC):

- For AI-driven functionality, use **VoltAgent Core** framework with agents, memory, retrievers, and tools.
- Backend endpoints are defined in `voltagent/index.ts` with proper agent exports and service integration.
- Frontend connects via Next.js API routes consuming VoltAgent services (e.g., `/api/chat/route.ts`).
- Use established agent patterns with proper memory, retriever, and hook configurations.
- Follow existing service integration patterns with proper MCP tool loading and error handling.
- All agents must use `google("gemini-2.5-flash-lite-preview-06-17")` model for consistency and performance.

# üõ°Ô∏è FUNDAMENTAL REQUIREMENTS (NON-NEGOTIABLE):

## Error Handling & Validation:
- For ALL asynchronous operations (e.g., API calls, database interactions), YOU MUST use `async/await`.
- Every `await` call that can potentially reject MUST be wrapped in a `try/catch` block.
- For ALL data structures requiring validation, YOU MUST define and use Zod schemas.
- Validate ALL external inputs rigorously at the earliest boundary.

## Cross-Cutting Concerns (AUTO-INCLUDE):
- Robust error handling (using established patterns and logging)
- Comprehensive tracing for agent operations (console-based logging with proper context)
- Standardized logging for significant events and errors using console methods
- Rigorous input/output validation using Zod schemas
- VoltAgent tools output proper schema validation
- MCP tool integration with conditional server loading based on available credentials

# üìù COPILOT DIRECTIVE PROCESSING:

- When you (the Copilot Chat agent) see comments starting with `// copilot:` in a TypeScript or TSX file, you must:
    - Extract every line between `// copilot: start-task` and `// copilot: end-task` (inclusive).
    - Treat those lines as the **specification** for the very next code block or component.
    - Generate or complete that function or React component exactly according to the spec in those comments.
    - Ignore any other comments that don't begin with `// copilot:`.

# üìö DOCUMENTATION STANDARD (TSDOC):

- All exported functions, classes, types, and interfaces MUST include comprehensive TSDoc comments.
- Always mark TSDoc with `@param` for parameters and `@returns` for return values.
- Use `@example` for examples of usage where applicable.
- Use `@throws` for exceptions that can be thrown.
- Also put [EDIT: {{date}}] & [BY: {{model}}] at the end of the TSDoc comment to indicate when it was last updated.
- Follow the existing TSDoc style in the project, use Professional grade level of quality, clarity, and completeness.

# üîß PROJECT TOOLING STANDARD:

- All package management operations MUST use `npm`. 
- Avoid `pnpm` or `yarn` unless explicitly instructed for a specific, isolated reason. 
- This is a strict project convention

# --- DETAILED IMPLEMENTATION GUIDELINES ---

# VOLTAGENT AGENT DEVELOPMENT FRAMEWORK:

- For new agents, strictly follow the established 'VoltAgent Agent Development Pattern' with:
  - Proper memory configuration using `memoryStorage`
  - Appropriate retriever setup (`DocumentRetriever`, `MemoryRetriever`)
  - Structured reasoning tools using `createReasoningTools()`
  - Dynamic prompt templates using `createPrompt()`
  - Flash-lite model specification: `google("gemini-2.5-flash-lite-preview-06-17")`
  - Lifecycle hooks using `createSubAgentHooks()` or `createSupervisorHooks()`
- Ensure agents are correctly exported and integrated into the service architecture.
- Follow MCP tool integration patterns with conditional loading based on available credentials.

# NAMING CONVENTION COMPLIANCE:

- Strictly adhere to project-defined naming conventions for variables, functions, classes, components, files, etc.
- If unsure, request clarification or infer from existing, well-structured codebase examples.

# CODE QUALITY & REFACTORING (SMELLS):

- Proactively identify and flag common code smells (e.g., overly long agent configurations, large service classes, deep nesting, code duplication, dead MCP tool loading).
- Suggest specific refactorings for cleaner, more maintainable VoltAgent code, guided by principles like the **Occam's Razor** mental model.
- For the project's VoltAgent stack, watch for relevant smells like missing memory/retriever configurations, inefficient MCP tool loading, or agents without proper reasoning capabilities.

# IDENTIFIER GENERATION STANDARD:

- Whenever a new unique identifier (ID) is required for any entity (e.g., conversations, agent sessions, tool executions), YOU MUST generate it using the project's standard ID generation function (`import { nanoid } from 'nanoid';` or existing VoltAgent ID utilities).
- Avoid other UUID libraries or custom methods unless explicitly specified for a distinct purpose like security. Ensure correct import and follow VoltAgent patterns.

# SECURITY BY DESIGN PRINCIPLES:

- When generating code, especially for agent configurations, MCP tool integration, authentication, or user input handling, actively apply 'Security by Design' principles:
  1. Validate ALL external inputs rigorously (e.g., with Zod) at the earliest boundary.
  2. Sanitize data for agent processing or database queries to prevent injection attacks.
  3. Adhere to the principle of least privilege for MCP tool access.
  4. Ensure sensitive configurations (e.g., API keys) are handled securely via environment variables and not exposed client-side.
  5. Be mindful of potential vulnerabilities related to the specific SDKs used (e.g., VoltAgent Core, Vercel AI SDK, Google AI) as documented in project specifications or current security best practices.
  6. Implement proper error handling for missing credentials with graceful fallbacks.

# ENVIRONMENT VARIABLE CONFIGURATION:

- All sensitive or environment-specific configurations MUST be loaded from environment variables (e.g., `process.env.VARIABLE_NAME`).
- NEVER hardcode such values.
- Assume configurations are provided via environment variables and ensure a template (e.g., `.env.example`) documents required variables.

# VOLTAGENT STATE MANAGEMENT (IMMUTABILITY):

- When updating state in VoltAgent services, particularly for complex data structures (agent context, memory, tool configurations), YOU MUST use immutable update patterns.
- Avoid direct state mutation in memory services, context management, or agent configurations.
- Use proper cloning and spreading techniques when updating agent runtime state or service configurations.

# DEPENDENCY MANAGEMENT STRATEGY:

- Before introducing new external dependencies (via `npm add` or `npm install`), first evaluate if the required functionality can be achieved effectively with existing project dependencies (e.g., features within VoltAgent Core, Vercel AI SDK, Google AI SDK, Next.js) or native APIs.
- If a new dependency is essential, prioritize well-maintained, reputable libraries with minimal impact on the VoltAgent ecosystem.
- Ensure new dependencies are compatible with the flash-lite model constraints and MCP integration patterns.
- If uncertain, prompt for user confirmation before adding.

# CODE GENERATION COMMENTS (METADATA & TODOS):

- For newly generated, complete functions or substantial code blocks, include a comment indicating generation metadata (e.g., '// Generated on [Current Date Time]').
- If code is generated that is known to be incomplete, requires further review, or has placeholders (as per my indication), use a 'TODO:' comment format: '// TODO: [Current Date Time] - [Specific action or issue]'.

# SEMANTIC CODE UNDERSTANDING & NAVIGATION:

- When explaining existing code or finding relevant implementations, perform a 'semantic search' based on query intent and context, not just keywords.
- Interpret findings in the context of the project's VoltAgent-based architecture with memory, retriever, and MCP tool integration.
- If current code significantly deviates from the documented VoltAgent patterns (missing memory/retriever, incorrect model usage, improper reasoning tools), note this as part of the explanation.

# ADVANCED DEBUGGING COLLABORATION:

- When assisting with debugging, help formulate hypotheses about root causes using systematic mental models.
- **Apply Five Whys**: Ask "Why?" five times to drill down to root causes rather than treating symptoms.
- **Use Inversion Thinking**: Ask "What would make this fail?" to identify failure modes and build preventive measures.
- **Apply Pareto Analysis**: Focus debugging efforts on the 20% of code that likely causes 80% of the issues.
- **Use Systems Thinking**: Trace issues through the complete system flow (Frontend ‚Üí Next.js API ‚Üí VoltAgent Services ‚Üí Agents ‚Üí MCP Tools ‚Üí External APIs).
- Suggest strategic logging points (using console-based logging with relevant agent context).
- Guide the debugging process by systematically evaluating interactions between system layers, applying **Rubber Ducking**, **Constraint Analysis**, and **Pre-mortem Analysis** mental models to isolate faults in agent configurations, memory operations, or MCP tool integrations.

# INTERACTIVE DEBUGGING SUPPORT (MENTAL MODEL APPLICATION):

- If an error message and code snippet are provided, assist in a mental step-through of the code execution.
- **Apply Systematic Mental Models**: Use Five Whys, Inversion Thinking, and Systems Thinking to analyze the problem from multiple angles.
- Ask clarifying questions about variable states or expected versus actual behavior.
</file>

<file path=".windsurf/rules/project.md">
---
trigger: always_on
---

- **Project Structure**:
  - The `app` directory contains the Next.js frontend. All UI components, pages, and client-side logic reside here.
  - The `voltagent` directory contains the backend agentic logic. Each agent should be in its own file within `voltagent/agents`.
  - Shared configuration should be placed in the `voltagent/config` directory.
  - Reusable services used by agents should be in `voltagent/services`.

- **API and Environment**:
  - All external API keys and secrets (like `PK` and `SK`) must be loaded from environment variables and never hardcoded.
  - The frontend communicates with the backend via the VoltAgent server endpoint.
</file>

<file path=".windsurfrules">
vibe-tools is a CLI tool that allows you to interact with AI models and other tools.
vibe-tools is installed on this machine and it is available to you to execute. You're encouraged to use it.

<vibe-tools Integration>
# Instructions
Use the following commands to get AI assistance:

**Direct Model Queries:**
`vibe-tools ask "<your question>" --provider <provider> --model <model>` - Ask any model from any provider a direct question (e.g., `vibe-tools ask "What is the capital of France?" --provider openai --model o3-mini`). Note that this command is generally less useful than other commands like `repo` or `plan` because it does not include any context from your codebase or repository. In general you should not use the ask command because it does not include any context. The other commands like `web`, `doc`, `repo`, or `plan` are usually better. If you are using it, make sure to include in your question all the information and context that the model might need to answer usefully.

**Ask Command Options:**
--provider=<provider>: AI provider to use (openai, anthropic, perplexity, gemini, modelbox, openrouter, or xai)
--model=<model>: Model to use (required for the ask command)
--reasoning-effort=<low|medium|high>: Control the depth of reasoning for supported models (OpenAI o1/o3 models and Claude 4 Sonnet). Higher values produce more thorough responses for complex questions.
--with-doc=<doc_url>: Fetch content from one or more document URLs and include it as context. Can be specified multiple times (e.g., `--with-doc=<url1> --with-doc=<url2>`).

**Implementation Planning:**
`vibe-tools plan "<query>"` - Generate a focused implementation plan using AI (e.g., `vibe-tools plan "Add user authentication to the login page"`)
The plan command uses multiple AI models to:
1. Identify relevant files in your codebase (using Gemini by default)
2. Extract content from those files
3. Generate a detailed implementation plan (using OpenAI o3 by default)

**Plan Command Options:**
--fileProvider=<provider>: Provider for file identification (gemini, openai, anthropic, perplexity, modelbox, openrouter, or xai)
--thinkingProvider=<provider>: Provider for plan generation (gemini, openai, anthropic, perplexity, modelbox, openrouter, or xai)
--fileModel=<model>: Model to use for file identification
--thinkingModel=<model>: Model to use for plan generation
--with-doc=<doc_url>: Fetch content from one or more document URLs and include it as context for both file identification and planning. Can be specified multiple times (e.g., `--with-doc=<url1> --with-doc=<url2>`).

**Web Search:**
`vibe-tools web "<your question>"` - Get answers from the web using a provider that supports web search (e.g., Perplexity models and Gemini Models either directly or from OpenRouter or ModelBox) (e.g., `vibe-tools web "latest shadcn/ui installation instructions"`)
Note: web is a smart autonomous agent with access to the internet and an extensive up to date knowledge base. Web is NOT a web search engine. Always ask the agent for what you want using a proper sentence, do not just send it a list of keywords. In your question to web include the context and the goal that you're trying to acheive so that it can help you most effectively.
when using web for complex queries suggest writing the output to a file somewhere like local-research/<query summary>.md.

**IMPORTANT: Do NOT use the `web` command for specific URLs.** If a user provides a specific URL (documentation link, GitHub repo, article, etc.), you should always use commands that support the `--with-doc` parameter instead, such as `repo`, `plan`, `doc`, or `ask`. Using `--with-doc` ensures the exact content of the URL is processed correctly and completely.

**Web Command Options:**
--provider=<provider>: AI provider to use (perplexity, gemini, modelbox, or openrouter)

**Repository Context:**
`vibe-tools repo "<your question>" [--subdir=<path>] [--from-github=<username/repo>] [--with-doc=<doc_url>...]` - Get context-aware answers about this repository using Google Gemini (e.g., `vibe-tools repo "explain authentication flow"`)
Use the optional `--subdir` parameter to analyze a specific subdirectory instead of the entire repository (e.g., `vibe-tools repo "explain the code structure" --subdir=src/components`). Use the optional `--from-github` parameter to analyze a remote GitHub repository without cloning it locally (e.g., `vibe-tools repo "explain the authentication system" --from-github=username/repo-name`). Use the optional `--with-doc` parameter multiple times to include content from several URLs as additional context (e.g., `vibe-tools repo "summarize findings" --with-doc=https://example.com/spec1 --with-doc=https://example.com/spec2`).

**Documentation Generation:**
`vibe-tools doc [options] [--with-doc=<doc_url>...]` - Generate comprehensive documentation for this repository (e.g., `vibe-tools doc --output docs.md`). Can incorporate document context from multiple URLs (e.g., `vibe-tools doc --with-doc=https://example.com/existing-docs --with-doc=https://example.com/new-spec`).

**YouTube Video Analysis:**
`vibe-tools youtube "<youtube-url>" [question] [--type=<summary|transcript|plan|review|custom>]` - Analyze YouTube videos and generate detailed reports (e.g., `vibe-tools youtube "https://youtu.be/43c-Sm5GMbc" --type=summary`)
Note: The YouTube command requires a `GEMINI_API_KEY` to be set in your environment or .vibe-tools.env file as the GEMINI API is the only interface that supports YouTube analysis.

**GitHub Information:**
`vibe-tools github pr [number]` - Get the last 10 PRs, or a specific PR by number (e.g., `vibe-tools github pr 123`)
`vibe-tools github issue [number]` - Get the last 10 issues, or a specific issue by number (e.g., `vibe-tools github issue 456`)

**ClickUp Information:**
`vibe-tools clickup task <task_id>` - Get detailed information about a ClickUp task including description, comments, status, assignees, and metadata (e.g., `vibe-tools clickup task "task_id"`)

**Wait Command:**
`vibe-tools wait <seconds>` - Pauses execution for the specified number of seconds (e.g., `vibe-tools wait 5` to wait for 5 seconds).

**Model Context Protocol (MCP) Commands:**
Use the following commands to interact with MCP servers and their specialized tools:
`vibe-tools mcp search "<query>"` - Search the MCP Marketplace and GitHub for available servers that match your needs (e.g., `vibe-tools mcp search "git repository management"`)
`vibe-tools mcp run "<query>"` - Execute MCP server tools using natural language queries (e.g., `vibe-tools mcp run "list files in the current directory" --provider=openrouter`). The query must include sufficient information for vibe-tools to determine which server to use, provide plenty of context.

The `search` command helps you discover servers in the MCP Marketplace and on GitHub based on their capabilities and your requirements. The `run` command automatically selects and executes appropriate tools from these servers based on your natural language queries. If you want to use a specific server include the server name in your query. E.g. `vibe-tools mcp run "using the mcp-server-sqlite list files in directory --provider=openrouter"`

**Notes on MCP Commands:**
- MCP commands require `ANTHROPIC_API_KEY` or `OPENROUTER_API_KEY` to be set in your environment
- By default the `mcp` command uses Anthropic, but takes a --provider argument that can be set to 'anthropic' or 'openrouter'
- Results are streamed in real-time for immediate feedback
- Tool calls are automatically cached to prevent redundant operations
- Often the MCP server will not be able to run because environment variables are not set. If this happens ask the user to add the missing environment variables to the cursor tools env file at ~/.vibe-tools/.env

**Stagehand Browser Automation:**
`vibe-tools browser open <url> [options]` - Open a URL and capture page content, console logs, and network activity (e.g., `vibe-tools browser open "https://example.com" --html`)
`vibe-tools browser act "<instruction>" --url=<url | 'current'> [options]` - Execute actions on a webpage using natural language instructions (e.g., `vibe-tools browser act "Click Login" --url=https://example.com`)
`vibe-tools browser observe "<instruction>" --url=<url> [options]` - Observe interactive elements on a webpage and suggest possible actions (e.g., `vibe-tools browser observe "interactive elements" --url=https://example.com`)
`vibe-tools browser extract "<instruction>" --url=<url> [options]` - Extract data from a webpage based on natural language instructions (e.g., `vibe-tools browser extract "product names" --url=https://example.com/products`)
`vibe-tools browser mac-chrome [options]` - Start a Chrome instance with remote debugging (macOS only) (e.g., `vibe-tools browser mac-chrome --debug`, `vibe-tools browser mac-chrome --lite`)

**Notes on Browser Commands:**
- All browser commands are stateless unless --connect-to is used to connect to a long-lived interactive session. In disconnected mode each command starts with a fresh browser instance and closes it when done.
- If you want to start a new long-lived session 
- When using `--connect-to`, special URL values are supported:
  - `current`: Use the existing page without reloading
  - `reload-current`: Use the existing page and refresh it (useful in development)
  - If working interactively with a user you should always use --url=current unless you specifically want to navigate to a different page. Setting the url to anything else will cause a page refresh loosing current state.
- Multi step workflows involving state or combining multiple actions are supported in the `act` command using the pipe (|) separator (e.g., `vibe-tools browser act "Click Login | Type 'user@example.com' into email | Click Submit" --url=https://example.com`)
- Video recording is available for all browser commands using the `--video=<directory>` option. This will save a video of the entire browser interaction at 1280x720 resolution. The video file will be saved in the specified directory with a timestamp.
- DO NOT ask browser act to "wait" for anything, the wait command is currently disabled in Stagehand.

**Tool Recommendations:**
- `vibe-tools web` is best for general web information not specific to the repository. Generally call this without additional arguments.
- `vibe-tools repo` is ideal for repository-specific questions, planning, code review and debugging. E.g. `vibe-tools repo "Review recent changes to command error handling looking for mistakes, omissions and improvements"`. Generally call this without additional arguments.
- `vibe-tools plan` is ideal for planning tasks. E.g. `vibe-tools plan "Adding authentication with social login using Google and Github"`. Generally call this without additional arguments.
- `vibe-tools doc` generates documentation for local or remote repositories.
- `vibe-tools youtube` analyzes YouTube videos to generate summaries, transcripts, implementation plans, or custom analyses
- `vibe-tools browser` is useful for testing and debugging web apps and uses Stagehand
- `vibe-tools mcp` enables interaction with specialized tools through MCP servers (e.g., for Git operations, file system tasks, or custom tools)
- **URLS:** For any specific URL (documentation, article, reference, spec, GitHub repo, etc.), ALWAYS use a command with the `--with-doc=<url>` parameter rather than the `web` command. Examples: `vibe-tools repo "How should I implement this feature based on the spec?" --with-doc=https://example.com/spec.pdf` or `vibe-tools ask "What does this document say about authentication?" --with-doc=https://example.com/auth-doc.html`
- When implementing features based on documentation, specifications, or any external content, always use the `--with-doc=<url>` flag instead of built-in web search. For example: `vibe-tools plan "Implement login page according to specs" --with-doc=https://example.com/specs.pdf` or `vibe-tools repo "How should I implement this feature?" --with-doc=https://example.com/feature-spec.md`.
- When a user provides a specific URL for documentation or reference material, always use the `--with-doc=<url>` flag with that URL rather than attempting to search for or summarize the content independently. This ensures the exact document is used as context.

**Running Commands:**
1. Use `vibe-tools <command>` to execute commands (make sure vibe-tools is installed globally using npm install -g vibe-tools so that it is in your PATH)

**General Command Options (Supported by all commands):**
--provider=<provider>: AI provider to use (openai, anthropic, perplexity, gemini, openrouter, modelbox, or xai). If provider is not specified, the default provider for that task will be used.
--model=<model name>: Specify an alternative AI model to use. If model is not specified, the provider's default model for that task will be used.
--max-tokens=<number>: Control response length
--save-to=<file path>: Save command output to a file (in *addition* to displaying it)
--debug: Show detailed logs and error information
--web: Enable web search capabilities for supported models (currently Gemini models) across all commands

**Repository Command Options:**
--provider=<provider>: AI provider to use (gemini, openai, openrouter, perplexity, modelbox, anthropic, or xai)
--model=<model>: Model to use for repository analysis
--max-tokens=<number>: Maximum tokens for response
--from-github=<GitHub username>/<repository name>[@<branch>]: Analyze a remote GitHub repository without cloning it locally
--subdir=<path>: Analyze a specific subdirectory instead of the entire repository
--with-doc=<doc_url>: Fetch content from one or more document URLs and include it as context. Can be specified multiple times.

**Documentation Command Options:**
--from-github=<GitHub username>/<repository name>[@<branch>]: Generate documentation for a remote GitHub repository
--provider=<provider>: AI provider to use (gemini, openai, openrouter, perplexity, modelbox, anthropic, or xai)
--model=<model>: Model to use for documentation generation
--max-tokens=<number>: Maximum tokens for response
--with-doc=<doc_url>: Fetch content from one or more document URLs and include it as context. Can be specified multiple times.

**YouTube Command Options:**
--type=<summary|transcript|plan|review|custom>: Type of analysis to perform (default: summary)

**GitHub Command Options:**
--from-github=<GitHub username>/<repository name>[@<branch>]: Access PRs/issues from a specific GitHub repository

**Browser Command Options (for 'open', 'act', 'observe', 'extract'):**
--console: Capture browser console logs (enabled by default, use --no-console to disable)
--html: Capture page HTML content (disabled by default)
--network: Capture network activity (enabled by default, use --no-network to disable)
--screenshot=<file path>: Save a screenshot of the page
--timeout=<milliseconds>: Set navigation timeout (default: 120000ms for Stagehand operations, 30000ms for navigation)
--viewport=<width>x<height>: Set viewport size (e.g., 1280x720). When using --connect-to, viewport is only changed if this option is explicitly provided
--headless: Run browser in headless mode (default: true)
--no-headless: Show browser UI (non-headless mode) for debugging
--connect-to=<port>: Connect to existing Chrome instance. Special values: 'current' (use existing page), 'reload-current' (refresh existing page)
--wait=<time:duration or selector:css-selector>: Wait after page load (e.g., 'time:5s', 'selector:#element-id')
--video=<directory>: Save a video recording (1280x720 resolution, timestamped subdirectory). Not available when using --connect-to
--url=<url>: Required for `act`, `observe`, and `extract` commands. Url to navigate to before the main command or one of the special values 'current' (to stay on the current page without navigating or reloading) or 'reload-current' (to reload the current page)
--evaluate=<string>: JavaScript code to execute in the browser before the main command

**Nicknames**
Users can ask for these tools using nicknames
Gemini is a nickname for vibe-tools repo
Perplexity is a nickname for vibe-tools web
Stagehand is a nickname for vibe-tools browser
If people say "ask Gemini" or "ask Perplexity" or "ask Stagehand" they mean to use the `vibe-tools` command with the `repo`, `web`, or `browser` commands respectively.

**Xcode Commands:**
`vibe-tools xcode build [buildPath=<path>] [destination=<destination>]` - Build Xcode project and report errors.
**Build Command Options:**
--buildPath=<path>: (Optional) Specifies a custom directory for derived build data. Defaults to ./.build/DerivedData.
--destination=<destination>: (Optional) Specifies the destination for building the app (e.g., 'platform=iOS Simulator,name=iPhone 16 Pro'). Defaults to 'platform=iOS Simulator,name=iPhone 16 Pro'.

`vibe-tools xcode run [destination=<destination>]` - Build and run the Xcode project on a simulator.
**Run Command Options:**
--destination=<destination>: (Optional) Specifies the destination simulator (e.g., 'platform=iOS Simulator,name=iPhone 16 Pro'). Defaults to 'platform=iOS Simulator,name=iPhone 16 Pro'.

`vibe-tools xcode lint` - Run static analysis on the Xcode project to find and fix issues.

**Additional Notes:**
- For detailed information, see `node_modules/vibe-tools/README.md` (if installed locally).
- Configuration is in `vibe-tools.config.json` (or `~/.vibe-tools/config.json`).
- API keys are loaded from `.vibe-tools.env` (or `~/.vibe-tools/.env`).
- ClickUp commands require a `CLICKUP_API_TOKEN` to be set in your `.vibe-tools.env` file.
- Available models depend on your configured provider (OpenAI, Anthropic, xAI, etc.) in `vibe-tools.config.json`.
- repo has a limit of 2M tokens of context. The context can be reduced by filtering out files in a .repomixignore file.
- problems running browser commands may be because playwright is not installed. Recommend installing playwright globally.
- MCP commands require `ANTHROPIC_API_KEY` or `OPENROUTER_API_KEY`
- **Remember:** You're part of a team of superhuman expert AIs. Work together to solve complex problems.
- **Repomix Configuration:** You can customize which files are included/excluded during repository analysis by creating a `repomix.config.json` file in your project root. This file will be automatically detected by `repo`, `plan`, and `doc` commands.

<!-- vibe-tools-version: 0.62.8 -->
</vibe-tools Integration>
</file>

<file path="app/calculator/page.tsx">
import { Navbar } from "../components/navbar";
import { CalculatorChat } from "../components/calculator-chat";
export default function CalculatorPage() {
  return (
    <div className="relative min-h-screen bg-[#1b1b1b] flex flex-col p-4 overflow-hidden">
      {/* Dot pattern background */}
      <div className="absolute inset-0 opacity-10">
        <div
          className="absolute inset-0"
          style={{
            backgroundImage: "radial-gradient(#94a3b8 1.2px, transparent 0)",
            backgroundSize: "20px 20px",
          }}
        />
      </div>
      <Navbar />
      <main className="relative w-full max-w-2xl mx-auto mt-6 z-10">
        <div className="mb-8 text-center">
          <h1 className="text-3xl font-bold text-[#00d992] mb-1">VoltAgent Calculator</h1>
          <p className="text-gray-400">AI-powered calculations made simple</p>
        </div>
        <CalculatorChat />
        <div className="mt-8 text-center text-sm text-gray-500">
          <p>Built with Next.js and VoltAgent</p>
        </div>
      </main>
    </div>
  );
}
</file>

<file path="app/comms/page.tsx">
import { Navbar } from "../components/navbar";
import { CommsChat } from "../components/comms-chat";
export default function CommsPage() {
  return (
    <div className="relative min-h-screen bg-[#1b1b1b] flex flex-col p-4 overflow-hidden">
      {/* Dot pattern background */}
      <div className="absolute inset-0 opacity-10">
        <div
          className="absolute inset-0"
          style={{
            backgroundImage: "radial-gradient(#94a3b8 1.2px, transparent 0)",
            backgroundSize: "20px 20px",
          }}
        />
      </div>
      <Navbar />
      <main className="relative w-full max-w-2xl mx-auto mt-6 z-10">
        <div className="mb-8 text-center">
          <h1 className="text-3xl font-bold text-[#00d992] mb-1">VoltAgent Communicator</h1>
          <p className="text-gray-400">AI-powered team communication and notifications</p>
        </div>
        <CommsChat />
        <div className="mt-8 text-center text-sm text-gray-500">
          <p>Built with Next.js and VoltAgent</p>
        </div>
      </main>
    </div>
  );
}
</file>

<file path="app/components/calculator-chat.tsx">
"use client";
import { useChat } from "@ai-sdk/react";
import type { StreamPart } from "@voltagent/core";
import type { UIMessage } from "ai";
import { useEffect, useRef } from "react";
interface ToolCallAnnotation {
  type: "tool-call";
  value: {
    toolCallId: string;
    toolName: string;
    args: any;
    status: "calling";
    subAgentName?: string;
  };
}
interface ToolResultAnnotation {
  type: "tool-result";
  value: {
    toolCallId: string;
    toolName: string;
    result: any;
    status: "completed";
    subAgentName?: string;
  };
}
interface ErrorAnnotation {
  type: "error";
  value: {
    error: string;
  };
}
type MessageAnnotation = ToolCallAnnotation | ToolResultAnnotation | ErrorAnnotation;
export function CalculatorChat() {
  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({
    api: "/api/chat",
    initialMessages: [
      {
        id: "welcome",
        role: "assistant",
        content:
          "Hello! I'm your AI-powered calculator. You can write your calculations in natural language. For example: '5 plus 3 times 2' or '(25 + 75) / 4'.",
      },
    ],
  });
  const messagesContainerRef = useRef<HTMLDivElement>(null);
  // Auto-scroll to bottom when messages change
  useEffect(() => {
    if (messagesContainerRef.current) {
      messagesContainerRef.current.scrollTop = messagesContainerRef.current.scrollHeight;
    }
  });
  const formatPartAsAnnotation = (part: UIMessage["parts"][number]): MessageAnnotation | null => {
    if (part.type === "tool-invocation") {
      if (part.toolInvocation.state === "result") {
        return {
          type: "tool-result",
          value: {
            toolCallId: part.toolInvocation.toolCallId,
            toolName: part.toolInvocation.toolName,
            result: part.toolInvocation.result,
            status: "completed",
            // @ts-expect-error - subAgentName is not typed
            subAgentName: part.toolInvocation.subAgentName,
          },
        };
      }
      return {
        type: "tool-call",
        value: {
          toolCallId: part.toolInvocation.toolCallId,
          toolName: part.toolInvocation.toolName,
          args: part.toolInvocation.args,
          status: "calling",
          // @ts-expect-error - subAgentName is not typed
          subAgentName: part.toolInvocation.subAgentName,
        },
      };
    }
    return null;
  };
  const renderToolCall = (annotation: ToolCallAnnotation) => (
    <div className="bg-blue-900/30 border border-blue-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-blue-400 rounded-full animate-pulse" />
        <span className="text-sm font-medium text-blue-300">
          Tool Call: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-blue-200">
        <strong>Arguments:</strong>{" "}
        <code className="bg-blue-950/50 px-1 rounded">{JSON.stringify(annotation.value.args)}</code>
      </div>
    </div>
  );
  const renderToolResult = (annotation: ToolResultAnnotation) => (
    <div className="bg-green-900/30 border border-green-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-green-400 rounded-full" />
        <span className="text-sm font-medium text-green-300">
          Tool Result: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-green-200">
        <strong>Result:</strong>{" "}
        <code className="bg-green-950/50 px-1 rounded">
          {JSON.stringify(annotation.value.result)}
        </code>
      </div>
    </div>
  );
  const renderError = (annotation: ErrorAnnotation) => (
    <div className="bg-red-900/30 border border-red-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-red-400 rounded-full" />
        <span className="text-sm font-medium text-red-300">Error</span>
      </div>
      <div className="mt-2 text-xs text-red-200">{annotation.value.error}</div>
    </div>
  );
  const renderAnnotations = (parts: UIMessage["parts"] = []) => {
    console.log(parts);
    return parts
      .map(formatPartAsAnnotation)
      .filter((annotation): annotation is MessageAnnotation => annotation !== null)
      .map((annotation, index) => {
        const key =
          annotation.type === "tool-call" || annotation.type === "tool-result"
            ? `${annotation.type}-${annotation.value.toolCallId || index}`
            : `${annotation.type}-${index}`;
        switch (annotation.type) {
          case "tool-call":
            return <div key={key}>{renderToolCall(annotation)}</div>;
          case "tool-result":
            return <div key={key}>{renderToolResult(annotation)}</div>;
          case "error":
            return <div key={key}>{renderError(annotation)}</div>;
          default:
            return null;
        }
      });
  };
  return (
    <div className="bg-[#1b1b1b] border-2 border-[#333333] rounded-xl shadow-xl overflow-hidden max-w-2xl mx-auto">
      <div className="bg-[#333333] p-6">
        <h2 className="text-white text-2xl font-bold">AI Calculator Chat</h2>
        <p className="text-gray-400 text-sm mt-1">Watch tool executions in real-time</p>
      </div>
      {/* Chat Messages */}
      <div ref={messagesContainerRef} className="p-6 max-h-96 overflow-y-auto">
        <div className="space-y-4">
          {messages.map((message) => (
            <div
              key={message.id}
              className={`flex ${message.role === "user" ? "justify-end" : "justify-start"}`}
            >
              <div
                className={`max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
                  message.role === "user"
                    ? "bg-[#333333] text-white"
                    : "bg-gray-800 text-gray-300 border border-gray-700"
                }`}
              >
                <div className="text-sm">
                  {message.role === "assistant" && (
                    <div className="flex items-center mb-1">
                      <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                      <span className="text-xs text-gray-400">AI Assistant</span>
                    </div>
                  )}
                  <div className="whitespace-pre-wrap">{message.content}</div>
                  {message.parts && renderAnnotations(message.parts)}
                </div>
              </div>
            </div>
          ))}
          {isLoading && (
            <div className="flex justify-start">
              <div className="bg-gray-800 text-gray-300 border border-gray-700 max-w-xs lg:max-w-md px-4 py-2 rounded-lg">
                <div className="flex items-center">
                  <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                  <span className="text-xs text-gray-400 mr-2">AI Assistant</span>
                  <div className="flex space-x-1">
                    <div className="w-2 h-2 bg-gray-500 rounded-full animate-bounce" />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.1s" }}
                    />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.2s" }}
                    />
                  </div>
                </div>
              </div>
            </div>
          )}
        </div>
      </div>
      {/* Input Form */}
      <div className="border-t border-gray-700 p-4">
        <form onSubmit={handleSubmit} className="flex space-x-2">
          <input
            value={input}
            onChange={handleInputChange}
            placeholder="Start typing your calculation... (e.g.: 25 + 17 * 3)"
            className="flex-1 px-4 py-3 bg-gray-800 border border-gray-700 text-white rounded-lg focus:ring-2 focus:ring-[#24f2ff] focus:border-[#24f2ff] transition-colors"
            disabled={isLoading}
          />
          <button
            type="submit"
            disabled={isLoading || !input.trim()}
            className="bg-[#333333] hover:bg-[#444444] focus:ring-4 focus:ring-[#333333]/50 text-white font-medium rounded-lg px-6 py-3 transition-all duration-200 ease-in-out focus:outline-none disabled:opacity-70 disabled:cursor-not-allowed"
          >
            {isLoading ? (
              <svg
                className="animate-spin h-4 w-4 text-white"
                xmlns="http://www.w3.org/2000/svg"
                fill="none"
                viewBox="0 0 24 24"
                aria-label="Loading"
              >
                <title>Loading spinner</title>
                <circle
                  className="opacity-25"
                  cx="12"
                  cy="12"
                  r="10"
                  stroke="currentColor"
                  strokeWidth="4"
                />
                <path
                  className="opacity-75"
                  fill="currentColor"
                  d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
                />
              </svg>
            ) : (
              "Send"
            )}
          </button>
        </form>
        <div className="mt-2 text-xs text-gray-500">
          <p>
            Tip: You can use expressions like "5 times 3 plus 10", "(20 + 5) divided by 5", "square
            root of 16"
          </p>
          <p className="text-blue-400">üí° Watch tool executions in real-time!</p>
        </div>
      </div>
    </div>
  );
}
</file>

<file path="app/components/comms-chat.tsx">
"use client";
import { useChat } from "@ai-sdk/react";
import type { StreamPart } from "@voltagent/core";
import type { UIMessage } from "ai";
import { useEffect, useRef } from "react";
interface ToolCallAnnotation {
  type: "tool-call";
  value: {
    toolCallId: string;
    toolName: string;
    args: any;
    status: "calling";
    subAgentName?: string;
  };
}
interface ToolResultAnnotation {
  type: "tool-result";
  value: {
    toolCallId: string;
    toolName: string;
    result: any;
    status: "completed";
    subAgentName?: string;
  };
}
interface ErrorAnnotation {
  type: "error";
  value: {
    error: string;
  };
}
type MessageAnnotation = ToolCallAnnotation | ToolResultAnnotation | ErrorAnnotation;
export function CommsChat() {
  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({
    api: "/api/chat",
    initialMessages: [
      {
        id: "welcome",
        role: "assistant",
        content:
          "Hello! I'm your AI-powered communication assistant. I can help with sending messages, managing team communications, scheduling meetings, and more. How can I assist you with your communication needs?",
      },
    ],
    body: {
      agentName: "comms"
    }
  });
  const messagesContainerRef = useRef<HTMLDivElement>(null);
  // Auto-scroll to bottom when messages change
  useEffect(() => {
    if (messagesContainerRef.current) {
      messagesContainerRef.current.scrollTop = messagesContainerRef.current.scrollHeight;
    }
  });
  const formatPartAsAnnotation = (part: UIMessage["parts"][number]): MessageAnnotation | null => {
    if (part.type === "tool-invocation") {
      if (part.toolInvocation.state === "result") {
        return {
          type: "tool-result",
          value: {
            toolCallId: part.toolInvocation.toolCallId,
            toolName: part.toolInvocation.toolName,
            result: part.toolInvocation.result,
            status: "completed",
            // @ts-expect-error - subAgentName is not typed
            subAgentName: part.toolInvocation.subAgentName,
          },
        };
      }
      return {
        type: "tool-call",
        value: {
          toolCallId: part.toolInvocation.toolCallId,
          toolName: part.toolInvocation.toolName,
          args: part.toolInvocation.args,
          status: "calling",
          // @ts-expect-error - subAgentName is not typed
          subAgentName: part.toolInvocation.subAgentName,
        },
      };
    }
    return null;
  };
  const renderToolCall = (annotation: ToolCallAnnotation) => (
    <div className="bg-blue-900/30 border border-blue-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-blue-400 rounded-full animate-pulse" />
        <span className="text-sm font-medium text-blue-300">
          Tool Call: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-blue-200">
        <strong>Arguments:</strong>{" "}
        <code className="bg-blue-950/50 px-1 rounded">{JSON.stringify(annotation.value.args)}</code>
      </div>
    </div>
  );
  const renderToolResult = (annotation: ToolResultAnnotation) => (
    <div className="bg-green-900/30 border border-green-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-green-400 rounded-full" />
        <span className="text-sm font-medium text-green-300">
          Tool Result: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-green-200">
        <strong>Result:</strong>{" "}
        <code className="bg-green-950/50 px-1 rounded">
          {JSON.stringify(annotation.value.result)}
        </code>
      </div>
    </div>
  );
  const renderError = (annotation: ErrorAnnotation) => (
    <div className="bg-red-900/30 border border-red-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-red-400 rounded-full" />
        <span className="text-sm font-medium text-red-300">Error</span>
      </div>
      <div className="mt-2 text-xs text-red-200">{annotation.value.error}</div>
    </div>
  );
  const renderAnnotations = (parts: UIMessage["parts"] = []) => {
    console.log(parts);
    return parts
      .map(formatPartAsAnnotation)
      .filter((annotation): annotation is MessageAnnotation => annotation !== null)
      .map((annotation, index) => {
        const key =
          annotation.type === "tool-call" || annotation.type === "tool-result"
            ? `${annotation.type}-${annotation.value.toolCallId || index}`
            : `${annotation.type}-${index}`;
        switch (annotation.type) {
          case "tool-call":
            return <div key={key}>{renderToolCall(annotation)}</div>;
          case "tool-result":
            return <div key={key}>{renderToolResult(annotation)}</div>;
          case "error":
            return <div key={key}>{renderError(annotation)}</div>;
          default:
            return null;
        }
      });
  };
  return (
    <div className="bg-[#1b1b1b] border-2 border-[#333333] rounded-xl shadow-xl overflow-hidden max-w-2xl mx-auto">
      <div className="bg-[#333333] p-6">
        <h2 className="text-white text-2xl font-bold">AI Communication Chat</h2>
        <p className="text-gray-400 text-sm mt-1">Manage team communications and notifications</p>
      </div>
      {/* Chat Messages */}
      <div ref={messagesContainerRef} className="p-6 max-h-96 overflow-y-auto">
        <div className="space-y-4">
          {messages.map((message) => (
            <div
              key={message.id}
              className={`flex ${message.role === "user" ? "justify-end" : "justify-start"}`}
            >
              <div
                className={`max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
                  message.role === "user"
                    ? "bg-[#333333] text-white"
                    : "bg-gray-800 text-gray-300 border border-gray-700"
                }`}
              >
                <div className="text-sm">
                  {message.role === "assistant" && (
                    <div className="flex items-center mb-1">
                      <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                      <span className="text-xs text-gray-400">AI Assistant</span>
                    </div>
                  )}
                  <div className="whitespace-pre-wrap">{message.content}</div>
                  {message.parts && renderAnnotations(message.parts)}
                </div>
              </div>
            </div>
          ))}
          {isLoading && (
            <div className="flex justify-start">
              <div className="bg-gray-800 text-gray-300 border border-gray-700 max-w-xs lg:max-w-md px-4 py-2 rounded-lg">
                <div className="flex items-center">
                  <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                  <span className="text-xs text-gray-400 mr-2">AI Assistant</span>
                  <div className="flex space-x-1">
                    <div className="w-2 h-2 bg-gray-500 rounded-full animate-bounce" />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.1s" }}
                    />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.2s" }}
                    />
                  </div>
                </div>
              </div>
            </div>
          )}
        </div>
      </div>
      {/* Input Form */}
      <div className="border-t border-gray-700 p-4">
        <form onSubmit={handleSubmit} className="flex space-x-2">
          <input
            value={input}
            onChange={handleInputChange}
            placeholder="Start typing your communication request... (e.g.: Send a message to the team on Slack)"
            className="flex-1 px-4 py-3 bg-gray-800 border border-gray-700 text-white rounded-lg focus:ring-2 focus:ring-[#24f2ff] focus:border-[#24f2ff] transition-colors"
            disabled={isLoading}
          />
          <button
            type="submit"
            disabled={isLoading || !input.trim()}
            className="bg-[#333333] hover:bg-[#444444] focus:ring-4 focus:ring-[#333333]/50 text-white font-medium rounded-lg px-6 py-3 transition-all duration-200 ease-in-out focus:outline-none disabled:opacity-70 disabled:cursor-not-allowed"
          >
            {isLoading ? (
              <svg
                className="animate-spin h-4 w-4 text-white"
                xmlns="http://www.w3.org/2000/svg"
                fill="none"
                viewBox="0 0 24 24"
                aria-label="Loading"
              >
                <title>Loading spinner</title>
                <circle
                  className="opacity-25"
                  cx="12"
                  cy="12"
                  r="10"
                  stroke="currentColor"
                  strokeWidth="4"
                />
                <path
                  className="opacity-75"
                  fill="currentColor"
                  d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
                />
              </svg>
            ) : (
              "Send"
            )}
          </button>
        </form>
        <div className="mt-2 text-xs text-gray-500">
          <p>
            Tip: You can request actions like "Send a Slack message to the dev channel", "Schedule a team meeting", or "Set up automated notifications"
          </p>
          <p className="text-blue-400">üí° Watch tool executions in real-time!</p>
        </div>
      </div>
    </div>
  );
}
</file>

<file path="app/components/data-chat.tsx">
"use client";
import { useChat } from "@ai-sdk/react";
import type { StreamPart } from "@voltagent/core";
import type { UIMessage } from "ai";
import { useEffect, useRef } from "react";
interface ToolCallAnnotation {
  type: "tool-call";
  value: {
    toolCallId: string;
    toolName: string;
    args: any;
    status: "calling";
    subAgentName?: string;
  };
}
interface ToolResultAnnotation {
  type: "tool-result";
  value: {
    toolCallId: string;
    toolName: string;
    result: any;
    status: "completed";
    subAgentName?: string;
  };
}
interface ErrorAnnotation {
  type: "error";
  value: {
    error: string;
  };
}
type MessageAnnotation = ToolCallAnnotation | ToolResultAnnotation | ErrorAnnotation;
export function DataChat() {
  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({
    api: "/api/chat",
    initialMessages: [
      {
        id: "welcome",
        role: "assistant",
        content:
          "Hello! I'm your AI-powered data management assistant. I can help with database operations, data analysis, and generating reports. How can I assist you with your data needs?",
      },
    ],
    body: {
      agentName: "data"
    }
  });
  const messagesContainerRef = useRef<HTMLDivElement>(null);
  // Auto-scroll to bottom when messages change
  useEffect(() => {
    if (messagesContainerRef.current) {
      messagesContainerRef.current.scrollTop = messagesContainerRef.current.scrollHeight;
    }
  });
  const formatPartAsAnnotation = (part: UIMessage["parts"][number]): MessageAnnotation | null => {
    if (part.type === "tool-invocation") {
      if (part.toolInvocation.state === "result") {
        return {
          type: "tool-result",
          value: {
            toolCallId: part.toolInvocation.toolCallId,
            toolName: part.toolInvocation.toolName,
            result: part.toolInvocation.result,
            status: "completed",
            // @ts-expect-error - subAgentName is not typed
            subAgentName: part.toolInvocation.subAgentName,
          },
        };
      }
      return {
        type: "tool-call",
        value: {
          toolCallId: part.toolInvocation.toolCallId,
          toolName: part.toolInvocation.toolName,
          args: part.toolInvocation.args,
          status: "calling",
          // @ts-expect-error - subAgentName is not typed
          subAgentName: part.toolInvocation.subAgentName,
        },
      };
    }
    return null;
  };
  const renderToolCall = (annotation: ToolCallAnnotation) => (
    <div className="bg-blue-900/30 border border-blue-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-blue-400 rounded-full animate-pulse" />
        <span className="text-sm font-medium text-blue-300">
          Tool Call: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-blue-200">
        <strong>Arguments:</strong>{" "}
        <code className="bg-blue-950/50 px-1 rounded">{JSON.stringify(annotation.value.args)}</code>
      </div>
    </div>
  );
  const renderToolResult = (annotation: ToolResultAnnotation) => (
    <div className="bg-green-900/30 border border-green-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-green-400 rounded-full" />
        <span className="text-sm font-medium text-green-300">
          Tool Result: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-green-200">
        <strong>Result:</strong>{" "}
        <code className="bg-green-950/50 px-1 rounded">
          {JSON.stringify(annotation.value.result)}
        </code>
      </div>
    </div>
  );
  const renderError = (annotation: ErrorAnnotation) => (
    <div className="bg-red-900/30 border border-red-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-red-400 rounded-full" />
        <span className="text-sm font-medium text-red-300">Error</span>
      </div>
      <div className="mt-2 text-xs text-red-200">{annotation.value.error}</div>
    </div>
  );
  const renderAnnotations = (parts: UIMessage["parts"] = []) => {
    console.log(parts);
    return parts
      .map(formatPartAsAnnotation)
      .filter((annotation): annotation is MessageAnnotation => annotation !== null)
      .map((annotation, index) => {
        const key =
          annotation.type === "tool-call" || annotation.type === "tool-result"
            ? `${annotation.type}-${annotation.value.toolCallId || index}`
            : `${annotation.type}-${index}`;
        switch (annotation.type) {
          case "tool-call":
            return <div key={key}>{renderToolCall(annotation)}</div>;
          case "tool-result":
            return <div key={key}>{renderToolResult(annotation)}</div>;
          case "error":
            return <div key={key}>{renderError(annotation)}</div>;
          default:
            return null;
        }
      });
  };
  return (
    <div className="bg-[#1b1b1b] border-2 border-[#333333] rounded-xl shadow-xl overflow-hidden max-w-2xl mx-auto">
      <div className="bg-[#333333] p-6">
        <h2 className="text-white text-2xl font-bold">AI Data Management Chat</h2>
        <p className="text-gray-400 text-sm mt-1">Analyze data and manage databases</p>
      </div>
      {/* Chat Messages */}
      <div ref={messagesContainerRef} className="p-6 max-h-96 overflow-y-auto">
        <div className="space-y-4">
          {messages.map((message) => (
            <div
              key={message.id}
              className={`flex ${message.role === "user" ? "justify-end" : "justify-start"}`}
            >
              <div
                className={`max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
                  message.role === "user"
                    ? "bg-[#333333] text-white"
                    : "bg-gray-800 text-gray-300 border border-gray-700"
                }`}
              >
                <div className="text-sm">
                  {message.role === "assistant" && (
                    <div className="flex items-center mb-1">
                      <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                      <span className="text-xs text-gray-400">AI Assistant</span>
                    </div>
                  )}
                  <div className="whitespace-pre-wrap">{message.content}</div>
                  {message.parts && renderAnnotations(message.parts)}
                </div>
              </div>
            </div>
          ))}
          {isLoading && (
            <div className="flex justify-start">
              <div className="bg-gray-800 text-gray-300 border border-gray-700 max-w-xs lg:max-w-md px-4 py-2 rounded-lg">
                <div className="flex items-center">
                  <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                  <span className="text-xs text-gray-400 mr-2">AI Assistant</span>
                  <div className="flex space-x-1">
                    <div className="w-2 h-2 bg-gray-500 rounded-full animate-bounce" />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.1s" }}
                    />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.2s" }}
                    />
                  </div>
                </div>
              </div>
            </div>
          )}
        </div>
      </div>
      {/* Input Form */}
      <div className="border-t border-gray-700 p-4">
        <form onSubmit={handleSubmit} className="flex space-x-2">
          <input
            value={input}
            onChange={handleInputChange}
            placeholder="Start typing your data request... (e.g.: Run a query on sales data)"
            className="flex-1 px-4 py-3 bg-gray-800 border border-gray-700 text-white rounded-lg focus:ring-2 focus:ring-[#24f2ff] focus:border-[#24f2ff] transition-colors"
            disabled={isLoading}
          />
          <button
            type="submit"
            disabled={isLoading || !input.trim()}
            className="bg-[#333333] hover:bg-[#444444] focus:ring-4 focus:ring-[#333333]/50 text-white font-medium rounded-lg px-6 py-3 transition-all duration-200 ease-in-out focus:outline-none disabled:opacity-70 disabled:cursor-not-allowed"
          >
            {isLoading ? (
              <svg
                className="animate-spin h-4 w-4 text-white"
                xmlns="http://www.w3.org/2000/svg"
                fill="none"
                viewBox="0 0 24 24"
                aria-label="Loading"
              >
                <title>Loading spinner</title>
                <circle
                  className="opacity-25"
                  cx="12"
                  cy="12"
                  r="10"
                  stroke="currentColor"
                  strokeWidth="4"
                />
                <path
                  className="opacity-75"
                  fill="currentColor"
                  d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
                />
              </svg>
            ) : (
              "Send"
            )}
          </button>
        </form>
        <div className="mt-2 text-xs text-gray-500">
          <p>
            Tip: You can request actions like "Execute a SQL query", "Analyze sales trends", or "Generate a data report"
          </p>
          <p className="text-blue-400">üí° Watch tool executions in real-time!</p>
        </div>
      </div>
    </div>
  );
}
</file>

<file path="app/components/dev-chat.tsx">
"use client";
import { useChat } from "@ai-sdk/react";
import type { StreamPart } from "@voltagent/core";
import type { UIMessage } from "ai";
import { useEffect, useRef } from "react";
interface ToolCallAnnotation {
  type: "tool-call";
  value: {
    toolCallId: string;
    toolName: string;
    args: any;
    status: "calling";
    subAgentName?: string;
  };
}
interface ToolResultAnnotation {
  type: "tool-result";
  value: {
    toolCallId: string;
    toolName: string;
    result: any;
    status: "completed";
    subAgentName?: string;
  };
}
interface ErrorAnnotation {
  type: "error";
  value: {
    error: string;
  };
}
type MessageAnnotation = ToolCallAnnotation | ToolResultAnnotation | ErrorAnnotation;
export function DevChat() {
  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({
    api: "/api/chat",
    initialMessages: [
      {
        id: "welcome",
        role: "assistant",
        content:
          "Hello! I'm your AI-powered development assistant. I can help with coding, version control, DevOps tasks, and debugging. How can I assist you with your development needs?",
      },
    ],
    body: {
      agentName: "dev"
    }
  });
  const messagesContainerRef = useRef<HTMLDivElement>(null);
  // Auto-scroll to bottom when messages change
  useEffect(() => {
    if (messagesContainerRef.current) {
      messagesContainerRef.current.scrollTop = messagesContainerRef.current.scrollHeight;
    }
  });
  const formatPartAsAnnotation = (part: UIMessage["parts"][number]): MessageAnnotation | null => {
    if (part.type === "tool-invocation") {
      if (part.toolInvocation.state === "result") {
        return {
          type: "tool-result",
          value: {
            toolCallId: part.toolInvocation.toolCallId,
            toolName: part.toolInvocation.toolName,
            result: part.toolInvocation.result,
            status: "completed",
            // @ts-expect-error - subAgentName is not typed
            subAgentName: part.toolInvocation.subAgentName,
          },
        };
      }
      return {
        type: "tool-call",
        value: {
          toolCallId: part.toolInvocation.toolCallId,
          toolName: part.toolInvocation.toolName,
          args: part.toolInvocation.args,
          status: "calling",
          // @ts-expect-error - subAgentName is not typed
          subAgentName: part.toolInvocation.subAgentName,
        },
      };
    }
    return null;
  };
  const renderToolCall = (annotation: ToolCallAnnotation) => (
    <div className="bg-blue-900/30 border border-blue-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-blue-400 rounded-full animate-pulse" />
        <span className="text-sm font-medium text-blue-300">
          Tool Call: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-blue-200">
        <strong>Arguments:</strong>{" "}
        <code className="bg-blue-950/50 px-1 rounded">{JSON.stringify(annotation.value.args)}</code>
      </div>
    </div>
  );
  const renderToolResult = (annotation: ToolResultAnnotation) => (
    <div className="bg-green-900/30 border border-green-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-green-400 rounded-full" />
        <span className="text-sm font-medium text-green-300">
          Tool Result: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-green-200">
        <strong>Result:</strong>{" "}
        <code className="bg-green-950/50 px-1 rounded">
          {JSON.stringify(annotation.value.result)}
        </code>
      </div>
    </div>
  );
  const renderError = (annotation: ErrorAnnotation) => (
    <div className="bg-red-900/30 border border-red-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-red-400 rounded-full" />
        <span className="text-sm font-medium text-red-300">Error</span>
      </div>
      <div className="mt-2 text-xs text-red-200">{annotation.value.error}</div>
    </div>
  );
  const renderAnnotations = (parts: UIMessage["parts"] = []) => {
    console.log(parts);
    return parts
      .map(formatPartAsAnnotation)
      .filter((annotation): annotation is MessageAnnotation => annotation !== null)
      .map((annotation, index) => {
        const key =
          annotation.type === "tool-call" || annotation.type === "tool-result"
            ? `${annotation.type}-${annotation.value.toolCallId || index}`
            : `${annotation.type}-${index}`;
        switch (annotation.type) {
          case "tool-call":
            return <div key={key}>{renderToolCall(annotation)}</div>;
          case "tool-result":
            return <div key={key}>{renderToolResult(annotation)}</div>;
          case "error":
            return <div key={key}>{renderError(annotation)}</div>;
          default:
            return null;
        }
      });
  };
  return (
    <div className="bg-[#1b1b1b] border-2 border-[#333333] rounded-xl shadow-xl overflow-hidden max-w-2xl mx-auto">
      <div className="bg-[#333333] p-6">
        <h2 className="text-white text-2xl font-bold">AI Development Chat</h2>
        <p className="text-gray-400 text-sm mt-1">Assist with coding and DevOps tasks</p>
      </div>
      {/* Chat Messages */}
      <div ref={messagesContainerRef} className="p-6 max-h-96 overflow-y-auto">
        <div className="space-y-4">
          {messages.map((message) => (
            <div
              key={message.id}
              className={`flex ${message.role === "user" ? "justify-end" : "justify-start"}`}
            >
              <div
                className={`max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
                  message.role === "user"
                    ? "bg-[#333333] text-white"
                    : "bg-gray-800 text-gray-300 border border-gray-700"
                }`}
              >
                <div className="text-sm">
                  {message.role === "assistant" && (
                    <div className="flex items-center mb-1">
                      <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                      <span className="text-xs text-gray-400">AI Assistant</span>
                    </div>
                  )}
                  <div className="whitespace-pre-wrap">{message.content}</div>
                  {message.parts && renderAnnotations(message.parts)}
                </div>
              </div>
            </div>
          ))}
          {isLoading && (
            <div className="flex justify-start">
              <div className="bg-gray-800 text-gray-300 border border-gray-700 max-w-xs lg:max-w-md px-4 py-2 rounded-lg">
                <div className="flex items-center">
                  <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                  <span className="text-xs text-gray-400 mr-2">AI Assistant</span>
                  <div className="flex space-x-1">
                    <div className="w-2 h-2 bg-gray-500 rounded-full animate-bounce" />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.1s" }}
                    />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.2s" }}
                    />
                  </div>
                </div>
              </div>
            </div>
          )}
        </div>
      </div>
      {/* Input Form */}
      <div className="border-t border-gray-700 p-4">
        <form onSubmit={handleSubmit} className="flex space-x-2">
          <input
            value={input}
            onChange={handleInputChange}
            placeholder="Start typing your development request... (e.g.: Help me debug this code)"
            className="flex-1 px-4 py-3 bg-gray-800 border border-gray-700 text-white rounded-lg focus:ring-2 focus:ring-[#24f2ff] focus:border-[#24f2ff] transition-colors"
            disabled={isLoading}
          />
          <button
            type="submit"
            disabled={isLoading || !input.trim()}
            className="bg-[#333333] hover:bg-[#444444] focus:ring-4 focus:ring-[#333333]/50 text-white font-medium rounded-lg px-6 py-3 transition-all duration-200 ease-in-out focus:outline-none disabled:opacity-70 disabled:cursor-not-allowed"
          >
            {isLoading ? (
              <svg
                className="animate-spin h-4 w-4 text-white"
                xmlns="http://www.w3.org/2000/svg"
                fill="none"
                viewBox="0 0 24 24"
                aria-label="Loading"
              >
                <title>Loading spinner</title>
                <circle
                  className="opacity-25"
                  cx="12"
                  cy="12"
                  r="10"
                  stroke="currentColor"
                  strokeWidth="4"
                />
                <path
                  className="opacity-75"
                  fill="currentColor"
                  d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
                />
              </svg>
            ) : (
              "Send"
            )}
          </button>
        </form>
        <div className="mt-2 text-xs text-gray-500">
          <p>
            Tip: You can request actions like "Commit changes to Git", "Review my code", or "Set up a Docker container"
          </p>
          <p className="text-blue-400">üí° Watch tool executions in real-time!</p>
        </div>
      </div>
    </div>
  );
}
</file>

<file path="app/components/file-chat.tsx">
"use client";
import { useChat } from "@ai-sdk/react";
import type { StreamPart } from "@voltagent/core";
import type { UIMessage } from "ai";
import { useEffect, useRef } from "react";
interface ToolCallAnnotation {
  type: "tool-call";
  value: {
    toolCallId: string;
    toolName: string;
    args: any;
    status: "calling";
    subAgentName?: string;
  };
}
interface ToolResultAnnotation {
  type: "tool-result";
  value: {
    toolCallId: string;
    toolName: string;
    result: any;
    status: "completed";
    subAgentName?: string;
  };
}
interface ErrorAnnotation {
  type: "error";
  value: {
    error: string;
  };
}
type MessageAnnotation = ToolCallAnnotation | ToolResultAnnotation | ErrorAnnotation;
export function FileChat() {
  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({
    api: "/api/chat",
    initialMessages: [
      {
        id: "welcome",
        role: "assistant",
        content:
          "Hello! I'm your AI-powered file management assistant. I can help with reading, writing, organizing files, and managing cloud storage. How can I assist you with your file needs?",
      },
    ],
    body: {
      agentName: "file"
    }
  });
  const messagesContainerRef = useRef<HTMLDivElement>(null);
  // Auto-scroll to bottom when messages change
  useEffect(() => {
    if (messagesContainerRef.current) {
      messagesContainerRef.current.scrollTop = messagesContainerRef.current.scrollHeight;
    }
  });
  const formatPartAsAnnotation = (part: UIMessage["parts"][number]): MessageAnnotation | null => {
    if (part.type === "tool-invocation") {
      if (part.toolInvocation.state === "result") {
        return {
          type: "tool-result",
          value: {
            toolCallId: part.toolInvocation.toolCallId,
            toolName: part.toolInvocation.toolName,
            result: part.toolInvocation.result,
            status: "completed",
            // @ts-expect-error - subAgentName is not typed
            subAgentName: part.toolInvocation.subAgentName,
          },
        };
      }
      return {
        type: "tool-call",
        value: {
          toolCallId: part.toolInvocation.toolCallId,
          toolName: part.toolInvocation.toolName,
          args: part.toolInvocation.args,
          status: "calling",
          // @ts-expect-error - subAgentName is not typed
          subAgentName: part.toolInvocation.subAgentName,
        },
      };
    }
    return null;
  };
  const renderToolCall = (annotation: ToolCallAnnotation) => (
    <div className="bg-blue-900/30 border border-blue-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-blue-400 rounded-full animate-pulse" />
        <span className="text-sm font-medium text-blue-300">
          Tool Call: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-blue-200">
        <strong>Arguments:</strong>{" "}
        <code className="bg-blue-950/50 px-1 rounded">{JSON.stringify(annotation.value.args)}</code>
      </div>
    </div>
  );
  const renderToolResult = (annotation: ToolResultAnnotation) => (
    <div className="bg-green-900/30 border border-green-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-green-400 rounded-full" />
        <span className="text-sm font-medium text-green-300">
          Tool Result: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-green-200">
        <strong>Result:</strong>{" "}
        <code className="bg-green-950/50 px-1 rounded">
          {JSON.stringify(annotation.value.result)}
        </code>
      </div>
    </div>
  );
  const renderError = (annotation: ErrorAnnotation) => (
    <div className="bg-red-900/30 border border-red-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-red-400 rounded-full" />
        <span className="text-sm font-medium text-red-300">Error</span>
      </div>
      <div className="mt-2 text-xs text-red-200">{annotation.value.error}</div>
    </div>
  );
  const renderAnnotations = (parts: UIMessage["parts"] = []) => {
    console.log(parts);
    return parts
      .map(formatPartAsAnnotation)
      .filter((annotation): annotation is MessageAnnotation => annotation !== null)
      .map((annotation, index) => {
        const key =
          annotation.type === "tool-call" || annotation.type === "tool-result"
            ? `${annotation.type}-${annotation.value.toolCallId || index}`
            : `${annotation.type}-${index}`;
        switch (annotation.type) {
          case "tool-call":
            return <div key={key}>{renderToolCall(annotation)}</div>;
          case "tool-result":
            return <div key={key}>{renderToolResult(annotation)}</div>;
          case "error":
            return <div key={key}>{renderError(annotation)}</div>;
          default:
            return null;
        }
      });
  };
  return (
    <div className="bg-[#1b1b1b] border-2 border-[#333333] rounded-xl shadow-xl overflow-hidden max-w-2xl mx-auto">
      <div className="bg-[#333333] p-6">
        <h2 className="text-white text-2xl font-bold">AI File Management Chat</h2>
        <p className="text-gray-400 text-sm mt-1">Manage files and cloud storage</p>
      </div>
      {/* Chat Messages */}
      <div ref={messagesContainerRef} className="p-6 max-h-96 overflow-y-auto">
        <div className="space-y-4">
          {messages.map((message) => (
            <div
              key={message.id}
              className={`flex ${message.role === "user" ? "justify-end" : "justify-start"}`}
            >
              <div
                className={`max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
                  message.role === "user"
                    ? "bg-[#333333] text-white"
                    : "bg-gray-800 text-gray-300 border border-gray-700"
                }`}
              >
                <div className="text-sm">
                  {message.role === "assistant" && (
                    <div className="flex items-center mb-1">
                      <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                      <span className="text-xs text-gray-400">AI Assistant</span>
                    </div>
                  )}
                  <div className="whitespace-pre-wrap">{message.content}</div>
                  {message.parts && renderAnnotations(message.parts)}
                </div>
              </div>
            </div>
          ))}
          {isLoading && (
            <div className="flex justify-start">
              <div className="bg-gray-800 text-gray-300 border border-gray-700 max-w-xs lg:max-w-md px-4 py-2 rounded-lg">
                <div className="flex items-center">
                  <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                  <span className="text-xs text-gray-400 mr-2">AI Assistant</span>
                  <div className="flex space-x-1">
                    <div className="w-2 h-2 bg-gray-500 rounded-full animate-bounce" />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.1s" }}
                    />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.2s" }}
                    />
                  </div>
                </div>
              </div>
            </div>
          )}
        </div>
      </div>
      {/* Input Form */}
      <div className="border-t border-gray-700 p-4">
        <form onSubmit={handleSubmit} className="flex space-x-2">
          <input
            value={input}
            onChange={handleInputChange}
            placeholder="Start typing your file management request... (e.g.: Upload a file to cloud storage)"
            className="flex-1 px-4 py-3 bg-gray-800 border border-gray-700 text-white rounded-lg focus:ring-2 focus:ring-[#24f2ff] focus:border-[#24f2ff] transition-colors"
            disabled={isLoading}
          />
          <button
            type="submit"
            disabled={isLoading || !input.trim()}
            className="bg-[#333333] hover:bg-[#444444] focus:ring-4 focus:ring-[#333333]/50 text-white font-medium rounded-lg px-6 py-3 transition-all duration-200 ease-in-out focus:outline-none disabled:opacity-70 disabled:cursor-not-allowed"
          >
            {isLoading ? (
              <svg
                className="animate-spin h-4 w-4 text-white"
                xmlns="http://www.w3.org/2000/svg"
                fill="none"
                viewBox="0 0 24 24"
                aria-label="Loading"
              >
                <title>Loading spinner</title>
                <circle
                  className="opacity-25"
                  cx="12"
                  cy="12"
                  r="10"
                  stroke="currentColor"
                  strokeWidth="4"
                />
                <path
                  className="opacity-75"
                  fill="currentColor"
                  d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
                />
              </svg>
            ) : (
              "Send"
            )}
          </button>
        </form>
        <div className="mt-2 text-xs text-gray-500">
          <p>
            Tip: You can request actions like "Read a file from my drive", "Organize my documents", or "Convert a file format"
          </p>
          <p className="text-blue-400">üí° Watch tool executions in real-time!</p>
        </div>
      </div>
    </div>
  );
}
</file>

<file path="app/components/memory-chat.tsx">
"use client";
import { useChat } from "@ai-sdk/react";
import type { StreamPart } from "@voltagent/core";
import type { UIMessage } from "ai";
import { useEffect, useRef } from "react";
interface ToolCallAnnotation {
  type: "tool-call";
  value: {
    toolCallId: string;
    toolName: string;
    args: any;
    status: "calling";
    subAgentName?: string;
  };
}
interface ToolResultAnnotation {
  type: "tool-result";
  value: {
    toolCallId: string;
    toolName: string;
    result: any;
    status: "completed";
    subAgentName?: string;
  };
}
interface ErrorAnnotation {
  type: "error";
  value: {
    error: string;
  };
}
type MessageAnnotation = ToolCallAnnotation | ToolResultAnnotation | ErrorAnnotation;
export function MemoryChat() {
  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({
    api: "/api/chat",
    initialMessages: [
      {
        id: "welcome",
        role: "assistant",
        content:
          "Hello! I'm your AI-powered knowledge management assistant. I can help with storing, retrieving, and organizing information. How can I assist you with your knowledge needs?",
      },
    ],
    body: {
      agentName: "memory"
    }
  });
  const messagesContainerRef = useRef<HTMLDivElement>(null);
  // Auto-scroll to bottom when messages change
  useEffect(() => {
    if (messagesContainerRef.current) {
      messagesContainerRef.current.scrollTop = messagesContainerRef.current.scrollHeight;
    }
  });
  const formatPartAsAnnotation = (part: UIMessage["parts"][number]): MessageAnnotation | null => {
    if (part.type === "tool-invocation") {
      if (part.toolInvocation.state === "result") {
        return {
          type: "tool-result",
          value: {
            toolCallId: part.toolInvocation.toolCallId,
            toolName: part.toolInvocation.toolName,
            result: part.toolInvocation.result,
            status: "completed",
            // @ts-expect-error - subAgentName is not typed
            subAgentName: part.toolInvocation.subAgentName,
          },
        };
      }
      return {
        type: "tool-call",
        value: {
          toolCallId: part.toolInvocation.toolCallId,
          toolName: part.toolInvocation.toolName,
          args: part.toolInvocation.args,
          status: "calling",
          // @ts-expect-error - subAgentName is not typed
          subAgentName: part.toolInvocation.subAgentName,
        },
      };
    }
    return null;
  };
  const renderToolCall = (annotation: ToolCallAnnotation) => (
    <div className="bg-blue-900/30 border border-blue-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-blue-400 rounded-full animate-pulse" />
        <span className="text-sm font-medium text-blue-300">
          Tool Call: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-blue-200">
        <strong>Arguments:</strong>{" "}
        <code className="bg-blue-950/50 px-1 rounded">{JSON.stringify(annotation.value.args)}</code>
      </div>
    </div>
  );
  const renderToolResult = (annotation: ToolResultAnnotation) => (
    <div className="bg-green-900/30 border border-green-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-green-400 rounded-full" />
        <span className="text-sm font-medium text-green-300">
          Tool Result: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-green-200">
        <strong>Result:</strong>{" "}
        <code className="bg-green-950/50 px-1 rounded">
          {JSON.stringify(annotation.value.result)}
        </code>
      </div>
    </div>
  );
  const renderError = (annotation: ErrorAnnotation) => (
    <div className="bg-red-900/30 border border-red-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-red-400 rounded-full" />
        <span className="text-sm font-medium text-red-300">Error</span>
      </div>
      <div className="mt-2 text-xs text-red-200">{annotation.value.error}</div>
    </div>
  );
  const renderAnnotations = (parts: UIMessage["parts"] = []) => {
    console.log(parts);
    return parts
      .map(formatPartAsAnnotation)
      .filter((annotation): annotation is MessageAnnotation => annotation !== null)
      .map((annotation, index) => {
        const key =
          annotation.type === "tool-call" || annotation.type === "tool-result"
            ? `${annotation.type}-${annotation.value.toolCallId || index}`
            : `${annotation.type}-${index}`;
        switch (annotation.type) {
          case "tool-call":
            return <div key={key}>{renderToolCall(annotation)}</div>;
          case "tool-result":
            return <div key={key}>{renderToolResult(annotation)}</div>;
          case "error":
            return <div key={key}>{renderError(annotation)}</div>;
          default:
            return null;
        }
      });
  };
  return (
    <div className="bg-[#1b1b1b] border-2 border-[#333333] rounded-xl shadow-xl overflow-hidden max-w-2xl mx-auto">
      <div className="bg-[#333333] p-6">
        <h2 className="text-white text-2xl font-bold">AI Knowledge Management Chat</h2>
        <p className="text-gray-400 text-sm mt-1">Store and retrieve information</p>
      </div>
      {/* Chat Messages */}
      <div ref={messagesContainerRef} className="p-6 max-h-96 overflow-y-auto">
        <div className="space-y-4">
          {messages.map((message) => (
            <div
              key={message.id}
              className={`flex ${message.role === "user" ? "justify-end" : "justify-start"}`}
            >
              <div
                className={`max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
                  message.role === "user"
                    ? "bg-[#333333] text-white"
                    : "bg-gray-800 text-gray-300 border border-gray-700"
                }`}
              >
                <div className="text-sm">
                  {message.role === "assistant" && (
                    <div className="flex items-center mb-1">
                      <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                      <span className="text-xs text-gray-400">AI Assistant</span>
                    </div>
                  )}
                  <div className="whitespace-pre-wrap">{message.content}</div>
                  {message.parts && renderAnnotations(message.parts)}
                </div>
              </div>
            </div>
          ))}
          {isLoading && (
            <div className="flex justify-start">
              <div className="bg-gray-800 text-gray-300 border border-gray-700 max-w-xs lg:max-w-md px-4 py-2 rounded-lg">
                <div className="flex items-center">
                  <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                  <span className="text-xs text-gray-400 mr-2">AI Assistant</span>
                  <div className="flex space-x-1">
                    <div className="w-2 h-2 bg-gray-500 rounded-full animate-bounce" />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.1s" }}
                    />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.2s" }}
                    />
                  </div>
                </div>
              </div>
            </div>
          )}
        </div>
      </div>
      {/* Input Form */}
      <div className="border-t border-gray-700 p-4">
        <form onSubmit={handleSubmit} className="flex space-x-2">
          <input
            value={input}
            onChange={handleInputChange}
            placeholder="Start typing your knowledge request... (e.g.: Store this information for later)"
            className="flex-1 px-4 py-3 bg-gray-800 border border-gray-700 text-white rounded-lg focus:ring-2 focus:ring-[#24f2ff] focus:border-[#24f2ff] transition-colors"
            disabled={isLoading}
          />
          <button
            type="submit"
            disabled={isLoading || !input.trim()}
            className="bg-[#333333] hover:bg-[#444444] focus:ring-4 focus:ring-[#333333]/50 text-white font-medium rounded-lg px-6 py-3 transition-all duration-200 ease-in-out focus:outline-none disabled:opacity-70 disabled:cursor-not-allowed"
          >
            {isLoading ? (
              <svg
                className="animate-spin h-4 w-4 text-white"
                xmlns="http://www.w3.org/2000/svg"
                fill="none"
                viewBox="0 0 24 24"
                aria-label="Loading"
              >
                <title>Loading spinner</title>
                <circle
                  className="opacity-25"
                  cx="12"
                  cy="12"
                  r="10"
                  stroke="currentColor"
                  strokeWidth="4"
                />
                <path
                  className="opacity-75"
                  fill="currentColor"
                  d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
                />
              </svg>
            ) : (
              "Send"
            )}
          </button>
        </form>
        <div className="mt-2 text-xs text-gray-500">
          <p>
            Tip: You can request actions like "Retrieve information about a topic", "Summarize past conversations", or "Organize my knowledge base"
          </p>
          <p className="text-blue-400">üí° Watch tool executions in real-time!</p>
        </div>
      </div>
    </div>
  );
}
</file>

<file path="app/components/navbar.tsx">
"use client";
import Link from "next/link";
import { usePathname } from "next/navigation";
export function Navbar() {
  const pathname = usePathname();
  const navItems = [
    { id: "supervisor", label: "Supervisor", href: "/" },
    { id: "math", label: "Calculator", href: "/calculator" },
    { id: "file", label: "File Manager", href: "/file" },
    { id: "web", label: "Web Research", href: "/web" },
    { id: "dev", label: "Developer", href: "/dev" },
    { id: "data", label: "Data Manager", href: "/data" },
    { id: "comms", label: "Communicator", href: "/comms" },
    { id: "memory", label: "Knowledge Keeper", href: "/memory" },
  ];
  return (
    <nav className="bg-[#333333] border-b border-gray-700">
      <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div className="flex justify-between h-16">
          <div className="flex">
            <div className="flex-shrink-0 flex items-center">
              <Link href="/" className="text-xl font-bold text-[#00d992]">
                VoltAgent
              </Link>
            </div>
            <div className="hidden sm:ml-6 sm:flex sm:space-x-8">
              {navItems.map((item) => (
                <Link
                  key={item.id}
                  href={item.href}
                  className={`inline-flex items-center px-1 pt-1 border-b-2 text-sm font-medium ${
                    pathname === item.href
                      ? "border-[#00d992] text-white"
                      : "border-transparent text-gray-300 hover:border-gray-500 hover:text-gray-100"
                  }`}
                >
                  {item.label}
                </Link>
              ))}
            </div>
          </div>
        </div>
      </div>
    </nav>
  );
}
</file>

<file path="app/components/supervisor-chat.tsx">
"use client";
import { useChat } from "@ai-sdk/react";
import type { StreamPart } from "@voltagent/core";
import type { UIMessage } from "ai";
import { useEffect, useRef } from "react";
interface ToolCallAnnotation {
  type: "tool-call";
  value: {
    toolCallId: string;
    toolName: string;
    args: any;
    status: "calling";
    subAgentName?: string;
  };
}
interface ToolResultAnnotation {
  type: "tool-result";
  value: {
    toolCallId: string;
    toolName: string;
    result: any;
    status: "completed";
    subAgentName?: string;
  };
}
interface ErrorAnnotation {
  type: "error";
  value: {
    error: string;
  };
}
type MessageAnnotation = ToolCallAnnotation | ToolResultAnnotation | ErrorAnnotation;
export function SupervisorChat() {
  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({
    api: "/api/chat",
    initialMessages: [
      {
        id: "welcome",
        role: "assistant",
        content:
          "Hello! I'm your AI-powered supervisor assistant. I can coordinate tasks across multiple specialized agents to help with complex workflows. How can I assist you today?",
      },
    ],
    body: {
      agentName: "supervisor"
    }
  });
  const messagesContainerRef = useRef<HTMLDivElement>(null);
  // Auto-scroll to bottom when messages change
  useEffect(() => {
    if (messagesContainerRef.current) {
      messagesContainerRef.current.scrollTop = messagesContainerRef.current.scrollHeight;
    }
  });
  const formatPartAsAnnotation = (part: UIMessage["parts"][number]): MessageAnnotation | null => {
    if (part.type === "tool-invocation") {
      if (part.toolInvocation.state === "result") {
        return {
          type: "tool-result",
          value: {
            toolCallId: part.toolInvocation.toolCallId,
            toolName: part.toolInvocation.toolName,
            result: part.toolInvocation.result,
            status: "completed",
            // @ts-expect-error - subAgentName is not typed
            subAgentName: part.toolInvocation.subAgentName,
          },
        };
      }
      return {
        type: "tool-call",
        value: {
          toolCallId: part.toolInvocation.toolCallId,
          toolName: part.toolInvocation.toolName,
          args: part.toolInvocation.args,
          status: "calling",
          // @ts-expect-error - subAgentName is not typed
          subAgentName: part.toolInvocation.subAgentName,
        },
      };
    }
    return null;
  };
  const renderToolCall = (annotation: ToolCallAnnotation) => (
    <div className="bg-blue-900/30 border border-blue-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-blue-400 rounded-full animate-pulse" />
        <span className="text-sm font-medium text-blue-300">
          Tool Call: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-blue-200">
        <strong>Arguments:</strong>{" "}
        <code className="bg-blue-950/50 px-1 rounded">{JSON.stringify(annotation.value.args)}</code>
      </div>
    </div>
  );
  const renderToolResult = (annotation: ToolResultAnnotation) => (
    <div className="bg-green-900/30 border border-green-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-green-400 rounded-full" />
        <span className="text-sm font-medium text-green-300">
          Tool Result: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-green-200">
        <strong>Result:</strong>{" "}
        <code className="bg-green-950/50 px-1 rounded">
          {JSON.stringify(annotation.value.result)}
        </code>
      </div>
    </div>
  );
  const renderError = (annotation: ErrorAnnotation) => (
    <div className="bg-red-900/30 border border-red-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-red-400 rounded-full" />
        <span className="text-sm font-medium text-red-300">Error</span>
      </div>
      <div className="mt-2 text-xs text-red-200">{annotation.value.error}</div>
    </div>
  );
  const renderAnnotations = (parts: UIMessage["parts"] = []) => {
    console.log(parts);
    return parts
      .map(formatPartAsAnnotation)
      .filter((annotation): annotation is MessageAnnotation => annotation !== null)
      .map((annotation, index) => {
        const key =
          annotation.type === "tool-call" || annotation.type === "tool-result"
            ? `${annotation.type}-${annotation.value.toolCallId || index}`
            : `${annotation.type}-${index}`;
        switch (annotation.type) {
          case "tool-call":
            return <div key={key}>{renderToolCall(annotation)}</div>;
          case "tool-result":
            return <div key={key}>{renderToolResult(annotation)}</div>;
          case "error":
            return <div key={key}>{renderError(annotation)}</div>;
          default:
            return null;
        }
      });
  };
  return (
    <div className="bg-[#1b1b1b] border-2 border-[#333333] rounded-xl shadow-xl overflow-hidden max-w-2xl mx-auto">
      <div className="bg-[#333333] p-6">
        <h2 className="text-white text-2xl font-bold">AI Supervisor Chat</h2>
        <p className="text-gray-400 text-sm mt-1">Coordinate tasks across multiple agents</p>
      </div>
      {/* Chat Messages */}
      <div ref={messagesContainerRef} className="p-6 max-h-96 overflow-y-auto">
        <div className="space-y-4">
          {messages.map((message) => (
            <div
              key={message.id}
              className={`flex ${message.role === "user" ? "justify-end" : "justify-start"}`}
            >
              <div
                className={`max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
                  message.role === "user"
                    ? "bg-[#333333] text-white"
                    : "bg-gray-800 text-gray-300 border border-gray-700"
                }`}
              >
                <div className="text-sm">
                  {message.role === "assistant" && (
                    <div className="flex items-center mb-1">
                      <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                      <span className="text-xs text-gray-400">AI Assistant</span>
                    </div>
                  )}
                  <div className="whitespace-pre-wrap">{message.content}</div>
                  {message.parts && renderAnnotations(message.parts)}
                </div>
              </div>
            </div>
          ))}
          {isLoading && (
            <div className="flex justify-start">
              <div className="bg-gray-800 text-gray-300 border border-gray-700 max-w-xs lg:max-w-md px-4 py-2 rounded-lg">
                <div className="flex items-center">
                  <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                  <span className="text-xs text-gray-400 mr-2">AI Assistant</span>
                  <div className="flex space-x-1">
                    <div className="w-2 h-2 bg-gray-500 rounded-full animate-bounce" />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.1s" }}
                    />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.2s" }}
                    />
                  </div>
                </div>
              </div>
            </div>
          )}
        </div>
      </div>
      {/* Input Form */}
      <div className="border-t border-gray-700 p-4">
        <form onSubmit={handleSubmit} className="flex space-x-2">
          <input
            value={input}
            onChange={handleInputChange}
            placeholder="Start typing your request... (e.g.: I need help with a complex task involving multiple areas)"
            className="flex-1 px-4 py-3 bg-gray-800 border border-gray-700 text-white rounded-lg focus:ring-2 focus:ring-[#24f2ff] focus:border-[#24f2ff] transition-colors"
            disabled={isLoading}
          />
          <button
            type="submit"
            disabled={isLoading || !input.trim()}
            className="bg-[#333333] hover:bg-[#444444] focus:ring-4 focus:ring-[#333333]/50 text-white font-medium rounded-lg px-6 py-3 transition-all duration-200 ease-in-out focus:outline-none disabled:opacity-70 disabled:cursor-not-allowed"
          >
            {isLoading ? (
              <svg
                className="animate-spin h-4 w-4 text-white"
                xmlns="http://www.w3.org/2000/svg"
                fill="none"
                viewBox="0 0 24 24"
                aria-label="Loading"
              >
                <title>Loading spinner</title>
                <circle
                  className="opacity-25"
                  cx="12"
                  cy="12"
                  r="10"
                  stroke="currentColor"
                  strokeWidth="4"
                />
                <path
                  className="opacity-75"
                  fill="currentColor"
                  d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
                />
              </svg>
            ) : (
              "Send"
            )}
          </button>
        </form>
        <div className="mt-2 text-xs text-gray-500">
          <p>
            Tip: You can request actions like "Coordinate a project plan", "Delegate tasks to appropriate agents", or "Help with a multi-step workflow"
          </p>
          <p className="text-blue-400">üí° Watch tool executions in real-time!</p>
        </div>
      </div>
    </div>
  );
}
</file>

<file path="app/components/web-chat.tsx">
"use client";
import { useChat } from "@ai-sdk/react";
import type { StreamPart } from "@voltagent/core";
import type { UIMessage } from "ai";
import { useEffect, useRef } from "react";
interface ToolCallAnnotation {
  type: "tool-call";
  value: {
    toolCallId: string;
    toolName: string;
    args: any;
    status: "calling";
    subAgentName?: string;
  };
}
interface ToolResultAnnotation {
  type: "tool-result";
  value: {
    toolCallId: string;
    toolName: string;
    result: any;
    status: "completed";
    subAgentName?: string;
  };
}
interface ErrorAnnotation {
  type: "error";
  value: {
    error: string;
  };
}
type MessageAnnotation = ToolCallAnnotation | ToolResultAnnotation | ErrorAnnotation;
export function WebChat() {
  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({
    api: "/api/chat",
    initialMessages: [
      {
        id: "welcome",
        role: "assistant",
        content:
          "Hello! I'm your AI-powered web research assistant. I can help with browsing websites, searching for information, and conducting online research. How can I assist you with your web needs?",
      },
    ],
    body: {
      agentName: "web"
    }
  });
  const messagesContainerRef = useRef<HTMLDivElement>(null);
  // Auto-scroll to bottom when messages change
  useEffect(() => {
    if (messagesContainerRef.current) {
      messagesContainerRef.current.scrollTop = messagesContainerRef.current.scrollHeight;
    }
  });
  const formatPartAsAnnotation = (part: UIMessage["parts"][number]): MessageAnnotation | null => {
    if (part.type === "tool-invocation") {
      if (part.toolInvocation.state === "result") {
        return {
          type: "tool-result",
          value: {
            toolCallId: part.toolInvocation.toolCallId,
            toolName: part.toolInvocation.toolName,
            result: part.toolInvocation.result,
            status: "completed",
            // @ts-expect-error - subAgentName is not typed
            subAgentName: part.toolInvocation.subAgentName,
          },
        };
      }
      return {
        type: "tool-call",
        value: {
          toolCallId: part.toolInvocation.toolCallId,
          toolName: part.toolInvocation.toolName,
          args: part.toolInvocation.args,
          status: "calling",
          // @ts-expect-error - subAgentName is not typed
          subAgentName: part.toolInvocation.subAgentName,
        },
      };
    }
    return null;
  };
  const renderToolCall = (annotation: ToolCallAnnotation) => (
    <div className="bg-blue-900/30 border border-blue-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-blue-400 rounded-full animate-pulse" />
        <span className="text-sm font-medium text-blue-300">
          Tool Call: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-blue-200">
        <strong>Arguments:</strong>{" "}
        <code className="bg-blue-950/50 px-1 rounded">{JSON.stringify(annotation.value.args)}</code>
      </div>
    </div>
  );
  const renderToolResult = (annotation: ToolResultAnnotation) => (
    <div className="bg-green-900/30 border border-green-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-green-400 rounded-full" />
        <span className="text-sm font-medium text-green-300">
          Tool Result: {annotation.value.toolName}{" "}
          {annotation.value.subAgentName ? `(Sub-Agent: ${annotation.value.subAgentName})` : ""}
        </span>
      </div>
      <div className="mt-2 text-xs text-green-200">
        <strong>Result:</strong>{" "}
        <code className="bg-green-950/50 px-1 rounded">
          {JSON.stringify(annotation.value.result)}
        </code>
      </div>
    </div>
  );
  const renderError = (annotation: ErrorAnnotation) => (
    <div className="bg-red-900/30 border border-red-700/50 rounded-lg p-3 my-2">
      <div className="flex items-center space-x-2">
        <div className="w-3 h-3 bg-red-400 rounded-full" />
        <span className="text-sm font-medium text-red-300">Error</span>
      </div>
      <div className="mt-2 text-xs text-red-200">{annotation.value.error}</div>
    </div>
  );
  const renderAnnotations = (parts: UIMessage["parts"] = []) => {
    console.log(parts);
    return parts
      .map(formatPartAsAnnotation)
      .filter((annotation): annotation is MessageAnnotation => annotation !== null)
      .map((annotation, index) => {
        const key =
          annotation.type === "tool-call" || annotation.type === "tool-result"
            ? `${annotation.type}-${annotation.value.toolCallId || index}`
            : `${annotation.type}-${index}`;
        switch (annotation.type) {
          case "tool-call":
            return <div key={key}>{renderToolCall(annotation)}</div>;
          case "tool-result":
            return <div key={key}>{renderToolResult(annotation)}</div>;
          case "error":
            return <div key={key}>{renderError(annotation)}</div>;
          default:
            return null;
        }
      });
  };
  return (
    <div className="bg-[#1b1b1b] border-2 border-[#333333] rounded-xl shadow-xl overflow-hidden max-w-2xl mx-auto">
      <div className="bg-[#333333] p-6">
        <h2 className="text-white text-2xl font-bold">AI Web Research Chat</h2>
        <p className="text-gray-400 text-sm mt-1">Browse websites and conduct online research</p>
      </div>
      {/* Chat Messages */}
      <div ref={messagesContainerRef} className="p-6 max-h-96 overflow-y-auto">
        <div className="space-y-4">
          {messages.map((message) => (
            <div
              key={message.id}
              className={`flex ${message.role === "user" ? "justify-end" : "justify-start"}`}
            >
              <div
                className={`max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
                  message.role === "user"
                    ? "bg-[#333333] text-white"
                    : "bg-gray-800 text-gray-300 border border-gray-700"
                }`}
              >
                <div className="text-sm">
                  {message.role === "assistant" && (
                    <div className="flex items-center mb-1">
                      <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                      <span className="text-xs text-gray-400">AI Assistant</span>
                    </div>
                  )}
                  <div className="whitespace-pre-wrap">{message.content}</div>
                  {message.parts && renderAnnotations(message.parts)}
                </div>
              </div>
            </div>
          ))}
          {isLoading && (
            <div className="flex justify-start">
              <div className="bg-gray-800 text-gray-300 border border-gray-700 max-w-xs lg:max-w-md px-4 py-2 rounded-lg">
                <div className="flex items-center">
                  <div className="w-2 h-2 bg-[#24f2ff] rounded-full mr-2" />
                  <span className="text-xs text-gray-400 mr-2">AI Assistant</span>
                  <div className="flex space-x-1">
                    <div className="w-2 h-2 bg-gray-500 rounded-full animate-bounce" />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.1s" }}
                    />
                    <div
                      className="w-2 h-2 bg-gray-500 rounded-full animate-bounce"
                      style={{ animationDelay: "0.2s" }}
                    />
                  </div>
                </div>
              </div>
            </div>
          )}
        </div>
      </div>
      {/* Input Form */}
      <div className="border-t border-gray-700 p-4">
        <form onSubmit={handleSubmit} className="flex space-x-2">
          <input
            value={input}
            onChange={handleInputChange}
            placeholder="Start typing your web research request... (e.g.: Search for the latest news on AI)"
            className="flex-1 px-4 py-3 bg-gray-800 border border-gray-700 text-white rounded-lg focus:ring-2 focus:ring-[#24f2ff] focus:border-[#24f2ff] transition-colors"
            disabled={isLoading}
          />
          <button
            type="submit"
            disabled={isLoading || !input.trim()}
            className="bg-[#333333] hover:bg-[#444444] focus:ring-4 focus:ring-[#333333]/50 text-white font-medium rounded-lg px-6 py-3 transition-all duration-200 ease-in-out focus:outline-none disabled:opacity-70 disabled:cursor-not-allowed"
          >
            {isLoading ? (
              <svg
                className="animate-spin h-4 w-4 text-white"
                xmlns="http://www.w3.org/2000/svg"
                fill="none"
                viewBox="0 0 24 24"
                aria-label="Loading"
              >
                <title>Loading spinner</title>
                <circle
                  className="opacity-25"
                  cx="12"
                  cy="12"
                  r="10"
                  stroke="currentColor"
                  strokeWidth="4"
                />
                <path
                  className="opacity-75"
                  fill="currentColor"
                  d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
                />
              </svg>
            ) : (
              "Send"
            )}
          </button>
        </form>
        <div className="mt-2 text-xs text-gray-500">
          <p>
            Tip: You can request actions like "Find information on a topic", "Browse a specific website", or "Conduct market research"
          </p>
          <p className="text-blue-400">üí° Watch tool executions in real-time!</p>
        </div>
      </div>
    </div>
  );
}
</file>

<file path="app/dev/page.tsx">
import { Navbar } from "../components/navbar";
import { DevChat } from "../components/dev-chat";
export default function DevPage() {
  return (
    <div className="relative min-h-screen bg-[#1b1b1b] flex flex-col p-4 overflow-hidden">
      {/* Dot pattern background */}
      <div className="absolute inset-0 opacity-10">
        <div
          className="absolute inset-0"
          style={{
            backgroundImage: "radial-gradient(#94a3b8 1.2px, transparent 0)",
            backgroundSize: "20px 20px",
          }}
        />
      </div>
      <Navbar />
      <main className="relative w-full max-w-2xl mx-auto mt-6 z-10">
        <div className="mb-8 text-center">
          <h1 className="text-3xl font-bold text-[#00d992] mb-1">VoltAgent Developer</h1>
          <p className="text-gray-400">AI-powered software development and DevOps</p>
        </div>
        <DevChat />
        <div className="mt-8 text-center text-sm text-gray-500">
          <p>Built with Next.js and VoltAgent</p>
        </div>
      </main>
    </div>
  );
}
</file>

<file path="app/file/page.tsx">
import { Navbar } from "../components/navbar";
import { FileChat } from "../components/file-chat";
export default function FilePage() {
  return (
    <div className="relative min-h-screen bg-[#1b1b1b] flex flex-col p-4 overflow-hidden">
      {/* Dot pattern background */}
      <div className="absolute inset-0 opacity-10">
        <div
          className="absolute inset-0"
          style={{
            backgroundImage: "radial-gradient(#94a3b8 1.2px, transparent 0)",
            backgroundSize: "20px 20px",
          }}
        />
      </div>
      <Navbar />
      <main className="relative w-full max-w-2xl mx-auto mt-6 z-10">
        <div className="mb-8 text-center">
          <h1 className="text-3xl font-bold text-[#00d992] mb-1">VoltAgent File Manager</h1>
          <p className="text-gray-400">AI-powered file operations and management</p>
        </div>
        <FileChat />
        <div className="mt-8 text-center text-sm text-gray-500">
          <p>Built with Next.js and VoltAgent</p>
        </div>
      </main>
    </div>
  );
}
</file>

<file path="app/GEMINI.md">
# Gemini Workspace: app

This document provides context and best practices for working within the `app` directory, which contains the Next.js frontend for the `voltagent` system.

## Core Architecture

The `app` directory is a standard Next.js application with the App Router. It is responsible for providing the user interface and interacting with the `voltagent` backend.

1.  **API Route (`app/api/chat/route.ts`):** This is the single entry point for all communication between the frontend and the `voltagent` system. It receives user messages, passes them to the `supervisorAgent`, and streams the response back to the client.

2.  **Pages (`app/**/*.page.tsx`):** Each page (e.g., `/calculator`, `/dev`, `/file`) corresponds to a specific agent interface. These pages are responsible for rendering the chat UI for their respective agent.

3.  **Chat Components (`app/components/*-chat.tsx`):** The core of the user interface is a set of specialized chat components (e.g., `calculator-chat.tsx`, `dev-chat.tsx`). Each of these components is tailored to a specific agent and handles the user input and message display for that agent's chat interface.

4.  **Shared Components (`app/components/navbar.tsx`):** The `navbar.tsx` component provides consistent navigation across all pages.

5.  **Layout (`app/layout.tsx`):** This is the root layout for the entire application. It sets up the main HTML structure and includes the `navbar`.

## Design Patterns & Best Practices

This section outlines the key design patterns used in the `app` and the best practices to follow during development.

### Core Design Patterns

-   **API Gateway Pattern:** The `app/api/chat/route.ts` file acts as a single API Gateway for the entire frontend. All requests to the AI backend are routed through this single endpoint, which simplifies security, logging, and request handling.
-   **Component-Based Architecture:** The UI is built using a standard React component model. This promotes reusability and a clear separation of concerns. The `app/components/` directory contains all the reusable UI components.
-   **Container/Presentational Pattern:** The page files (`app/**/*.page.tsx`) act as **Container Components**. They are responsible for fetching data and managing state. The chat components (`app/components/*-chat.tsx`) are **Presentational Components**. They are responsible for rendering the UI and passing user events up to the container.

### Best Practices

-   **One Page Per Agent:** Each specialized agent in the `voltagent` system should have its own corresponding page in the `app` directory. For example, if you create a new `emailAgent`, you should also create an `app/email/page.tsx`.
-   **Create Dedicated Chat Components:** For each new agent page, create a dedicated chat component in `app/components/`. For an `emailAgent`, this would be `email-chat.tsx`. This component will contain the logic for interacting with that specific agent via the API.
-   **Use the API Route for Communication:** All communication with the `voltagent` system must go through the `/api/chat` endpoint. Do not attempt to import or call the `voltagent` code directly from the frontend components.
-   **Keep Pages Simple:** The main page components (`*.page.tsx`) should be kept as simple as possible. Their primary responsibility is to render the correct chat component.
-   **Style with `globals.css`:** Use the existing `globals.css` file for any new global styles. For component-specific styles, consider using CSS Modules or a similar solution if the complexity warrants it.
-   **Update the Navbar:** When adding a new page, be sure to add a corresponding link to the `navbar.tsx` component to make it accessible to users.

## Common Anti-Patterns to Avoid

-   **Fat Pages:** Avoid putting all of your logic directly into the page components. Pages should be responsible for layout and data fetching, while the actual UI and interaction logic should be encapsulated in the `components`.
-   **Direct Backend Communication:** Never import or call the `voltagent` code directly from a frontend component. This creates a tight coupling between the frontend and backend and makes the system much harder to maintain. Always use the `/api/chat` route.
-   **State in Presentational Components:** Avoid storing complex state in your presentational components (`*-chat.tsx`). State should be managed by the container components (`*.page.tsx`) and passed down as props.
-   **Inconsistent UI:** When creating new pages and components, be sure to reuse the existing components in `app/components/` as much as possible to maintain a consistent look and feel.
</file>

<file path="app/globals.css">
@import "tailwindcss";
</file>

<file path="app/layout.tsx">
import type { Metadata } from "next";
import { Geist, Geist_Mono } from "next/font/google";
import "./globals.css";
const geistSans = Geist({
  variable: "--font-geist-sans",
  subsets: ["latin"],
});
const geistMono = Geist_Mono({
  variable: "--font-geist-mono",
  subsets: ["latin"],
});
export const metadata: Metadata = {
  title: "VoltAgent Calculator",
  description: "AI-powered calculation made simple",
  icons: {
    icon: "/favicon.ico",
  },
};
export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body className={`${geistSans.variable} ${geistMono.variable}`}>{children}</body>
    </html>
  );
}
</file>

<file path="app/web/page.tsx">
import { Navbar } from "../components/navbar";
import { WebChat } from "../components/web-chat";
export default function WebPage() {
  return (
    <div className="relative min-h-screen bg-[#1b1b1b] flex flex-col p-4 overflow-hidden">
      {/* Dot pattern background */}
      <div className="absolute inset-0 opacity-10">
        <div
          className="absolute inset-0"
          style={{
            backgroundImage: "radial-gradient(#94a3b8 1.2px, transparent 0)",
            backgroundSize: "20px 20px",
          }}
        />
      </div>
      <Navbar />
      <main className="relative w-full max-w-2xl mx-auto mt-6 z-10">
        <div className="mb-8 text-center">
          <h1 className="text-3xl font-bold text-[#00d992] mb-1">VoltAgent Web Research</h1>
          <p className="text-gray-400">AI-powered web browsing and research</p>
        </div>
        <WebChat />
        <div className="mt-8 text-center text-sm text-gray-500">
          <p>Built with Next.js and VoltAgent</p>
        </div>
      </main>
    </div>
  );
}
</file>

<file path="eslint.config.js">
// @ts-check
import eslint from '@eslint/js';
import tseslint from 'typescript-eslint';
import nextPlugin from '@next/eslint-plugin-next';
export default [
  {
    ignores: ['.next/', 'node_modules/', 'dist/', '.mastra/']
  },
  {
    languageOptions: {
      parser: tseslint.parser,
      parserOptions: {
        project: './tsconfig.json',
      },
    },
  },
  ...tseslint.configs.recommended,
  eslint.configs.recommended,
  {
    plugins: {
      '@next/next': nextPlugin,
    },
    rules: {
      '@next/next/no-html-link-for-pages': 'off',
      '@typescript-eslint/no-unused-vars': 'warn',
      '@typescript-eslint/no-explicit-any': 'warn',
    },
  }
];
</file>

<file path="log.txt">
{
  "message": "'system messages are only supported at the beginning of the conversation' functionality not supported.",
  "stage": "llm_stream",
  "originalError": "AI_UnsupportedFunctionalityError: 'system messages are only supported at the beginning of the conversation' functionality not supported."
}
</file>

<file path="next-eslint-plugin-next.d.ts">
declare module '@next/eslint-plugin-next';
</file>

<file path="postcss.config.mjs">
const config = {
    plugins: {
      "@tailwindcss/postcss": {},
    },
  };
  export default config;
</file>

<file path="README.md">
# üöÄ DeanMachines VoltAgent AI System

<div align="center">

**ü§ñ Professional Multi-Agent AI System Built with VoltAgent & Google Gemini**

*A modular, production-ready AI agent orchestration platform featuring specialized sub-agents, MCP integration, and real-time collaboration capabilities.*

</div>

---

<div align="center">

[![VoltAgent](https://img.shields.io/badge/VoltAgent-Core-blue?style=for-the-badge&logo=typescript)](https://voltagent.dev)
[![Google AI](https://img.shields.io/badge/Google-Gemini%202.5-4285F4?style=for-the-badge&logo=google)](https://ai.google.dev)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-3178C6?style=for-the-badge&logo=typescript)](https://typescriptlang.org)
[![Next.js](https://img.shields.io/badge/Next.js-15+-000000?style=for-the-badge&logo=nextdotjs)](https://nextjs.org)

[![Build Status](https://img.shields.io/badge/build-passing-brightgreen?style=flat-square)](https://github.com)
[![License](https://img.shields.io/badge/license-MIT-blue?style=flat-square)](LICENSE)
[![Node Version](https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen?style=flat-square)](https://nodejs.org)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen?style=flat-square)](CONTRIBUTING.md)

</div>

## üìã Table of Contents

- [üéØ Overview](#-overview)
- [‚ú® Features](#-features)
- [üèóÔ∏è Architecture](#Ô∏è-architecture)
- [üöÄ Quick Start](#-quick-start)
- [üì¶ Installation](#-installation)
- [‚öôÔ∏è Configuration](#Ô∏è-configuration)
- [ü§ñ Agents](#-agents)
- [üõ†Ô∏è Usage](#Ô∏è-usage)
- [üìö API Documentation](#-api-documentation)
- [üîß Development](#-development)
- [üß™ Testing](#-testing)
- [üìà Monitoring](#-monitoring)
- [üîí Security](#-security)
- [ü§ù Contributing](#-contributing)
- [üìÑ License](#-license)

## üéØ Overview

DeanMachines VoltAgent is a cutting-edge AI agent orchestration system that leverages the power of Google's Gemini 2.5 Flash Lite models through the VoltAgent framework. Built with modern TypeScript and Next.js, it provides a robust foundation for creating, managing, and scaling AI-powered applications.

### üé™ Live Demo
- **Backend API**: [http://localhost:3141](http://localhost:3141)
- **Swagger UI**: [http://localhost:3141/ui](http://localhost:3141/ui)
- **Frontend**: [http://localhost:3000](http://localhost:3000)
- **VoltOps Dashboard**: [https://console.voltagent.dev](https://console.voltagent.dev)

## ‚ú® Features

### üß† **Intelligent Agent System**
- **8 Specialized Sub-Agents** - Domain-specific AI agents for different tasks
- **Supervisor Orchestration** - Intelligent delegation and coordination
- **Memory & Context** - Persistent memory with advanced retrieval
- **MCP Integration** - Model Context Protocol for enhanced capabilities

### üîß **Technical Excellence**
- **Google Gemini 2.5** - Latest AI models with flash-lite performance
- **TypeScript First** - Full type safety and modern development
- **Modular Architecture** - Clean, maintainable, and scalable design
- **Production Ready** - Telemetry, monitoring, and error handling

### üåê **Integration Ready**
- **Next.js Frontend** - Modern React-based user interface
- **RESTful API** - Well-documented endpoints with Swagger
- **MCP Tools** - GitHub, GitLab, Brave Search, PostgreSQL, and more
- **Real-time Logging** - Comprehensive observability

## üèóÔ∏è Architecture

```mermaid
graph TB
    A[üë§ User] --> B[üåê Next.js Frontend]
    A --> C[üîå REST API]
    
    B --> C
    C --> D[üéØ Supervisor Agent]
    
    D --> E[üìä Math Agent]
    D --> F[üìÅ File Agent]
    D --> G[üåç Web Agent]
    D --> H[‚ö° Dev Agent]
    D --> I[üìà Data Agent]
    D --> J[üí¨ Comms Agent]
    D --> K[üß† Memory Agent]
    
    E --> L[ü§ñ Google Gemini 2.5]
    F --> L
    G --> L
    H --> L
    I --> L
    J --> L
    K --> L
    
    M[üîß MCP Tools] --> E
    M --> F
    M --> G
    M --> H
    M --> I
    M --> J
    M --> K
    
    N[üíæ Memory Service] --> D
    O[üîç Retriever Service] --> D
    P[üìä Telemetry] --> Q[‚òÅÔ∏è VoltOps Cloud]
```

## üöÄ Quick Start

### Prerequisites
- **Node.js** 18.0.0 or higher
- **npm** or **yarn** package manager
- **Google AI API Key** ([Get one here](https://aistudio.google.com/app/apikey))
- **VoltAgent Account** ([Sign up here](https://console.voltagent.dev))

### 1-Minute Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/deanmachines-volt.git
cd deanmachines-volt

# Install dependencies
npm install

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys

# Start the development servers
npm run dev          # Full stack (Next.js + VoltAgent)
npm run dev:backend  # Backend only
npm run dev:frontend # Frontend only
```

## üì¶ Installation

### Full Installation

```bash
# Clone and navigate
git clone https://github.com/yourusername/deanmachines-volt.git
cd deanmachines-volt

# Install all dependencies
npm install

# Build the project
npm run build
```

### Backend Only

```bash
# Install backend dependencies
npm install

# Run backend development server
npm run dev:voltagent
```

### Docker Setup

```bash
# Build and run with Docker
docker-compose up --build

# Or use individual services
docker-compose up voltagent  # Backend only
docker-compose up frontend   # Frontend only
```

## ‚öôÔ∏è Configuration

### Environment Variables

Create a `.env` file in the root directory:

```env
# Google AI Configuration
GOOGLE_GENERATIVE_AI_API_KEY=your_google_ai_api_key_here

# VoltAgent Cloud (Optional)
PK=your_voltagent_public_key
SK=your_voltagent_secret_key

# MCP Services (Optional)
GITHUB_TOKEN=your_github_token
GITLAB_TOKEN=your_gitlab_token
BRAVE_API_KEY=your_brave_search_api_key
DATABASE_URL=your_postgresql_connection_string
GOOGLE_APPLICATION_CREDENTIALS=path/to/service-account.json
SLACK_BOT_TOKEN=your_slack_bot_token

# Application
NODE_ENV=development
PORT=3141
NEXT_PUBLIC_API_URL=http://localhost:3141
```

### Agent Configuration

Each agent can be customized through their respective configuration files:

```typescript
// voltagent/config/googleProvider.ts
export const googleProvider = createGoogleProvider({
  apiKey: process.env.GOOGLE_GENERATIVE_AI_API_KEY!,
  defaultModel: "gemini-2.5-flash-lite-preview-06-17",
  // Additional configuration...
});
```

## ü§ñ Agents

### üéØ Supervisor Agent
**Role**: Orchestrates and delegates tasks to specialized sub-agents
- **Capabilities**: Task routing, agent coordination, response synthesis
- **Model**: Gemini 2.5 Flash Lite
- **Tools**: All sub-agent capabilities

### üìä Math Agent
**Role**: Mathematical computations and data analysis
- **Capabilities**: Calculations, statistical analysis, data visualization
- **Tools**: Calculator, chart generation, numerical analysis
- **Use Cases**: Financial modeling, scientific calculations

### üìÅ File Agent
**Role**: File system operations and document management
- **Capabilities**: File CRUD, content analysis, format conversion
- **Tools**: Filesystem MCP, document parsers
- **Use Cases**: Document processing, file organization

### üåç Web Agent
**Role**: Web scraping and online research
- **Capabilities**: Web search, content extraction, API interactions
- **Tools**: Brave Search, web scraping, HTTP clients
- **Use Cases**: Research, data collection, monitoring

### ‚ö° Dev Agent
**Role**: Software development assistance
- **Capabilities**: Code analysis, debugging, deployment
- **Tools**: GitHub/GitLab MCP, code analysis
- **Use Cases**: Code review, CI/CD, documentation

### üìà Data Agent
**Role**: Database operations and data processing
- **Capabilities**: Query execution, data transformation, reporting
- **Tools**: PostgreSQL MCP, data visualization
- **Use Cases**: Analytics, reporting, data migration

### üí¨ Comms Agent
**Role**: Communication and notification management
- **Capabilities**: Message sending, alert management, collaboration
- **Tools**: Slack MCP, email services
- **Use Cases**: Team collaboration, notifications

### üß† Memory Agent
**Role**: Knowledge management and retrieval
- **Capabilities**: Memory storage, context retrieval, knowledge graphs
- **Tools**: Vector databases, memory services
- **Use Cases**: Long-term memory, context management

## üõ†Ô∏è Usage

### Basic Agent Interaction

```typescript
import { VoltAgent } from '@voltagent/core';

// Initialize the system
const volt = new VoltAgent({
  agents: {
    supervisor: supervisorAgent,
    math: mathAgent,
    // ... other agents
  }
});

// Make a request
const response = await volt.invoke('supervisor', {
  message: "Calculate the ROI for a $10,000 investment with 8% annual return over 5 years"
});
```

### REST API Usage

```bash
# Health Check
curl http://localhost:3141/health

# Chat with Supervisor Agent
curl -X POST http://localhost:3141/agents/supervisor/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Help me analyze this data"}'

# Direct Agent Access
curl -X POST http://localhost:3141/agents/math/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Calculate compound interest for $1000 at 5% for 10 years"}'
```

### Frontend Integration

```typescript
// React component example
import { useState } from 'react';

export function ChatInterface() {
  const [message, setMessage] = useState('');
  const [response, setResponse] = useState('');

  const sendMessage = async () => {
    const res = await fetch('/api/chat', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ message, agent: 'supervisor' })
    });
    const data = await res.json();
    setResponse(data.response);
  };

  return (
    <div>
      <input 
        value={message} 
        onChange={(e) => setMessage(e.target.value)}
        placeholder="Ask the AI agents anything..."
      />
      <button onClick={sendMessage}>Send</button>
      <div>{response}</div>
    </div>
  );
}
```

## üìö API Documentation

### Available Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | System health check |
| `GET` | `/agents` | List all available agents |
| `POST` | `/agents/{agentId}/chat` | Chat with specific agent |
| `GET` | `/agents/{agentId}/status` | Get agent status |
| `POST` | `/agents/supervisor/delegate` | Delegate task to best agent |
| `GET` | `/memory` | Retrieve stored memories |
| `POST` | `/memory` | Store new memory |
| `GET` | `/docs` | OpenAPI documentation |

### Response Format

All API responses follow this structure:

```typescript
interface ApiResponse<T> {
  success: boolean;
  data?: T;
  error?: string;
  timestamp: string;
  agent?: string;
  requestId: string;
}
```

## üîß Development

### Project Structure

```
deanmachines-volt/
‚îú‚îÄ‚îÄ app/                    # Next.js frontend application
‚îÇ   ‚îú‚îÄ‚îÄ api/               # API routes
‚îÇ   ‚îú‚îÄ‚îÄ components/        # React components
‚îÇ   ‚îî‚îÄ‚îÄ globals.css       # Global styles
‚îú‚îÄ‚îÄ voltagent/             # VoltAgent backend
‚îÇ   ‚îú‚îÄ‚îÄ agents/           # Agent implementations
‚îÇ   ‚îú‚îÄ‚îÄ config/           # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ services/         # Core services
‚îÇ   ‚îî‚îÄ‚îÄ index.ts          # Main entry point
‚îú‚îÄ‚îÄ .env                   # Environment variables
‚îú‚îÄ‚îÄ package.json          # Dependencies and scripts
‚îî‚îÄ‚îÄ README.md             # This file
```

### Available Scripts

```bash
# Development
npm run dev              # Full stack development
npm run dev:backend      # Backend only (port 3141)
npm run dev:frontend     # Frontend only (port 3000)
npm run dev:voltagent    # VoltAgent only

# Building
npm run build            # Build everything
npm run build:frontend   # Build Next.js app
npm run build:backend    # Build VoltAgent

# Testing
npm test                 # Run all tests
npm run test:unit        # Unit tests only
npm run test:integration # Integration tests
npm run test:e2e         # End-to-end tests

# Linting & Formatting
npm run lint             # ESLint check
npm run lint:fix         # Fix linting issues
npm run format           # Prettier formatting
npm run type-check       # TypeScript checking

# Production
npm start                # Start production server
npm run preview          # Preview production build
```

### Development Guidelines

1. **Code Style**: Follow TypeScript best practices and use ESLint/Prettier
2. **Testing**: Write tests for all new features and bug fixes
3. **Documentation**: Update README and inline docs for API changes
4. **Git Flow**: Use feature branches and meaningful commit messages
5. **Performance**: Monitor agent response times and memory usage

## üß™ Testing

### Running Tests

```bash
# All tests
npm test

# Specific test suites
npm run test:agents      # Test all agents
npm run test:services    # Test services
npm run test:api         # Test API endpoints

# Coverage report
npm run test:coverage
```

### Test Structure

```typescript
// Example agent test
describe('MathAgent', () => {
  let agent: MathAgent;

  beforeEach(() => {
    agent = new MathAgent();
  });

  it('should calculate compound interest correctly', async () => {
    const result = await agent.invoke({
      message: "Calculate compound interest for $1000 at 5% for 10 years"
    });
    
    expect(result).toContain('$1,628.89');
  });
});
```

## üìà Monitoring

### Health Monitoring

The system includes comprehensive health monitoring:

- **Agent Health**: Each agent reports status and performance metrics
- **System Metrics**: Memory usage, response times, error rates
- **VoltOps Integration**: Cloud-based monitoring and analytics
- **Logging**: Structured logging with different levels

### Performance Metrics

```bash
# Check system health
curl http://localhost:3141/health

# Agent-specific metrics
curl http://localhost:3141/agents/supervisor/metrics

# Memory usage
curl http://localhost:3141/system/memory
```

### Telemetry

OpenTelemetry integration provides:
- Distributed tracing
- Performance monitoring
- Error tracking
- Custom metrics

## üîí Security

### Security Features

- **API Key Validation**: All external APIs require valid authentication
- **Input Sanitization**: All user inputs are validated and sanitized
- **Rate Limiting**: Prevent abuse with configurable rate limits
- **CORS Protection**: Properly configured cross-origin policies
- **Environment Isolation**: Sensitive data stored in environment variables

### Security Best Practices

1. **Never commit API keys** to version control
2. **Use environment variables** for all sensitive configuration
3. **Regular dependency updates** to patch security vulnerabilities
4. **Monitor logs** for suspicious activity
5. **Implement proper error handling** to avoid information leakage

### Reporting Security Issues

If you discover a security vulnerability, please:
1. **Do not** create a public GitHub issue
2. Email security concerns to: security@deanmachines.dev
3. Include detailed information about the vulnerability
4. Allow time for assessment and patching before disclosure

## ü§ù Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Quick Contribution Guide

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Make** your changes with tests
4. **Commit** with clear messages (`git commit -m 'Add amazing feature'`)
5. **Push** to your branch (`git push origin feature/amazing-feature`)
6. **Open** a Pull Request

### Development Setup

```bash
# Fork and clone your fork
git clone https://github.com/yourusername/deanmachines-volt.git
cd deanmachines-volt

# Add upstream remote
git remote add upstream https://github.com/original/deanmachines-volt.git

# Install dependencies
npm install

# Create feature branch
git checkout -b feature/your-feature-name

# Make changes, test, and commit
npm test
git add .
git commit -m "feat: add your feature"

# Push and create PR
git push origin feature/your-feature-name
```

## üìû Support & Community

- **üìö Documentation**: [Full documentation](https://docs.deanmachines.dev)
- **üí¨ Discord**: [Join our community](https://discord.gg/deanmachines)
- **üêõ Issues**: [Report bugs](https://github.com/yourusername/deanmachines-volt/issues)
- **üí° Feature Requests**: [Request features](https://github.com/yourusername/deanmachines-volt/discussions)
- **üìß Email**: support@deanmachines.dev

## üôè Acknowledgments

- **[VoltAgent](https://voltagent.dev)** - The amazing framework that powers this system
- **[Google AI](https://ai.google.dev)** - Gemini models for intelligent processing
- **[Vercel](https://vercel.com)** - AI SDK and deployment platform
- **[Next.js](https://nextjs.org)** - React framework for the frontend
- **[TypeScript](https://typescriptlang.org)** - Type-safe development

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

**‚≠ê If you found this project helpful, please give it a star! ‚≠ê**

Made with ‚ù§Ô∏è by [DeanMachines](https://github.com/yourusername)

[üöÄ Get Started](#-quick-start) ‚Ä¢ [üìö Documentation](https://docs.deanmachines.dev) ‚Ä¢ [üí¨ Community](https://discord.gg/deanmachines)

</div>
</file>

<file path="voltagent/agents/index.ts">
/**
 * Agent Exports
 * Central export point for all VoltAgent agents
 */
// Specialized Sub-Agents
export { mathAgent } from "./mathAgent";
export { fileAgent } from "./fileAgent";
export { webAgent } from "./webAgent";
export { devAgent } from "./devAgent";
export { dataAgent } from "./dataAgent";
export { commsAgent } from "./commsAgent";
export { memoryAgent } from "./memoryAgent";
// Supervisor Agent
export { supervisorAgent } from "./supervisorAgent";
// Agent Collections
export const subAgents = {
  math: () => import("./mathAgent").then(m => m.mathAgent),
  file: () => import("./fileAgent").then(m => m.fileAgent),
  web: () => import("./webAgent").then(m => m.webAgent),
  dev: () => import("./devAgent").then(m => m.devAgent),
  data: () => import("./dataAgent").then(m => m.dataAgent),
  comms: () => import("./commsAgent").then(m => m.commsAgent),
  memory: () => import("./memoryAgent").then(m => m.memoryAgent),
};
export const allAgents = {
  supervisor: () => import("./supervisorAgent").then(m => m.supervisorAgent),
  ...subAgents,
};
</file>

<file path="voltagent/GEMINI.md">
# Gemini Workspace: voltagent

This document provides context and best practices for working within the `voltagent` directory.

## Core Architecture

The `voltagent` module is a TypeScript-based multi-agent system designed for task automation. Its architecture consists of several key components:

1.  **Supervisor Agent (`supervisorAgent.ts`):** This is the primary orchestrator. It receives tasks, breaks them down, and delegates them to the appropriate specialized agent. All high-level logic and inter-agent communication flows through the supervisor.

2.  **Specialized Agents (`agents/*.ts`):** Each agent (`mathAgent`, `devAgent`, `fileAgent`, etc.) is an expert in a specific domain. They are designed to handle a narrow set of tasks delegated by the supervisor.

3.  **Tools (`tools/*.ts`):** Agents are equipped with tools to interact with the outside world or perform specific actions (e.g., `calculator.ts`). Tools are the fundamental building blocks of an agent's capabilities.

4.  **Services (`services/*.ts`):** These provide core, reusable functionalities that support the agents and tools. This includes:
    *   **Memory:** `memory.ts` (session memory), `supaMemory.ts` (persistent memory via Supabase), and `chroma.ts` (vector-based retrieval) provide a multi-layered memory system.
    *   **Data Retrieval:** `retriever.ts` is used for fetching information.
    *   **Configuration:** `config/googleProvider.ts` manages the connection to the underlying Google AI models.

5.  **Entry Point (`index.ts`):** This file initializes and wires together all the agents, tools, and services.

## Design Patterns & Best Practices

This section outlines the key design patterns used in `voltagent` and the best practices to follow during development.

### Core Design Patterns

-   **Supervisor-Worker Pattern:** The entire system is built on this pattern. The `supervisorAgent` acts as the central dispatcher, routing tasks to the appropriate specialized `Worker` agent (e.g., `mathAgent`, `devAgent`). This promotes a clear separation of concerns and makes the system highly extensible.
-   **Tool-Based Architecture:** Agents are given capabilities through `Tools`. This is a form of the **Strategy Pattern**, where each tool encapsulates a specific algorithm or action. This makes it easy to add new functionality without modifying the agent's core logic.
-   **Service Layer:** The `services` directory is an implementation of the **Service Locator Pattern**. It provides a centralized place to access shared resources like memory, databases, and external APIs.
-   **Multi-Layered Memory:** The memory system uses a **Chain of Responsibility Pattern**. When an agent needs to recall information, it can query the `memory` service, which will check the session memory,  and finally the vector store (`chroma`) if necessary.

### Best Practices

-   **Start with the Supervisor:** For any new task or workflow, the `supervisorAgent` is the first point of modification. The supervisor is responsible for understanding the task and delegating it correctly.
-   **Create Specialized Tools:** When adding a new capability, always implement it as a `Tool`. Tools should be small, single-purpose, and placed in the `voltagent/tools/` directory. This makes them reusable and easy to test.
-   **Create New Agents for New Domains:** If a new capability represents a completely new domain of expertise (e.g., interacting with a new third-party API), create a new specialized agent in the `voltagent/agents/` directory. Do not add unrelated responsibilities to existing agents.
-   **Use Services for Shared Logic:** If a piece of logic needs to be shared across multiple agents or tools (e.g., accessing a database, calling an external API), implement it as a `Service` in the `voltagent/services/` directory.
-   **Manage Memory Appropriately:** Be mindful of the different memory services available. Use `memory.ts` for short-term, conversational context. Use `supaMemory.ts` or `chroma.ts` for long-term knowledge that needs to be persisted and searched.
-   **Register New Components:** After creating a new agent, tool, or service, ensure it is correctly imported and registered in the main `voltagent/index.ts` file.

## Common Anti-Patterns to Avoid

-   **Monolithic Agents:** Do not add multiple, unrelated responsibilities to a single agent. If an agent is doing too much, it should be broken down into smaller, more specialized agents.
-   **Fat Tools:** Avoid creating tools that perform multiple, complex operations. A tool should do one thing and do it well. If a tool's logic is becoming too complex, consider splitting it into multiple tools or moving the complex logic into a dedicated `Service`.
-   **Bypassing the Supervisor:** Never have specialized agents communicate directly with each other. All inter-agent communication must be orchestrated by the `supervisorAgent`. This ensures a clear and predictable flow of information.
-   **Ignoring the Service Layer:** Do not instantiate service clients (like database connections or API clients) directly within an agent or tool. Always access these resources through the appropriate `Service` to ensure proper lifecycle management and reusability.
-   **Mixing Memory Types:** Avoid using the wrong type of memory for the task. Don't store long-term, searchable knowledge in the session memory. Conversely, don't clutter the persistent memory with transient, conversational data.
</file>

<file path="voltagent/services/chroma.ts">
import { BaseRetriever, type BaseMessage, type RetrieveOptions } from "@voltagent/core";
import { ChromaClient } from "chromadb";
import { GoogleGeminiEmbeddingFunction } from "@chroma-core/google-gemini";
// Initialize Chroma client
const chromaClient = new ChromaClient({
  path: process.env.CHROMA_URL || "http://localhost:8000",
});
const embeddingFunction = new GoogleGeminiEmbeddingFunction({
  apiKey: process.env.GEMINI_API_KEY,
  modelName: "gemini-embedding-exp-03-07",
});
const collectionName = "voltagent-knowledge-base";
// Initialize collection with some sample documents
async function initializeCollection() {
  try {
    const collection = await chromaClient.getOrCreateCollection({
      name: collectionName,
      embeddingFunction: embeddingFunction,
    });
    // Add some sample documents to get started
    const sampleDocuments = [
      "VoltAgent is a TypeScript framework for building AI agents with modular components.",
      "Chroma is an AI-native open-source vector database that handles embeddings automatically.",
      "Vector databases store high-dimensional vectors and enable semantic search capabilities.",
      "Retrieval-Augmented Generation (RAG) combines information retrieval with language generation.",
      "TypeScript provides static typing for JavaScript, making code more reliable and maintainable.",
    ];
    const sampleIds = sampleDocuments.map((_, index) => `sample_${index + 1}`);
    // Use upsert to avoid duplicates
    await collection.upsert({
      documents: sampleDocuments,
      ids: sampleIds,
      metadatas: sampleDocuments.map((_, index) => ({
        type: "sample",
        index: index + 1,
        topic: index < 2 ? "frameworks" : index < 4 ? "databases" : "programming",
      })),
    });
    console.log("üìö Sample knowledge base initialized with", sampleDocuments.length, "documents");
  } catch (error) {
    console.error("Error initializing collection:", error);
  }
}
// Call initialization
initializeCollection();
// Retriever function
async function retrieveDocuments(query: string, nResults = 3) {
  try {
    const collection = await chromaClient.getOrCreateCollection({
      name: collectionName,
      embeddingFunction: embeddingFunction,
    });
    const results = await collection.query({
      queryTexts: [query],
      nResults,
    });
    if (!results.documents || !results.documents[0]) {
      return [];
    }
    // Format results with metadata
    return results.documents[0].map((doc, index) => ({
      content: doc,
      metadata: results.metadatas?.[0]?.[index] || {},
      distance: results.distances?.[0]?.[index] || 0,
      id: results.ids?.[0]?.[index] || `unknown_${index}`,
    }));
  } catch (error) {
    console.error("Error retrieving documents:", error);
    return [];
  }
}
/**
 * Chroma-based retriever implementation for VoltAgent
 */
export class ChromaRetriever extends BaseRetriever {
  /**
   * Retrieve documents from Chroma based on semantic similarity
   * @param input - The input to use for retrieval (string or BaseMessage[])
   * @param options - Configuration and context for the retrieval
   * @returns Promise resolving to a formatted context string
   */
  async retrieve(input: string | BaseMessage[], options: RetrieveOptions): Promise<string> {
    // Convert input to searchable string
    let searchText = "";
    if (typeof input === "string") {
      searchText = input;
    } else if (Array.isArray(input) && input.length > 0) {
      const lastMessage = input[input.length - 1];
      // Handle content as array of content parts with text type
      if (Array.isArray(lastMessage.content)) {
        const textParts = lastMessage.content
          .filter((part: any) => part.type === "text")
          .map((part: any) => part.text);
        searchText = textParts.join(" ");
      } else {
        // Fallback to string content
        searchText = lastMessage.content as string;
      }
    }
    // Perform semantic search using Chroma
    const results = await retrieveDocuments(searchText, 3);
    // Add references to userContext if available
    if (options.userContext && results.length > 0) {
      const references = results.map((doc, index) => ({
        id: doc.id,
        title: doc.metadata.title || `Document ${index + 1}`,
        source: "Chroma Knowledge Base",
        distance: doc.distance,
      }));
      options.userContext.set("references", references);
    }
    // Return the concatenated content for the LLM
    if (results.length === 0) {
      return "No relevant documents found in the knowledge base.";
    }
    return results
      .map(
        (doc, index) =>
          `Document ${index + 1} (ID: ${doc.id}, Distance: ${doc.distance.toFixed(4)}):\n${doc.content}`,
      )
      .join("\n\n---\n\n");
  }
}
// Create retriever instance
export const retriever = new ChromaRetriever();
</file>

<file path="voltagent/tools/calculator.ts">
import { createTool } from "@voltagent/core";
import { z } from "zod";
/**
 * Calculator Tool
 * Provides mathematical calculation capabilities
 */
export const calculatorTool = createTool({
  name: "calculate",
  description: "Perform a mathematical calculation",
  parameters: z.object({
    expression: z.string().describe("The mathematical expression to evaluate, e.g. (2 + 2) * 3"),
  }),
  execute: async (args) => {
    try {
      // Using Function is still not ideal for production but safer than direct eval
      // eslint-disable-next-line no-new-func
      const result = new Function(`return ${args.expression}`)();
      return { result };
    } catch (e) {
      // Properly use the error variable
      const errorMessage = e instanceof Error ? e.message : String(e);
      throw new Error(`Invalid expression: ${args.expression}. Error: ${errorMessage}`);
    }
  },
});
</file>

<file path="voltagent/tools/index.ts">
export * from "./calculator";
// Future tools can be exported here
// export * from "./weatherTool";
// export * from "./databaseTool";
</file>

<file path=".clinerules/voltAgent.instructions.md">
---
description: AI rules derived by SpecStory from the project AI interaction history
applyTo: "/voltagent/**/*.{ts,tsx}"
---
# VoltAgent Development Guidelines

## Overview

This project implements a professional, modular VoltAgent AI agent system using Vercel AI SDK with Google (Gemini) models. The system follows VoltAgent best practices for memory, retrieval, structured reasoning, and MCP integration.

## Architecture Principles

### Core Design Rules

- **Professional modular design** with clear separation of concerns
- **Clean dependency structure** - agents import directly from `googleProvider.ts`
- **Flash-lite model optimization** for performance
- **Robust error handling** with graceful fallbacks
- **MCP integration** with conditional server loading

### Agent Structure

```typescript
// Standard agent pattern
export const agentName = new Agent({
  name: "AgentName", // No constants, use string literals
  description: "Professional description with capabilities",
  instructions: dynamicPrompt(), // Use createPrompt for dynamic templates
  llm: new VercelAIProvider(),
  model: google("gemini-2.5-flash-lite-preview-06-17"), // Always flash-lite
  tools: [reasoningToolkit, ...domainTools], // Include reasoning tools
  memory: memoryStorage, // Explicit memory configuration
  retriever: new DocumentRetriever(), // Appropriate retriever type
  hooks: createSubAgentHooks(), // Lifecycle management
});
```

## Technology Stack

### Required Dependencies

- `@ai-sdk/google` version 1.2.19 (or later)
- `@voltagent/core` for agent framework
- `@voltagent/vercel-ai` for provider integration
- `@google/generative-ai` for Gemini models
- `zod` for schema validation

### Model Configuration

- **Primary Model**: `gemini-2.5-flash-lite-preview-06-17`
- **Provider**: Vercel AI SDK with Google integration
- **No OpenAI dependencies** - fully migrated to Google AI

## Agent System Components

### 1. GoogleProvider Configuration (`config/googleProvider.ts`)

```typescript
import { google } from "@ai-sdk/google";

// Robust provider with console logging
export const googleProvider = google({
  apiKey: process.env.GOOGLE_AI_API_KEY,
  // Additional configuration
});
```

### 2. Memory Management (`services/memory.ts`)

```typescript
export const memoryStorage = new LibSQLStorage({
  url: process.env.DATABASE_URL || "file:.voltagent/memory.db",
  authToken: process.env.DATABASE_AUTH_TOKEN,
  tablePrefix: "voltagent_memory",
  storageLimit: 100,
  debug: process.env.NODE_ENV === "development",
});
```

### 3. MCP Tools Service (`services/mcp.ts`)

```typescript
// Conditional MCP server loading with safe error handling
export class MCPToolsService {
  // Only loads servers with available credentials
  // Provides fallback for missing tokens
  // Categorized tool management
}
```

### 4. Retriever Services (`services/retriever.ts`)

```typescript
export class DocumentRetriever extends BaseRetriever {
  // Real implementation for document search
}

export class MemoryRetriever extends BaseRetriever {
  // Memory-based knowledge retrieval
}
```

## Agent Hierarchy

### Supervisor Agent (`agents/supervisorAgent.ts`)

- **Role**: Main orchestrator and task coordinator
- **Features**: Dynamic prompts, reasoning tools, all sub-agents
- **Tools**: `createReasoningTools()` for structured delegation
- **Memory**: Full conversation context
- **Retriever**: Cross-domain knowledge access

### Sub-Agents

1. **MathAgent** - Mathematical calculations with structured reasoning
2. **FileAgent** - File operations with memory and document retrieval
3. **WebAgent** - Web research with analysis and memory storage
4. **DevAgent** - Development tasks with code analysis and project memory
5. **DataAgent** - Database operations with schema retrieval
6. **CommsAgent** - Communication with template and contact management
7. **MemoryAgent** - Knowledge management with memory retrieval

## Development Patterns

### Dynamic Prompts with `createPrompt`

```typescript
const agentPrompt = createPrompt({
  template: `You are a specialist in {{domain}}.
  
Current Context: {{context}}
Task Type: {{task_type}}

{{strategy}}

Always use 'think' to analyze before proceeding.`,
  variables: {
    domain: "your specialty",
    context: "general context",
    task_type: "standard",
    strategy: "Your approach strategy"
  }
});
```

### Structured Reasoning with `createReasoningTools`

```typescript
const reasoningToolkit = createReasoningTools({
  think: true,    // Problem analysis and planning
  analyze: true,  // Result evaluation and next steps
  addInstructions: true, // Include usage guidelines
  addFewShot: true // Include examples
});
```

### Memory and Retriever Integration

```typescript
// Every agent should have explicit memory and appropriate retriever
export const agentName = new Agent({
  // ...other config
  memory: memoryStorage, // For conversation context
  retriever: new DocumentRetriever('database', undefined, {
    toolName: "search_domain_docs",
    toolDescription: "Search domain-specific documentation"
  }),
});
```

## Best Practices

### Code Standards

- Use TypeScript with strict typing
- Follow VoltAgent naming conventions
- Implement proper error boundaries
- Include comprehensive JSDoc comments
- Use console-based logging (not PinoLogger)

### Agent Design

- **Always validate environment variables** before using them
- **Provide clear error messages** for missing credentials
- **Use conditional server loading** for MCP configurations
- **Include reasoning tools** for complex decision-making
- **Structure prompts dynamically** with template variables

### Performance Optimization

- Use `flash-lite` models for speed
- Implement tool categorization for efficient loading
- Cache MCP tool responses where appropriate
- Optimize memory retrieval with proper limits

### Error Handling

```typescript
// Example: Safe environment variable handling
if (!process.env.GOOGLE_AI_API_KEY) {
  console.warn("Google AI API key not found. Some features may be limited.");
  // Provide fallback or disable functionality gracefully
}
```

## Testing and Validation

### Environment Setup

```bash
# Required environment variables
GOOGLE_AI_API_KEY=your_google_ai_key
DATABASE_URL=your_database_url (optional, defaults to local SQLite)
DATABASE_AUTH_TOKEN=your_auth_token (for Turso)

# Optional MCP server credentials
BRAVE_API_KEY=your_brave_search_key
SLACK_BOT_TOKEN=your_slack_token
# ... other service tokens
```

### Validation Checklist

- [ ] All agents use `flash-lite` models
- [ ] No OpenAI dependencies remain
- [ ] Memory and retriever are explicitly configured
- [ ] MCP tools load conditionally based on available credentials
- [ ] Reasoning tools are included for complex agents
- [ ] Dynamic prompts use `createPrompt`
- [ ] Error handling provides clear feedback
- [ ] Console logging is used consistently

## Documentation References

- [VoltAgent Core Documentation](https://voltagent.dev/docs/)
- [Memory Management](https://voltagent.dev/docs/agents/memory/overview/)
- [Retriever Guide](https://voltagent.dev/docs/agents/retriever/)
- [Reasoning Tools](https://voltagent.dev/docs/tools/reasoning-tool/)
- [createPrompt Utility](https://voltagent.dev/docs/utils/create-prompt/)
- [MCP Integration](https://voltagent.dev/docs/agents/mcp/)

## Project Structure

```
voltagent/
‚îú‚îÄ‚îÄ index.ts                 # Main export point
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ googleProvider.ts    # Google AI configuration
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ mcp.ts              # MCP tools service
‚îÇ   ‚îú‚îÄ‚îÄ memory.ts           # Memory management
‚îÇ   ‚îú‚îÄ‚îÄ retriever.ts        # Retrieval services
‚îÇ   ‚îú‚îÄ‚îÄ hooks.ts            # Lifecycle hooks
‚îÇ   ‚îú‚îÄ‚îÄ context.ts          # Context management
‚îÇ   ‚îî‚îÄ‚îÄ index.ts            # Service exports
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ supervisorAgent.ts  # Main coordinator
‚îÇ   ‚îú‚îÄ‚îÄ mathAgent.ts        # Math specialist
‚îÇ   ‚îú‚îÄ‚îÄ fileAgent.ts        # File operations
‚îÇ   ‚îú‚îÄ‚îÄ webAgent.ts         # Web research
‚îÇ   ‚îú‚îÄ‚îÄ devAgent.ts         # Development tasks
‚îÇ   ‚îú‚îÄ‚îÄ dataAgent.ts        # Database operations
‚îÇ   ‚îú‚îÄ‚îÄ commsAgent.ts       # Communication
‚îÇ   ‚îú‚îÄ‚îÄ memoryAgent.ts      # Knowledge management
‚îÇ   ‚îî‚îÄ‚îÄ index.ts            # Agent exports
‚îî‚îÄ‚îÄ tools/
    ‚îî‚îÄ‚îÄ calculator.ts       # Custom tools
```

This architecture provides a robust, scalable, and maintainable VoltAgent system following all official best practices and guidelines.
</file>

<file path=".github/copilot-instructions.md">
---
description: AI rules derived by SpecStory from the project AI interaction history
globs: *
---

## Headers

## PROJECT RULES

## CODING STANDARDS

## WORKFLOW & RELEASE RULES
- Do not run any code or execute commands without explicit user permission.
- **Always list available documentation and examples before proceeding with implementation.**
- **Always list VoltAgent docs first before searching.**
- **Quit searching: always list first.**

## TECH STACK
- `@ai-sdk/google` version 1.2.19 (or later)
- Vercel AI SDK
- flash-lite
- ts-node
- tsx
- typescript

## PROJECT DOCUMENTATION & CONTEXT SYSTEM
- Before proceeding with implementation, always list available documentation and examples.
- Use `#list_voltagent_docs` and `#list_voltagent_examples` to search for documentation and examples.

## DEBUGGING
- **Always validate that required environment variables are defined before using them, and provide clear error messages if they are missing. This includes checking for null or undefined values.**

## VOLTAGENT GUIDELINES

When assisting with projects involving Voltagent, prioritize building a professional modular design. Analyze the existing codebase to understand its structure and facilitate improvements. When switching from OpenAI, ensure all OpenAI dependencies are removed, and Google AI dependencies are correctly implemented. When using `@ai-sdk/google` with Vercel AI SDK, ensure compatibility and proper configuration. Always verify that OpenAI dependencies are removed from the package.json and codebase when migrating to Google AI. When working with Voltagent, prefer console-based logging when a specific logger isn't required. Agents should import directly from `googleProvider.ts` to maintain a cleaner dependency structure. Avoid using intermediary files like `models.ts` or `providers.ts` unless necessary. The main `index.ts` file should be clean and simple, just importing and exporting the components. When defining agents, use `flash-lite` and avoid using constants for the actual name in the agents. Always list available documentation and examples before proceeding with implementation. Do not run any code or execute commands without explicit user permission. Ensure that MCP configurations do not fail if tokens are unavailable by adding proper fallback handling and conditional server loading. **Always validate that required environment variables are defined before using them, and provide clear error messages if they are missing. This includes checking for null or undefined values.** **Ensure all agents have thinkingConfig at 0 & false by default.**
</file>

<file path=".windsurf/rules/quality.md">
---
trigger: always_on
globs: voltagent/**/*.ts, app/**/*.tsx, app/**/*.ts
---

- **TypeScript Best Practices**:
  - Ensure all functions and methods have explicit return types.
  - Use interfaces or types for complex object shapes.
  - Avoid using `any` unless absolutely necessary. Prefer `unknown` for type-safe operations.
  - Enable and adhere to strict mode (`"strict": true`) in `tsconfig.json`.
  - Always use unread imports & variables, values. Never remove them unless you are absolutely sure it is unnescessary, because removing 1 critical function, type, ect can break everything.
  - Use Professional TSDoc in each file
  - Never guess or assume anything.
      - Always make sure whatever your working is consistent with similar files & always check valid info.
  - Use all your mcp tools for example 'vibe_check' is an amazing tool, to help you not only helps you at that moment but if you also use 'vibe_distill' & 'vibe_learn' all together is very powerful
  - Also use Vibe-Tools, with instructions from '.windsurfrules', this is another extremely powerful tool you can use whenever especially Vibe-Tools web, repo & other commands.


- **React/Next.js Component Rules**:
  - Components should be functional and use Hooks.
  - Keep components small and focused on a single responsibility.
  - Use `memo` for components that render frequently with the same props.
  - All components in `app/components` should be client components (`'use client'`) unless they are purely presentational and have no interactivity.

- **Dependency Management**:
  - Regularly run `npm audit` or `yarn audit` to check for vulnerabilities.
  - Keep dependencies up-to-date, especially major frameworks like Next.js and VoltAgent.
  - Remove unused dependencies from `package.json`.
</file>

<file path=".windsurf/rules/voltagent.md">
---
trigger: glob
description: Any files within ./voltagents/**/*.ts
globs: voltagent/**/*.ts
---

# VoltAgent Development Guidelines

## Overview

This project implements a professional, modular VoltAgent AI agent system using Vercel AI SDK with Google (Gemini) models. The system follows VoltAgent best practices for memory, retrieval, structured reasoning, and MCP integration.

## Architecture Principles

### Core Design Rules

- **Professional modular design** with clear separation of concerns
- **Clean dependency structure** - agents import directly from `googleProvider.ts`
- **Flash-lite model optimization** for performance
- **Robust error handling** with graceful fallbacks
- **MCP integration** with conditional server loading

### Agent Structure

```typescript
// Standard agent pattern
export const agentName = new Agent({
  name: "AgentName", // No constants, use string literals
  description: "Professional description with capabilities",
  instructions: dynamicPrompt(), // Use createPrompt for dynamic templates
  llm: new VercelAIProvider(),
  model: google("gemini-2.5-flash-lite-preview-06-17"), // Always flash-lite
  tools: [reasoningToolkit, ...domainTools], // Include reasoning tools
  memory: memoryStorage, // Explicit memory configuration
  retriever: new DocumentRetriever(), // Appropriate retriever type
  hooks: createSubAgentHooks(), // Lifecycle management
});
```

## Technology Stack

### Required Dependencies

- `@ai-sdk/google` version 1.2.19 (or later)
- `@voltagent/core` for agent framework
- `@voltagent/vercel-ai` for provider integration
- `@google/generative-ai` for Gemini models
- `zod` for schema validation

### Model Configuration

- **Primary Model**: `gemini-2.5-flash-lite-preview-06-17`
- **Provider**: Vercel AI SDK with Google integration
- **No OpenAI dependencies** - fully migrated to Google AI

## Agent System Components

### 1. GoogleProvider Configuration (`config/googleProvider.ts`)

```typescript
import { google } from "@ai-sdk/google";

// Robust provider with console logging
export const googleProvider = google({
  apiKey: process.env.GOOGLE_AI_API_KEY,
  // Additional configuration
});
```

### 2. Memory Management (`services/memory.ts`)

```typescript
export const memoryStorage = new LibSQLStorage({
  url: process.env.DATABASE_URL || "file:.voltagent/memory.db",
  authToken: process.env.DATABASE_AUTH_TOKEN,
  tablePrefix: "voltagent_memory",
  storageLimit: 100,
  debug: process.env.NODE_ENV === "development",
});
```

### 3. MCP Tools Service (`services/mcp.ts`)

```typescript
// Conditional MCP server loading with safe error handling
export class MCPToolsService {
  // Only loads servers with available credentials
  // Provides fallback for missing tokens
  // Categorized tool management
}
```

### 4. Retriever Services (`services/retriever.ts`)

```typescript
export class DocumentRetriever extends BaseRetriever {
  // Real implementation for document search
}

export class MemoryRetriever extends BaseRetriever {
  // Memory-based knowledge retrieval
}
```

## Agent Hierarchy

### Supervisor Agent (`agents/supervisorAgent.ts`)

- **Role**: Main orchestrator and task coordinator
- **Features**: Dynamic prompts, reasoning tools, all sub-agents
- **Tools**: `createReasoningTools()` for structured delegation
- **Memory**: Full conversation context
- **Retriever**: Cross-domain knowledge access

### Sub-Agents

1. **MathAgent** - Mathematical calculations with structured reasoning
2. **FileAgent** - File operations with memory and document retrieval
3. **WebAgent** - Web research with analysis and memory storage
4. **DevAgent** - Development tasks with code analysis and project memory
5. **DataAgent** - Database operations with schema retrieval
6. **CommsAgent** - Communication with template and contact management
7. **MemoryAgent** - Knowledge management with memory retrieval

## Development Patterns

### Dynamic Prompts with `createPrompt`

```typescript
const agentPrompt = createPrompt({
  template: `You are a specialist in {{domain}}.
  
Current Context: {{context}}
Task Type: {{task_type}}

{{strategy}}

Always use 'think' to analyze before proceeding.`,
  variables: {
    domain: "your specialty",
    context: "general context",
    task_type: "standard",
    strategy: "Your approach strategy"
  }
});
```

### Structured Reasoning with `createReasoningTools`

```typescript
const reasoningToolkit = createReasoningTools({
  think: true,    // Problem analysis and planning
  analyze: true,  // Result evaluation and next steps
  addInstructions: true, // Include usage guidelines
  addFewShot: true // Include examples
});
```

### Memory and Retriever Integration

```typescript
// Every agent should have explicit memory and appropriate retriever
export const agentName = new Agent({
  // ...other config
  memory: memoryStorage, // For conversation context
  retriever: new DocumentRetriever('database', undefined, {
    toolName: "search_domain_docs",
    toolDescription: "Search domain-specific documentation"
  }),
});
```

## Best Practices

### Code Standards

- Use TypeScript with strict typing
- Follow VoltAgent naming conventions
- Implement proper error boundaries
- Include comprehensive JSDoc comments
- Use console-based logging (not PinoLogger)

### Agent Design

- **Always validate environment variables** before using them
- **Provide clear error messages** for missing credentials
- **Use conditional server loading** for MCP configurations
- **Include reasoning tools** for complex decision-making
- **Structure prompts dynamically** with template variables

### Performance Optimization

- Use `flash-lite` models for speed
- Implement tool categorization for efficient loading
- Cache MCP tool responses where appropriate
- Optimize memory retrieval with proper limits

### Error Handling

```typescript
// Example: Safe environment variable handling
if (!process.env.GOOGLE_AI_API_KEY) {
  console.warn("Google AI API key not found. Some features may be limited.");
  // Provide fallback or disable functionality gracefully
}
```

## Testing and Validation

### Environment Setup

```bash
# Required environment variables
GOOGLE_AI_API_KEY=your_google_ai_key
DATABASE_URL=your_database_url (optional, defaults to local SQLite)
DATABASE_AUTH_TOKEN=your_auth_token (for Turso)

# Optional MCP server credentials
BRAVE_API_KEY=your_brave_search_key
SLACK_BOT_TOKEN=your_slack_token
# ... other service tokens
```

### Validation Checklist

- [ ] All agents use `flash-lite` models
- [ ] No OpenAI dependencies remain
- [ ] Memory and retriever are explicitly configured
- [ ] MCP tools load conditionally based on available credentials
- [ ] Reasoning tools are included for complex agents
- [ ] Dynamic prompts use `createPrompt`
- [ ] Error handling provides clear feedback
- [ ] Console logging is used consistently

## Documentation References

- [VoltAgent Core Documentation](https://voltagent.dev/docs/)
- [Memory Management](https://voltagent.dev/docs/agents/memory/overview/)
- [Retriever Guide](https://voltagent.dev/docs/agents/retriever/)
- [Reasoning Tools](https://voltagent.dev/docs/tools/reasoning-tool/)
- [createPrompt Utility](https://voltagent.dev/docs/utils/create-prompt/)
- [MCP Integration](https://voltagent.dev/docs/agents/mcp/)

## Project Structure

```
voltagent/
‚îú‚îÄ‚îÄ index.ts                 # Main export point
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ googleProvider.ts    # Google AI configuration
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ mcp.ts              # MCP tools service
‚îÇ   ‚îú‚îÄ‚îÄ memory.ts           # Memory management
‚îÇ   ‚îú‚îÄ‚îÄ retriever.ts        # Retrieval services
‚îÇ   ‚îú‚îÄ‚îÄ hooks.ts            # Lifecycle hooks
‚îÇ   ‚îú‚îÄ‚îÄ context.ts          # Context management
‚îÇ   ‚îî‚îÄ‚îÄ index.ts            # Service exports
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ supervisorAgent.ts  # Main coordinator
‚îÇ   ‚îú‚îÄ‚îÄ mathAgent.ts        # Math specialist
‚îÇ   ‚îú‚îÄ‚îÄ fileAgent.ts        # File operations
‚îÇ   ‚îú‚îÄ‚îÄ webAgent.ts         # Web research
‚îÇ   ‚îú‚îÄ‚îÄ devAgent.ts         # Development tasks
‚îÇ   ‚îú‚îÄ‚îÄ dataAgent.ts        # Database operations
‚îÇ   ‚îú‚îÄ‚îÄ commsAgent.ts       # Communication
‚îÇ   ‚îú‚îÄ‚îÄ memoryAgent.ts      # Knowledge management
‚îÇ   ‚îî‚îÄ‚îÄ index.ts            # Agent exports
‚îî‚îÄ‚îÄ tools/
    ‚îî‚îÄ‚îÄ calculator.ts       # Custom tools
```

This architecture provides a robust, scalable, and maintainable VoltAgent system following all official best practices and guidelines.
</file>

<file path="app/page.tsx">
import { Navbar } from "./components/navbar";
import { SupervisorChat } from "./components/supervisor-chat";
export default function Home() {
  return (
    <div className="relative min-h-screen bg-[#1b1b1b] flex flex-col p-4 overflow-hidden">
      {/* Dot pattern background */}
      <div className="absolute inset-0 opacity-10">
        <div
          className="absolute inset-0"
          style={{
            backgroundImage: "radial-gradient(#94a3b8 1.2px, transparent 0)",
            backgroundSize: "20px 20px",
          }}
        />
      </div>
      <Navbar />
      <main className="relative w-full max-w-2xl mx-auto mt-6 z-10">
        <div className="mb-8 text-center">
          <h1 className="text-3xl font-bold text-[#00d992] mb-1">VoltAgent Supervisor</h1>
          <p className="text-gray-400">AI-powered task coordination across multiple agents</p>
        </div>
        <SupervisorChat />
        <div className="mt-8 text-center text-sm text-gray-500">
          <p>Built with Next.js and VoltAgent</p>
        </div>
      </main>
    </div>
  );
}
</file>

<file path="next.config.ts">
import type { NextConfig } from "next";
const nextConfig: NextConfig = {
  serverExternalPackages: [
    "@voltagent/*",
    "npm-check-updates",
    "@ai-sdk/google",
    "@libsql/client",
    "@opentelemetry/*",
    "@swagger-api/apidom-parser-adapter-openapi-json-2",
    "ai",
    "@upstash/*",
    "cheerio",
    "@google/generative-ai",
    "crawlee",
    "wikibase-sdk",
    "papaparse",
    "fast-xml-parser",
    "quick-lru",
    "yaml",
    "zod",
    "js-yaml",
    "jsonschema",
    "simple-git",
    "octokit",
    "memfs"
  ],
};
export default nextConfig;
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2022",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./*"]
    }
  },
  "include": [
    "next-env.d.ts",
    "**/*.ts",
    "**/*.tsx",
    ".next/types/**/*.ts",
    "**/*.d.ts"
  ],
  "exclude": ["node_modules"]
}
</file>

<file path="voltagent/config/googleProvider.ts">
// Generated on 2025-06-20 - Enhanced with Gemini 2.5 features
/**
 * Enhanced Google Generative AI Provider Setup for Mastra
 *
 * Comprehensive Google provider with full Gemini 2.5 feature support including:
 * - Search Grounding with Dynamic Retrieval
 * - Cached Content (Implicit & Explicit)
 * - File Inputs (PDF, images, etc.)
 * - Embedding Models with flexible dimensions (1536 default)
 * - Thinking Config via providerOptions (correct AI SDK pattern)
 * - Safety Settings and Response Modalities
 * - Image Generation capabilities
 *
 * @see https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai
 * @see https://ai.google.dev/gemini-api/docs
 *
 * @example Correct thinking config usage:
 * ```typescript
 * const result = await generateText({
 *   model: google('gemini-2.5-flash-lite-preview-06-17'),
 *   providerOptions: {
 *     google: {
 *       thinkingConfig: { thinkingBudget: 2048 }
 *     }
 *   },
 *   prompt: 'Think step by step...'
 * });
 * ```
 */
import {
  google as baseGoogle,
  GoogleGenerativeAIProviderSettings,
  GoogleGenerativeAIProviderOptions,
  GoogleGenerativeAIProviderMetadata
} from '@ai-sdk/google';
import { GoogleAICacheManager } from '@google/generative-ai/server';
// Simple console-based logger for VoltAgent compatibility
const logger = {
  info: (msg: string, data?: Record<string, unknown>) => 
    console.log(`[INFO] googleProvider: ${msg}`, data ? JSON.stringify(data, null, 2) : ''),
  debug: (msg: string, data?: Record<string, unknown>) => 
    console.debug(`[DEBUG] googleProvider: ${msg}`, data ? JSON.stringify(data, null, 2) : ''),
  error: (msg: string, data?: Record<string, unknown>) => 
    console.error(`[ERROR] googleProvider: ${msg}`, data ? JSON.stringify(data, null, 2) : ''),
  warn: (msg: string, data?: Record<string, unknown>) => 
    console.warn(`[WARN] googleProvider: ${msg}`, data ? JSON.stringify(data, null, 2) : '')
};
/**
 * Gemini Model Configuration Constants - Focused on 2.5 Series
 */
export const GEMINI_CONFIG = {
  // Latest Gemini 2.5 models with advanced capabilities
  MODELS: {
    // Main model - Latest 2.5 Flash Lite with 1M context, thinking, and all features
    GEMINI_2_5_FLASH_LITE: 'gemini-2.5-flash-lite-preview-06-17', // Primary model
    GEMINI_2_5_PRO: 'gemini-2.5-pro-preview-05-06',
    GEMINI_2_5_FLASH: 'gemini-2.5-flash-preview-05-20'
  },
  // Embedding models with dimension support
  EMBEDDING_MODELS: {
    TEXT_EMBEDDING_004: 'text-embedding-004', // 768 default, supports custom dimensions
    GEMINI_EMBEDDING_EXP: 'gemini-embedding-exp-03-07' // 1536 dimensions, elastic: 3072, 1536, 768
  },
  // Safety settings presets
  SAFETY_PRESETS: {
    STRICT: [
      { category: 'HARM_CATEGORY_HATE_SPEECH' as const, threshold: 'BLOCK_LOW_AND_ABOVE' as const },
      { category: 'HARM_CATEGORY_DANGEROUS_CONTENT' as const, threshold: 'BLOCK_LOW_AND_ABOVE' as const },
      { category: 'HARM_CATEGORY_HARASSMENT' as const, threshold: 'BLOCK_LOW_AND_ABOVE' as const },
      { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT' as const, threshold: 'BLOCK_LOW_AND_ABOVE' as const }
    ],
    MODERATE: [
      { category: 'HARM_CATEGORY_HATE_SPEECH' as const, threshold: 'BLOCK_MEDIUM_AND_ABOVE' as const },
      { category: 'HARM_CATEGORY_DANGEROUS_CONTENT' as const, threshold: 'BLOCK_MEDIUM_AND_ABOVE' as const },
      { category: 'HARM_CATEGORY_HARASSMENT' as const, threshold: 'BLOCK_MEDIUM_AND_ABOVE' as const },
      { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT' as const, threshold: 'BLOCK_MEDIUM_AND_ABOVE' as const }
    ],
    PERMISSIVE: [
      { category: 'HARM_CATEGORY_HATE_SPEECH' as const, threshold: 'BLOCK_ONLY_HIGH' as const },
      { category: 'HARM_CATEGORY_DANGEROUS_CONTENT' as const, threshold: 'BLOCK_ONLY_HIGH' as const },
      { category: 'HARM_CATEGORY_HARASSMENT' as const, threshold: 'BLOCK_ONLY_HIGH' as const },
      { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT' as const, threshold: 'BLOCK_ONLY_HIGH' as const }
    ],
    OFF: [
      { category: 'HARM_CATEGORY_HATE_SPEECH' as const, threshold: 'BLOCK_NONE' as const },
      { category: 'HARM_CATEGORY_DANGEROUS_CONTENT' as const, threshold: 'BLOCK_NONE' as const },
      { category: 'HARM_CATEGORY_HARASSMENT' as const, threshold: 'BLOCK_NONE' as const },
      { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT' as const, threshold: 'BLOCK_NONE' as const }
    ]
  }
} as const;
/**
 * Supported models for explicit caching (using your current model naming)
 * @see https://ai.google.dev/gemini-api/docs/caching
 */
export type GoogleModelCacheableId =
  | 'gemini-2.5-pro-preview-05-06'     // Your GEMINI_2_5_PRO
  | 'gemini-2.5-flash-preview-05-20'   // Your GEMINI_2_5_FLASH
  | 'gemini-2.5-flash-lite-preview-06-17' // Your GEMINI_2_5_FLASH_LITE
  | 'models/gemini-2.5-pro'            // Standard API v5 Beta format
  | 'models/gemini-2.5-flash'          // Standard API v5 Beta format
  | 'models/gemini-2.5-flash-lite'     // Standard API v5 Beta format
// Log provider initialization
logger.info('Google provider configuration loaded', {
  defaultModel: GEMINI_CONFIG.MODELS.GEMINI_2_5_FLASH_LITE,
  availableModels: Object.keys(GEMINI_CONFIG.MODELS).length,
  embeddingModels: Object.keys(GEMINI_CONFIG.EMBEDDING_MODELS).length
});
/**
 * Enhanced base Google model with Gemini 2.5 Flash Lite as default
 * Supports all advanced features via proper AI SDK patterns
 *
 * @param modelId - Gemini model ID (defaults to 2.5 Flash Lite)
 * @param options - Model configuration options
 * @returns Configured Google model instance
 */
export const baseGoogleModel = (
  modelId: string = GEMINI_CONFIG.MODELS.GEMINI_2_5_FLASH_LITE,
  options: {
    useSearchGrounding?: boolean;
    dynamicRetrieval?: boolean;
    safetyLevel?: 'STRICT' | 'MODERATE' | 'PERMISSIVE' | 'OFF';
    cachedContent?: string;
    structuredOutputs?: boolean;
    // Langfuse tracing options
    agentName?: string;
    tags?: string[];
    metadata?: Record<string, unknown>;
    traceName?: string;
  } = {}
) => {
  const {
    useSearchGrounding = false,
    dynamicRetrieval = false,
    safetyLevel = 'MODERATE',
    cachedContent,
    structuredOutputs = true,
    // Langfuse tracing options
    agentName,
    tags = [],
    metadata = {},
    traceName
  } = options;
  // Log model configuration
  logger.debug('Creating Google model instance', {
    modelId,
    useSearchGrounding,
    dynamicRetrieval,
    safetyLevel,
    structuredOutputs,
    agentName,
    traceName
  });
  try {
    const model = baseGoogle(modelId, {
      useSearchGrounding,
      dynamicRetrievalConfig: dynamicRetrieval ? {
        mode: 'MODE_DYNAMIC',
        dynamicThreshold: 0.8
      } : undefined,
      safetySettings: [...GEMINI_CONFIG.SAFETY_PRESETS[safetyLevel]],
      cachedContent,
      structuredOutputs
    });
    // Add Langfuse metadata to the model for automatic tracing
    if (agentName || tags.length > 0 || Object.keys(metadata).length > 0) {
      // Attach metadata that Langfuse can pick up
      (model as Record<string, unknown>).__langfuseMetadata = {
        agentName: agentName || 'unknown',
        tags: [
          'mastra',
          'google',
          'gemini-2.5',
          'dean-machines',
          ...(agentName ? [agentName] : []),
          ...tags
        ],
        metadata: {
          modelId,
          provider: 'google',
          framework: 'mastra',
          project: 'dean-machines-rsc',
          agentName: agentName || 'unknown',
          thinkingBudget: 'dynamic',
          safetyLevel,
          useSearchGrounding,
          dynamicRetrieval,
          structuredOutputs,
          timestamp: new Date().toISOString(),
          traceName: traceName || `${agentName || 'agent'}-${modelId}`,
          ...metadata
        }
      };
      logger.info('Google model configured with Langfuse metadata', {
        modelId,
        agentName,
        traceName: traceName || `${agentName || 'agent'}-${modelId}`,
        tagsCount: tags.length
      });
    }
    logger.info('Google model instance created successfully', { modelId, agentName });
    return model;
  } catch (error) {
    logger.error('Failed to create Google model instance', {
      modelId,
      error: error instanceof Error ? error.message : 'Unknown error',
      agentName
    });
    throw error;
  }
};
/**
 * Create Google provider for Gemini 2.5+ models
 *
 * @param modelId - Gemini 2.5+ model ID
 * @param options - Model configuration options
 * @returns Configured Google model
 *
 * @example Basic usage:
 * ```typescript
 * const model = createGemini25Provider('gemini-2.5-flash-lite-preview-06-17');
 * ```
 *
 * @example With thinking config (use in generateText):
 * ```typescript
 * const result = await generateText({
 *   model: createGemini25Provider('gemini-2.5-flash-lite-preview-06-17'),
 *   providerOptions: {
 *     google: {
 *       thinkingConfig: { thinkingBudget: 2048 }
 *     }
 *   },
 *   prompt: 'Think step by step...'
 * });
 * ```
 */
export function createGemini25Provider(
  modelId: string = GEMINI_CONFIG.MODELS.GEMINI_2_5_FLASH_LITE,
  options: {
    // Thinking capabilities (for backward compatibility with existing agents)
    thinkingConfig?: {
      thinkingBudget?: number;
      includeThoughts?: boolean;
    };
    // Response modalities (for backward compatibility)
    responseModalities?: ('TEXT' | 'IMAGE')[];
    // Search and grounding
    useSearchGrounding?: boolean;
    dynamicRetrieval?: boolean;
    functionCalls?: boolean;
    // Content and caching
    cachedContent?: string;
    // Safety and structure
    safetyLevel?: 'STRICT' | 'MODERATE' | 'PERMISSIVE' | 'OFF';
    structuredOutputs?: boolean;
    // Langfuse tracing options
    agentName?: string;
    tags?: string[];
    metadata?: Record<string, unknown>;
    traceName?: string;
  } = {}
) {
  // Extract the thinking and response modality options (for backward compatibility)
  const { thinkingConfig, responseModalities, ...baseOptions } = options;
  logger.debug('Creating Gemini 2.5 provider', {
    modelId,
    hasThinkingConfig: !!thinkingConfig,
    responseModalities,
    agentName: baseOptions.agentName
  });
  // Note: thinkingConfig and responseModalities should ideally be used in providerOptions
  // but we accept them here for backward compatibility with existing agent code
  // These parameters are intentionally unused but kept for API compatibility
  return baseGoogleModel(modelId, baseOptions);
}
/**
 * Create Google provider with image generation capabilities
 * @param modelId - Model ID (default: gemini-2.0-flash-exp)
 * @param options - Configuration options
 */
export function createGeminiImageProvider(
  modelId: string = GEMINI_CONFIG.MODELS.GEMINI_2_5_FLASH_LITE,
  options: {
    useSearchGrounding?: boolean;
    safetyLevel?: 'STRICT' | 'MODERATE' | 'PERMISSIVE' | 'OFF';
  } = {}
) {
  const { useSearchGrounding = false, safetyLevel = 'MODERATE' } = options;
  return baseGoogle(modelId, {
    useSearchGrounding,
    safetySettings: [...GEMINI_CONFIG.SAFETY_PRESETS[safetyLevel]]
  });
}
/**
 * Create embedding model with flexible dimensions
 * @param modelId - Embedding model ID
 * @param options - Embedding configuration
 */
export function createGeminiEmbeddingModel(
  modelId: string = GEMINI_CONFIG.EMBEDDING_MODELS.GEMINI_EMBEDDING_EXP,
  options: {
    outputDimensionality?: 768 | 1536 | 3072; // Supported dimensions for gemini-embedding-exp-03-07
    taskType?: 'SEMANTIC_SIMILARITY' | 'CLASSIFICATION' | 'CLUSTERING' | 'RETRIEVAL_DOCUMENT' | 'RETRIEVAL_QUERY' | 'QUESTION_ANSWERING' | 'FACT_VERIFICATION' | 'CODE_RETRIEVAL_QUERY';
  } = {}
) {
  const {
    outputDimensionality = 1536, // Default to 1536 to match your setup
    taskType = 'SEMANTIC_SIMILARITY'
  } = options;
  return baseGoogle.textEmbeddingModel(modelId, {
    outputDimensionality,
    taskType
  });
}
/**
 * Main function - auto-detects model version and uses appropriate provider
 * @param modelId - ID of the Google model to use
 * @param options - Optional settings for the provider
 * @returns Google provider instance
 */
/**
 * Create a Mastra-compatible Google provider with proper thinking config support
 *
 * @param modelId - Gemini model ID
 * @param options - Provider configuration options
 * @returns Configured Google provider
 *
 * @example
 * ```typescript
 * // Basic usage
 * const model = createMastraGoogleProvider();
 *
 * // With thinking config (use in generateText providerOptions)
 * const result = await generateText({
 *   model: createMastraGoogleProvider('gemini-2.5-flash-lite-preview-06-17'),
 *   providerOptions: {
 *     google: {
 *       thinkingConfig: { thinkingBudget: 2048 }
 *     }
 *   },
 *   prompt: 'Explain quantum computing'
 * });
 * ```
 */
export function createMastraGoogleProvider(
  modelId: string = GEMINI_CONFIG.MODELS.GEMINI_2_5_FLASH_LITE,
  options: {
    // Search and grounding
    useSearchGrounding?: boolean;
    dynamicRetrieval?: boolean;
    // Content and caching
    cachedContent?: string;
    // Safety and structure
    safetyLevel?: 'STRICT' | 'MODERATE' | 'PERMISSIVE' | 'OFF';
    structuredOutputs?: boolean;
  } = {}
) {
  // Use the enhanced 2.5 provider for all models
  return createGemini25Provider(modelId, options);
}
/**
 * Main Google provider export - defaults to Gemini 2.5 Flash Lite
 * This is the primary export that should be used throughout the application
 *
 * @example Basic usage:
 * ```typescript
 * import { google } from './googleProvider';
 * const model = google('gemini-2.5-flash-lite-preview-06-17');
 * ```
 *
 * @example With thinking config (correct AI SDK pattern):
 * ```typescript
 * import { generateText } from 'ai';
 * import { google } from './googleProvider';
 *
 * const result = await generateText({
 *   model: google('gemini-2.5-flash-lite-preview-06-17'),
 *   providerOptions: {
 *     google: {
 *       thinkingConfig: { thinkingBudget: 2048 },
 *       responseModalities: ['TEXT']
 *     }
 *   },
 *   prompt: 'Think step by step about quantum computing...'
 * });
 * ```
 */
export const google = createMastraGoogleProvider;
export type { GoogleGenerativeAIProviderOptions, GoogleGenerativeAIProviderSettings, GoogleGenerativeAIProviderMetadata };
// ============================
// EXPLICIT CACHING UTILITIES
// ============================
/**
 * Create explicit cache manager for guaranteed cost savings
 * @param apiKey - Google AI API key (optional, uses env var if not provided)
 * @returns GoogleAICacheManager instance
 *
 * @example
 * ```typescript
 * const cacheManager = createCacheManager();
 * ```
 * 
 * [EDIT: 2025-06-22] [BY: GitHub Copilot]
 */
export function createCacheManager(apiKey?: string): GoogleAICacheManager {
  const key = apiKey || process.env.GOOGLE_GENERATIVE_AI_API_KEY;
  if (!key) {
    throw new Error('Google AI API key is required for cache manager');
  }
  logger.info('Creating Google AI cache manager', { hasApiKey: !!key });
  return new GoogleAICacheManager(key);
}
/**
 * Create cached content for explicit caching
 * @param cacheManager - Cache manager instance
 * @param modelId - Model to cache content for
 * @param contents - Content to cache
 * @param ttlSeconds - Time to live in seconds (default: 5 minutes)
 * @returns Promise resolving to cached content name
 * * @example
 * ```typescript
 * const cacheManager = createCacheManager();
 * const cachedContent = await createCachedContent(
 *   cacheManager,
 *   'gemini-2.5-pro-preview-05-06', // Using your model names
 *   [{ role: 'user', parts: [{ text: 'Context...' }] }],
 *   300
 * );
 * ```
 * 
 * [EDIT: 2025-06-22] [BY: GitHub Copilot]
 */
export async function createCachedContent(
  cacheManager: GoogleAICacheManager,
  modelId: GoogleModelCacheableId,
  contents: Array<{ role: 'user' | 'model'; parts: Array<{ text: string }> }>,
  ttlSeconds: number = 300
): Promise<string> {
  try {
    logger.info('Creating cached content', { modelId, ttlSeconds, contentCount: contents.length });
      const { name } = await cacheManager.create({
      model: modelId,
      contents,
      ttlSeconds
    });
    if (!name) {
      throw new Error('Failed to create cached content: no name returned');
    }
    logger.info('Cached content created successfully', { name, modelId });
    return name;
  } catch (error) {
    logger.error('Failed to create cached content', {
      modelId,
      error: error instanceof Error ? error.message : 'Unknown error'
    });
    throw error;
  }
}
/**
 * Enhanced Google model with explicit caching support
 * @param modelId - Cacheable model ID
 * @param options - Enhanced options including cache configuration
 * @returns Configured Google model with caching
 * * @example
 * ```typescript
 * const cacheManager = createCacheManager();
 * const model = await createCachedGoogleModel(
 *   'gemini-2.5-flash-preview-05-20', // Using your model names
 *   {
 *     cacheManager,
 *     cacheContents: [{ role: 'user', parts: [{ text: 'Context...' }] }],
 *     cacheTtlSeconds: 300
 *   }
 * );
 * ```
 * 
 * [EDIT: 2025-06-22] [BY: GitHub Copilot]
 */
export const createCachedGoogleModel = async (
  modelId: GoogleModelCacheableId,
  options: {
    // Cache configuration
    cacheManager?: GoogleAICacheManager;
    cacheContents?: Array<{ role: 'user' | 'model'; parts: Array<{ text: string }> }>;
    cacheTtlSeconds?: number;
    // Standard options (preserving your existing function signature)
    useSearchGrounding?: boolean;
    dynamicRetrieval?: boolean;
    safetyLevel?: 'STRICT' | 'MODERATE' | 'PERMISSIVE' | 'OFF';
    structuredOutputs?: boolean;
    agentName?: string;
    tags?: string[];
    metadata?: Record<string, unknown>;
    traceName?: string;
  } = {}
) => {
  const {
    cacheManager,
    cacheContents,
    cacheTtlSeconds = 300,
    ...baseOptions
  } = options;
  if (cacheManager && cacheContents) {
    // Create cached content and return model with cache
    const cachedContent = await createCachedContent(cacheManager, modelId, cacheContents, cacheTtlSeconds);
    logger.info('Using explicit caching for model', { modelId, cachedContent });
    return baseGoogleModel(modelId, { ...baseOptions, cachedContent });
  }
  // Return regular model without caching
  return baseGoogleModel(modelId, baseOptions);
};
/**
 * Utility to validate model supports caching
 * @param modelId - Model ID to validate
 * @returns Boolean indicating cache support
 * * @example
 * ```typescript
 * if (supportsExplicitCaching('gemini-2.5-pro-preview-05-06')) {
 *   // Can use explicit caching with your models
 * }
 * ```
 * 
 * [EDIT: 2025-06-22] [BY: GitHub Copilot]
 */
export function supportsExplicitCaching(modelId: string): modelId is GoogleModelCacheableId {
  const cacheableModels: GoogleModelCacheableId[] = [
    // Your current model names
    'gemini-2.5-pro-preview-05-06',
    'gemini-2.5-flash-preview-05-20',
    'gemini-2.5-flash-lite-preview-06-17',
    // Standard API format models
    'models/gemini-2.5-pro',
    'models/gemini-2.5-flash',
    'models/gemini-2.5-flash-lite',
  ];
  return cacheableModels.includes(modelId as GoogleModelCacheableId);
}
// ============================
// SEARCH GROUNDING UTILITIES
// ============================
/**
 * Extract and process search grounding metadata from provider response
 * @param providerMetadata - Provider metadata from generateText response
 * @returns Processed grounding information
 *
 * @example
 * ```typescript
 * const { text, providerMetadata } = await generateText({ model, prompt });
 * const grounding = extractGroundingMetadata(providerMetadata);
 * console.log('Search queries:', grounding?.searchQueries);
 * ```
 * 
 * [EDIT: 2025-06-22] [BY: GitHub Copilot]
 */
export function extractGroundingMetadata(providerMetadata?: Record<string, unknown>) {
  if (!providerMetadata?.google || typeof providerMetadata.google !== 'object') {
    return null;
  }
  const googleMetadata = providerMetadata.google as GoogleGenerativeAIProviderMetadata;
  const grounding = googleMetadata.groundingMetadata;
  return {
    searchQueries: grounding?.webSearchQueries || [],
    searchEntryPoint: grounding?.searchEntryPoint?.renderedContent || null,
    groundingSupports: grounding?.groundingSupports?.map(support => ({
      segment: {
        text: support.segment?.text || '',
        startIndex: support.segment?.startIndex || 0,
        endIndex: support.segment?.endIndex || 0
      },
      groundingChunkIndices: support.groundingChunkIndices || [],
      confidenceScores: support.confidenceScores || []
    })) || [],
    safetyRatings: googleMetadata.safetyRatings || []
  };
}
/**
 * Log cache usage statistics from response metadata
 * @param response - Response object from generateText
 * @param logger - Logger instance
 *
 * @example
 * ```typescript
 * const result = await generateText({ model, prompt });
 * logCacheUsage(result.response, logger);
 * ```
 * 
 * [EDIT: 2025-06-22] [BY: GitHub Copilot]
 */
export function logCacheUsage(response: Record<string, unknown>, customLogger = logger) {
  const responseBody = response?.body as Record<string, unknown> | undefined;
  const usageMetadata = responseBody?.usageMetadata as Record<string, unknown> | undefined;  if (usageMetadata?.cachedContentTokenCount && typeof usageMetadata.cachedContentTokenCount === 'number' && 
      usageMetadata.totalTokenCount && typeof usageMetadata.totalTokenCount === 'number') {
    const cacheHitRate = (usageMetadata.cachedContentTokenCount / usageMetadata.totalTokenCount * 100).toFixed(2);
    customLogger.info('Cache hit detected', {
      cachedTokens: usageMetadata.cachedContentTokenCount,
      totalTokens: usageMetadata.totalTokenCount,
      promptTokens: usageMetadata.promptTokenCount,
      candidatesTokens: usageMetadata.candidatesTokenCount,
      cacheHitRate: `${cacheHitRate}%`,
      costSavings: `~${cacheHitRate}%`
    });
  }
}
/**
 * Enhanced search grounding utility with metadata extraction
 * @param prompt - Search query or prompt
 * @param options - Search grounding configuration
 * @returns Promise with response and extracted grounding metadata
 *
 * @example
 * ```typescript
 * const { model, extractGroundingMetadata } = await searchGroundedGeneration(
 *   'What are the latest AI developments?',
 *   { agentName: 'research-agent' }
 * );
 * ```
 * 
 * [EDIT: 2025-06-22] [BY: GitHub Copilot]
 */
export async function searchGroundedGeneration(
  prompt: string,
  options: {
    modelId?: string;
    agentName?: string;
    extractMetadata?: boolean;
    safetyLevel?: 'STRICT' | 'MODERATE' | 'PERMISSIVE' | 'OFF';
  } = {}
) {
  const {
    modelId = GEMINI_CONFIG.MODELS.GEMINI_2_5_FLASH_LITE,
    agentName = 'search-agent',
    extractMetadata = true,
    safetyLevel = 'MODERATE'
  } = options;
  const model = baseGoogleModel(modelId, {
    useSearchGrounding: true,
    dynamicRetrieval: true,
    safetyLevel,
    agentName,
    tags: ['search', 'grounding'],
    traceName: `search-${agentName}`
  });
  try {
    // Return the configured model and helper for metadata extraction
    return {
      model,
      extractGroundingMetadata: (providerMetadata: Record<string, unknown>) => 
        extractMetadata ? extractGroundingMetadata(providerMetadata) : null
    };
  } catch (error) {
    logger.error('Search grounded generation failed', {
      prompt: prompt.substring(0, 100),
      modelId,
      agentName,
      error: error instanceof Error ? error.message : 'Unknown error'
    });
    throw error;
  }
}
</file>

<file path="voltagent/services/context.ts">
/**
 * Context Service for VoltAgent
 * Provides user context management and cross-agent data sharing
 */
/**
 * Simple user context implementation for maintaining state across agent interactions
 */
class UserContextMap extends Map<string, any> {
  constructor() {
    super();
  }
}
/**
 * User Context for maintaining state across agent interactions
 * This context flows through the agent lifecycle and between agents
 */
export const userContext = new UserContextMap();
/**
 * Context Service for managing user sessions and cross-agent data
 */
export class ContextService {
  private context = userContext;
  /**
   * Set a value in the user context
   */
  set(key: string, value: any) {
    this.context.set(key, value);
  }
  /**
   * Get a value from the user context
   */
  get(key: string) {
    return this.context.get(key);
  }
  /**
   * Check if a key exists in the context
   */
  has(key: string): boolean {
    return this.context.has(key);
  }
  /**
   * Delete a key from the context
   */
  delete(key: string): boolean {
    return this.context.delete(key);
  }
  /**
   * Clear all context data
   */
  clear() {
    this.context.clear();
  }
  /**
   * Get all context data as an object
   */
  getAll(): Record<string, any> {
    const data: Record<string, any> = {};
    this.context.forEach((value: any, key: string) => {
      data[key] = value;
    });
    return data;
  }
  /**
   * Initialize session context with user data
   */
  initializeSession(userId: string, sessionId: string, metadata?: Record<string, any>) {
    this.set("userId", userId);
    this.set("sessionId", sessionId);
    this.set("sessionStartTime", new Date().toISOString());
    if (metadata) {
      Object.entries(metadata).forEach(([key, value]) => {
        this.set(key, value);
      });
    }
  }
  /**
   * Get session information
   */
  getSessionInfo() {
    return {
      userId: this.get("userId"),
      sessionId: this.get("sessionId"),
      sessionStartTime: this.get("sessionStartTime"),
      currentAgent: this.get("currentAgent"),
      operationId: this.get("operationId")
    };
  }
  /**
   * Set current agent context
   */
  setCurrentAgent(agentName: string, operation?: string) {
    this.set("currentAgent", agentName);
    this.set("lastAgentChange", new Date().toISOString());
    if (operation) {
      this.set("currentOperation", operation);
    }
  }
  /**
   * Track agent handoffs and delegation flow
   */
  trackHandoff(fromAgent: string, toAgent: string, reason?: string) {
    const handoffs = this.get("handoffs") || [];
    handoffs.push({
      from: fromAgent,
      to: toAgent,
      reason,
      timestamp: new Date().toISOString()
    });
    this.set("handoffs", handoffs);
  }
  /**
   * Store operation results for cross-agent access
   */
  storeResult(operationId: string, result: any, agentName: string) {
    const results = this.get("operationResults") || {};
    results[operationId] = {
      result,
      agentName,
      timestamp: new Date().toISOString()
    };
    this.set("operationResults", results);
  }
  /**
   * Get result from a previous operation
   */
  getResult(operationId: string) {
    const results = this.get("operationResults") || {};
    return results[operationId];
  }
  /**
   * Set user preferences
   */
  setPreferences(preferences: Record<string, any>) {
    this.set("userPreferences", preferences);
  }
  /**
   * Get user preferences
   */
  getPreferences(): Record<string, any> {
    return this.get("userPreferences") || {};
  }
  /**
   * Update a specific preference
   */
  updatePreference(key: string, value: any) {
    const prefs = this.getPreferences();
    prefs[key] = value;
    this.setPreferences(prefs);
  }
}
/**
 * Global context service instance
 */
export const contextService = new ContextService();
/**
 * Helper functions for common context operations
 */
export const contextHelpers = {
  /**
   * Quick session initialization
   */
  initSession: (userId: string, sessionId?: string) => {
    const sid = sessionId || `session-${Date.now()}`;
    contextService.initializeSession(userId, sid);
    return sid;
  },
  /**
   * Track conversation flow
   */
  trackConversation: (conversationId: string, message: string, role: 'user' | 'assistant') => {
    const conversations = contextService.get("conversations") || {};
    if (!conversations[conversationId]) {
      conversations[conversationId] = [];
    }
    conversations[conversationId].push({
      message,
      role,
      timestamp: new Date().toISOString()
    });
    contextService.set("conversations", conversations);
  },
  /**
   * Get conversation history
   */
  getConversation: (conversationId: string) => {
    const conversations = contextService.get("conversations") || {};
    return conversations[conversationId] || [];
  },
  /**
   * Store file or resource references
   */
  storeReference: (type: string, reference: any) => {
    const refs = contextService.get("references") || {};
    if (!refs[type]) {
      refs[type] = [];
    }
    refs[type].push({
      ...reference,
      timestamp: new Date().toISOString()
    });
    contextService.set("references", refs);
  },
  /**
   * Get references by type
   */
  getReferences: (type: string) => {
    const refs = contextService.get("references") || {};
    return refs[type] || [];
  }
};
</file>

<file path="voltagent/services/index.ts">
/**
 * Services Exports
 * Central export point for all VoltAgent services
 */
// Core Services
export { mcpConfig, mcpToolsService, MCPToolsService } from "./mcp";
export { memoryService, MemoryService } from "./memory";
export { 
  documentRetriever, 
  retrieverService, 
  RetrieverService, 
  DocumentRetriever, 
  MemoryRetriever 
} from "./retriever";
// Context Management
export {
  userContext,
  contextService,
  ContextService,
  contextHelpers
} from "./context";
// Hooks
export {
  createAgentHooks,
  createSupervisorHooks,
  createSubAgentHooks,
  defaultAgentHooks
} from "./hooks";
// Service Collections
export const services = {
  mcp: () => import("./mcp").then(m => m.mcpToolsService),
  memory: () => import("./memory").then(m => m.memoryService),
  retriever: () => import("./retriever").then(m => m.retrieverService),
  context: () => import("./context").then(m => m.contextService),
};
</file>

<file path="voltagent/services/memory.ts">
/**
 * Memory Service for VoltAgent
 * Uses LibSQL for persistent storage and conversation management
 */
import { LibSQLStorage } from "@voltagent/core";
/**
 * LibSQL Memory Storage configured for VoltAgent
 * Supports local SQLite files and Turso cloud database
 */
export const memoryStorage = new LibSQLStorage({
  // Use local SQLite file for development, Turso URL for production
  url: process.env.DATABASE_URL || "file:data/voltagent-memory.db",
  // Auth token for Turso (optional for local SQLite)
  authToken: process.env.DATABASE_AUTH_TOKEN,
  // Prefix for all memory tables
  tablePrefix: "voltagent_memory",
  // Keep last 100 messages per conversation (official default)
  storageLimit: 100,
  // Enable debug logging in development
  debug: process.env.NODE_ENV === "development",
});
/**
 * Memory Service wrapper for easier conversation management
 */
export class MemoryService {
  private storage: LibSQLStorage;
  constructor(storage: LibSQLStorage = memoryStorage) {
    this.storage = storage;
  }
  /**
   * Get conversations for a specific user
   */
  async getUserConversations(userId: string, limit = 50) {
    return this.storage.getConversationsByUserId(userId, {
      limit,
      orderBy: "updated_at",
      orderDirection: "DESC",
    });
  }
  /**
   * Get paginated conversations for a user
   */
  async getPaginatedConversations(userId: string, page = 1, pageSize = 20) {
    return this.storage.getPaginatedUserConversations(userId, page, pageSize);
  }
  /**
   * Get messages for a specific conversation with pagination
   */
  async getConversationMessages(conversationId: string, options?: { limit?: number; offset?: number }) {
    return this.storage.getConversationMessages(conversationId, options);
  }
  /**
   * Process messages in batches for large conversations
   */
  async getConversationMessagesBatched(
    conversationId: string, 
    batchSize = 100,
    processor: (batch: any[]) => Promise<void>
  ) {
    let offset = 0;
    let hasMore = true;
    while (hasMore) {
      const batch = await this.storage.getConversationMessages(conversationId, {
        limit: batchSize,
        offset: offset,
      });
      await processor(batch);
      hasMore = batch.length === batchSize;
      offset += batchSize;
    }
  }
  /**
   * Create a new conversation
   */
  async createConversation(conversationData: {
    id: string;
    resourceId: string;
    userId: string;
    title: string;
    metadata?: Record<string, unknown>;
  }) {
    return this.storage.createConversation({
      ...conversationData,
      metadata: conversationData.metadata || {},
    });
  }
  /**
   * Query conversations with filters
   */
  async queryConversations(options: {
    userId?: string;
    resourceId?: string;
    limit?: number;
    offset?: number;
    orderBy?: "created_at" | "updated_at" | "title";
    orderDirection?: "ASC" | "DESC";
  }) {
    return this.storage.queryConversations(options);
  }
  /**
   * Update conversation title or metadata
   */
  async updateConversation(conversationId: string, updates: {
    title?: string;
    metadata?: Record<string, unknown>;
  }) {
    return this.storage.updateConversation(conversationId, updates);
  }
  /**
   * Get specific conversation with user validation
   */
  async getUserConversation(conversationId: string, userId: string) {
    return this.storage.getUserConversation(conversationId, userId);
  }
  /**
   * Delete a conversation and all its messages
   */
  async deleteConversation(conversationId: string) {
    return this.storage.deleteConversation(conversationId);
  }
  /**
   * Clear all messages for a conversation or user
   */
  async clearMessages(options: {
    userId: string;
    conversationId?: string | undefined;
  }) {
    return this.storage.clearMessages(options);  }
  /**
   * Get messages with filtering options
   */
  async getMessages(options: {
    userId: string;
    conversationId: string;
    limit?: number;
    offset?: number;
  }) {
    return this.storage.getMessages(options);
  }
}
export const memoryService = new MemoryService();
</file>

<file path="app/api/chat/route.ts">
import { supervisorAgent, subAgents } from "@/voltagent/agents";
import { mergeIntoDataStream } from "@voltagent/vercel-ui";
import { createDataStreamResponse } from "ai";
export async function POST(req: Request) {
  try {
    const { messages, agentName: requestedAgentName } = await req.json();
    const lastMessage = messages[messages.length - 1];
    const agentToUseName = requestedAgentName || 'supervisor';
    let selectedAgentInstance;
    // Dynamically import and get the agent instance
    if (agentToUseName === 'supervisor') {
      selectedAgentInstance = supervisorAgent; // supervisorAgent is directly imported
    } else if (subAgents && typeof (subAgents as any)[agentToUseName] === 'function') {
      // If it's a sub-agent and it's a function that returns a promise, await it
      selectedAgentInstance = await (subAgents as any)[agentToUseName]();
    } else {
      throw new Error(`Agent '${agentToUseName}' not found or not correctly configured.`);
    }
    if (!selectedAgentInstance || typeof selectedAgentInstance.streamText !== 'function') {
        throw new Error(`Agent '${agentToUseName}' not found or does not support streaming text.`);
    }
    return createDataStreamResponse({
      async execute(dataStream) {
        try {
          const result = await selectedAgentInstance.streamText(lastMessage.content);
          mergeIntoDataStream(dataStream, result.fullStream!); // Fixed syntax: removed 'n'
        } catch (error) {
          console.error("Stream processing error:", error);
          dataStream.writeMessageAnnotation({
            type: "error",
            value: {
              error: error instanceof Error ? error.message : "Unknown error",
            },
          });
        }
      },
      onError: (error) =>
        `VoltAgent stream error: ${error instanceof Error ? error.message : String(error)}`,
    });
  } catch (error) {
    console.error("API route error:", error);
    return new Response(JSON.stringify({ error: "Internal server error" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
</file>

<file path="voltagent/index.ts">
import { VoltAgent, VoltAgentExporter } from "@voltagent/core";
import { NodeSDK } from "@opentelemetry/sdk-node";
import { getNodeAutoInstrumentations } from "@opentelemetry/auto-instrumentations-node";
import { ConsoleSpanExporter } from "@opentelemetry/sdk-trace-base";
import { mathAgent } from "./agents/mathAgent";
import { fileAgent } from "./agents/fileAgent";
import { webAgent } from "./agents/webAgent";
import { devAgent } from "./agents/devAgent";
import { dataAgent } from "./agents/dataAgent";
import { commsAgent } from "./agents/commsAgent";
import { memoryAgent } from "./agents/memoryAgent";
import { supervisorAgent } from "./agents/supervisorAgent";
import { LangfuseExporter } from "@voltagent/langfuse-exporter";
const voltagentPublicKey = process.env.PK;
const voltagentSecretKey = process.env.SK;
// Validate required environment variables
if (!voltagentPublicKey) {
  throw new Error("PK environment variable is required");
}
if (!voltagentSecretKey) {
  throw new Error("SK environment variable is required");
}
new VoltAgent({
  agents: {
    math: mathAgent,
    file: fileAgent,
    web: webAgent,
    dev: devAgent,
    data: dataAgent,
    comms: commsAgent,
    memory: memoryAgent,
    supervisor: supervisorAgent,
  },
  server: {
    autoStart: true,
    enableSwaggerUI: true,
    port: 3141,
  },
  telemetryExporter: [
    new VoltAgentExporter({
      publicKey: voltagentPublicKey,
      secretKey: voltagentSecretKey,
      baseUrl: "https://api.voltagent.dev", // Default URL for the VoltAgent cloud service
    }),
    new LangfuseExporter({
      publicKey: process.env.LANGFUSE_PUBLIC_KEY,
      secretKey: process.env.LANGFUSE_SECRET_KEY,
      baseUrl: process.env.LANGFUSE_BASE_URL,
      debug: true,
    })
  ],
});
 // Initialize OpenTelemetry SDK
    const sdk = new NodeSDK({
      traceExporter: new ConsoleSpanExporter(),
      instrumentations: [getNodeAutoInstrumentations()],
    });
    sdk.start();
// Handle graceful shutdown
process.on("SIGTERM", () => sdk.shutdown());
process.on("SIGINT", () => sdk.shutdown());
</file>

<file path="voltagent/services/mcp.ts">
/**
 * MCP (Model Context Protocol) Tools Service
 * Provides tools from MCP servers for VoltAgent
 * Comprehensive integration with official and community MCP servers
 */
import { MCPConfiguration } from "@voltagent/core";
/**
 * Create MCP servers configuration based on available environment variables
 * Only includes servers that have required credentials or work without them
 */
function createMCPServers() {
  const servers: Record<string, any> = {};
  // ============================
  // ALWAYS AVAILABLE SERVERS (no auth required)
  // ============================
  servers.filesystem = {
    name: "File_System",
    type: "stdio",
    timeout: 60000,
    command: "npx",
    args: ["-y", "@modelcontextprotocol/server-filesystem", process.cwd(), "c:/Users/dm/Documents/deanmachines-volt"],
  };
  servers.memory = {
    name: "Memory",
    type: "stdio",
    command: "npx",
    args: ["-y", "@modelcontextprotocol/server-memory"],
  };
  servers.browser = {
    name: "Browser",
    type: "stdio",
    timeout: 60000,
    command: "npx",
    args: ["-y", "@modelcontextprotocol/server-puppeteer"],
  };
  servers.git = {
    name: "Git",
    type: "stdio",
    timeout: 60000,
    command: "uvx",
    args: ["mcp-server-git", "--repository", process.cwd(), "c:/Users/dm/Documents/deanmachines-volt"],
  };
  servers.docker = {
    name: "Docker",
    type: "stdio",
    timeout: 60000,
    command: "npx",
    args: ["-y", "@modelcontextprotocol/server-docker"],
  };
  servers.everything = {
    name: "Everything",
    type: "stdio",
    timeout: 60000,
    command: "npx",
    args: ["-y", "@modelcontextprotocol/server-everything"],
  };
  servers.voltagent = {
    name: "Voltagent",
    type: "stdio",
    command: "npx",
    args: ["-y", "@voltagent/docs-mcp"],
    timeout: 60000,
    disabled: false
  };
  servers.vibe_check = {
    name: "Vibe_Check",
    timeout: 60000,
    type: "stdio",
    command: "node",
    args: [
      "C:\\Users\\dm\\vibe-check-mcp-server\\build\\index.js"
      ],
    env: {
      GEMINI_API_KEY: process.env.GEMINI_API_KEY,
    },
    disabled: false
  };
  // ============================
  // CONDITIONAL SERVERS (require credentials)
  // ============================
  // GitHub - only if token is available
  if (process.env.GITHUB_TOKEN) {
    servers.github = {
      name: "GitHub",
      timeout: 60000,
      type: "stdio",
      command: "npx",
      args: ["-y", "@modelcontextprotocol/server-github"],
      env: {
        GITHUB_PERSONAL_ACCESS_TOKEN: process.env.GITHUB_TOKEN,
      },
    };
    console.log("‚úÖ GitHub MCP server enabled");
  } else {
    console.log("‚ö†Ô∏è  GitHub MCP server disabled (GITHUB_TOKEN not found)");
  }
  // Brave Search - only if API key is available
  if (process.env.BRAVE_API_KEY) {
    servers.web_search = {
      name: "Brave_Search",
      timeout: 60000,
      type: "stdio", 
      command: "npx",
      args: ["-y", "@modelcontextprotocol/server-brave-search"],
      env: {
        BRAVE_API_KEY: process.env.BRAVE_API_KEY,
      },
    };
    console.log("‚úÖ Brave Search MCP server enabled");
  } else {
    console.log("‚ö†Ô∏è  Brave Search MCP server disabled (BRAVE_API_KEY not found)");
  }
  // PostgreSQL - only if connection string is available
  if (process.env.SUPABASE_URI) {
    servers.postgres = {
      name: "Supabase",
      timeout: 60000,
      type: "stdio",
      command: "npx", 
      args: ["-y", "@modelcontextprotocol/server-postgres"],
      env: {
        POSTGRES_CONNECTION_STRING: process.env.SUPABASE_URI,
      },
    };
    console.log("‚úÖ Supabase MCP server enabled");
  } else {
    console.log("‚ö†Ô∏è  Supabase MCP server disabled (SUPABASE_URI not found)");
  }
  console.log(`üîß MCP Configuration: ${Object.keys(servers).length} servers configured`);
  return servers;
}
/**
 * Enhanced MCP Configuration with conditional server loading
 * Only includes servers that have required credentials or work without them
 */
export const mcpConfig = new MCPConfiguration({
  servers: createMCPServers(),
});
/**
 * Enhanced MCP Tools Service with categorized tool management
 */
export class MCPToolsService {
  private config: MCPConfiguration;
  private tools: any[] = [];
  private toolsByCategory: Map<string, any[]> = new Map();
  private initialized = false;
  constructor(config: MCPConfiguration = mcpConfig) {
    this.config = config;
  }
  /**
   * Initialize and categorize all MCP tools
   */
  async initializeTools(): Promise<any[]> {
    if (this.initialized) {
      return this.tools;
    }
    try {
      console.log("üîß Initializing MCP tools from servers...");
      this.tools = await this.config.getTools();
      // Categorize tools by server type
      this.categorizeTools();
      console.log(`‚úÖ Initialized ${this.tools.length} MCP tools from ${this.toolsByCategory.size} categories`);
      this.logToolsSummary();
      this.initialized = true;
      return this.tools;
    } catch (error) {
      console.error("‚ùå Failed to initialize MCP tools:", error);
      console.log("üîÑ Continuing with empty tools array - agents will work without MCP tools");
      // Set as initialized to prevent retries, but with empty tools
      this.initialized = true;
      this.tools = [];
      return [];
    }
  }
  /**
   * Categorize tools by their originating server name.
   * Assumes tool names are namespaced, e.g., 'filesystem_read_file'.
   */
  private categorizeTools(): void {
    this.toolsByCategory.clear();
    for (const tool of this.tools) {
      // Assumes tool name is in format 'serverName_toolAction'
      const parts = tool.name?.split('_');
      const category = parts && parts.length > 1 ? parts[0] : 'general';
      const existingTools = this.toolsByCategory.get(category) || [];
      existingTools.push(tool);
      this.toolsByCategory.set(category, existingTools);
    }
  }
  /**
   * Log summary of available tools
   */
  private logToolsSummary(): void {
    console.log("üìä MCP Tools Summary:");
    for (const [category, tools] of this.toolsByCategory.entries()) {
      console.log(`   ${category}: ${tools.length} tools`);
    }
  }
  /**
   * Get all tools (safe - never throws)
   */
  getTools(): any[] {
    return this.tools || [];
  }
  /**
   * Get tools by category (safe - never throws)
   */
  getToolsByCategory(category: string): any[] {
    return this.toolsByCategory.get(category) || [];
  }
  /**
   * Safely get tools with fallback for uninitialized state
   */
  async getToolsSafe(): Promise<any[]> {
    if (!this.initialized) {
      try {
        return await this.initializeTools();
      } catch (error) {
        console.warn("‚ö†Ô∏è  Could not initialize MCP tools, returning empty array");
        return [];
      }
    }
    return this.tools || [];
  }
  /**
   * Get filesystem tools
   */
  getFilesystemTools(): any[] {
    return this.getToolsByCategory('filesystem');
  }
  /**
   * Get memory tools
   */
  getMemoryTools(): any[] {
    return this.getToolsByCategory('memory');
  }
  /**
   * Get web browsing tools
   */
  getWebTools(): any[] {
    return this.getToolsByCategory('web');
  }
  /**
   * Get git/version control tools
   */
  getGitTools(): any[] {
    return [...this.getToolsByCategory('git'), ...this.getToolsByCategory('github'), ...this.getToolsByCategory('gitlab')];
  }
  /**
   * Get database tools
   */
  getDatabaseTools(): any[] {
    return this.getToolsByCategory('database');
  }
  /**
   * Get cloud storage tools
   */
  getCloudTools(): any[] {
    return this.getToolsByCategory('cloud');
  }
  /**
   * Get development tools
   */
  getDevelopmentTools(): any[] {
    return this.getToolsByCategory('development');
  }
  /**
   * Get thinking/reasoning tools
   */
  getThinkingTools(): any[] {
    return this.getToolsByCategory('thinking');
  }
  /**
   * Get tools for a specific agent by providing an array of server names
   */
  getToolsForAgent(serverNames: string[]): any[] {
    let agentTools: any[] = [];
    for (const serverName of serverNames) {
      agentTools = [...agentTools, ...this.getToolsByCategory(serverName)];
    }
    return agentTools;
  }
  /**
   * Search tools by name or description (safe - never throws)
   */
  searchTools(query: string): any[] {
    if (!this.tools || this.tools.length === 0) {
      return [];
    }
    const queryLower = query.toLowerCase();
    return this.tools.filter(tool => 
      tool.name?.toLowerCase().includes(queryLower) ||
      tool.description?.toLowerCase().includes(queryLower)
    );
  }
  /**
   * Get tool statistics
   */
  getStats(): {
    totalTools: number;
    categoriesCount: number;
    categories: Record<string, number>;
    topCategories: Array<{ category: string; count: number }>;
  } {
    const categories: Record<string, number> = {};
    for (const [category, tools] of this.toolsByCategory.entries()) {
      categories[category] = tools.length;
    }
    const topCategories = Object.entries(categories)
      .map(([category, count]) => ({ category, count }))
      .sort((a, b) => b.count - a.count)
      .slice(0, 5);
    return {
      totalTools: this.tools.length,
      categoriesCount: this.toolsByCategory.size,
      categories,
      topCategories
    };
  }
  /**
   * Check if tools are initialized
   */
  isInitialized(): boolean {
    return this.initialized;
  }
  /**
   * Reinitialize tools (useful for config changes)
   */
  async reinitialize(): Promise<any[]> {
    this.initialized = false;
    this.tools = [];
    this.toolsByCategory.clear();
    return this.initializeTools();
  }
}
export const toolsets = mcpConfig.getToolsets();
// Export singleton instance
export const mcpToolsService = new MCPToolsService();
// Preload MCP tools on startup
mcpToolsService.initializeTools().catch(error => console.error("Error initializing MCP tools:", error));
</file>

<file path="package.json">
{
  "name": "deanmachines-volt",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "build": "next build",
    "dev": "next dev --turbopack",
    "dev:backend": "tsx watch  --env-file=.env voltagent/index.ts",
    "dev:voltagent": "tsx  --env-file=.env voltagent/index.ts",
    "lint": "next lint",
    "start": "next start",
    "volt": "volt",
    "husky": "husky"
  },
  "dependencies": {
    "@ai-sdk/google": "^1.2.19",
    "@ai-sdk/react": "^1.2.12",
    "@chroma-core/google-gemini": "^0.1.7",
    "@google/generative-ai": "^0.24.1",
    "@libsql/client": "0.15.9",
    "@opentelemetry/auto-instrumentations-node": "^0.60.1",
    "@opentelemetry/sdk-node": "^0.202.0",
    "@opentelemetry/sdk-trace-base": "^2.0.1",
    "@supabase/supabase-js": "^2.50.2",
    "@swagger-api/apidom-parser-adapter-openapi-json-2": "^1.0.0-beta.43",
    "@tailwindcss/postcss": "^4.1.11",
    "@upstash/redis": "^1.35.0",
    "@upstash/search": "^0.1.2",
    "@upstash/semantic-cache": "^1.0.5",
    "@upstash/vector": "^1.2.1",
    "@voltagent/cli": "^0.1.9",
    "@voltagent/langfuse-exporter": "^0.1.4",
    "@voltagent/postgres": "^0.1.6",
    "@voltagent/supabase": "^0.1.12",
    "@voltagent/vercel-ai": "^0.1.13",
    "@voltagent/vercel-ai-exporter": "^0.1.5",
    "@voltagent/vercel-ui": "^0.1.2",
    "ai": "^4.3.16",
    "cheerio": "^1.1.0",
    "chromadb": "^3.0.4",
    "chromadb-default-embed": "^2.14.0",
    "crawlee": "^3.13.8",
    "fast-xml-parser": "^5.2.5",
    "jose": "^6.0.11",
    "js-yaml": "^4.1.0",
    "jsinspect-plus": "^3.1.3",
    "jsonschema": "^1.5.0",
    "langfuse-vercel": "^3.37.6",
    "memfs": "^4.17.2",
    "next": "15.3.4",
    "npm-check-updates": "^18.0.1",
    "octokit": "^5.0.3",
    "papaparse": "^5.5.3",
    "postcss": "^8.5.6",
    "quick-lru": "^7.0.1",
    "react": "^19.1.0",
    "react-dom": "^19.1.0",
    "remark": "^15.0.1",
    "simple-git": "^3.28.0",
    "tailwindcss": "^4.1.11",
    "wikibase-sdk": "^10.2.3",
    "yaml": "^2.8.0",
    "zod": "3.25.67"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3.3.1",
    "@types/js-yaml": "^4.0.9",
    "@types/node": "^20.19.1",
    "@types/papaparse": "^5.3.16",
    "@types/react": "^19.1.8",
    "@types/react-dom": "^19.1.6",
    "@typescript-eslint/eslint-plugin": "^8.35.0",
    "@typescript-eslint/parser": "^8.35.0",
    "@voltagent/core": "^0.1.46",
    "eslint": "^9.29.0",
    "eslint-config-next": "15.3.4",
    "husky": "^9.1.7",
    "ts-node": "^10.9.2",
    "tsx": "^4.20.3",
    "tw-animate-css": "^1.3.4",
    "typescript": "^5.8.3",
    "typescript-eslint": "^8.35.0"
  },
  "overrides": {
    "zod": "3.25.67"
  }
}
</file>

<file path="voltagent/services/retriever.ts">
/**
 * Retriever Service for VoltAgent
 * Provides RAG (Retrieval-Augmented Generation) capabilities
 */
import { BaseRetriever, type BaseMessage, type RetrieveOptions } from "@voltagent/core";
import { LibSQLStorage } from "@voltagent/core";
import { mcpToolsService } from "./mcp";
/**
 * Real Document Retriever - connects to actual document sources
 * Searches through filesystem, databases, or external APIs
 */
export class DocumentRetriever extends BaseRetriever {
  constructor(
    private documentSource: 'filesystem' | 'database' | 'api' = 'filesystem',
    private basePath?: string,
    options?: { toolName?: string; toolDescription?: string }
  ) {
    super(options);
  }
  async retrieve(input: string | BaseMessage[], options: RetrieveOptions): Promise<string> {
    const query = typeof input === "string" ? input : (input[input.length - 1].content as string);
    console.log(`DocumentRetriever: Searching ${this.documentSource} for "${query}"`);    // Store search metadata in userContext if available
    if (options.userContext) {
      const searches = options.userContext.get("searches") as any[] || [];
      searches.push({
        type: this.documentSource,
        query,
        timestamp: new Date().toISOString(),
        retriever: 'DocumentRetriever'
      });
      options.userContext.set("searches", searches);
    }
    try {
      switch (this.documentSource) {
        case 'filesystem':
          return await this.searchFilesystem(query, options);
        case 'database':
          return await this.searchDatabase(query, options);
        case 'api':
          return await this.searchAPI(query, options);
        default:
          return "No document source configured.";
      }
    } catch (error) {
      console.error("Document retrieval error:", error);
        // Store error in userContext if available
      if (options.userContext) {
        const errors = options.userContext.get("retrievalErrors") as any[] || [];
        errors.push({
          retriever: 'DocumentRetriever',
          error: error instanceof Error ? error.message : 'Unknown error',
          timestamp: new Date().toISOString()
        });
        options.userContext.set("retrievalErrors", errors);
      }
      return "Error retrieving documents.";
    }
  }
  private async searchFilesystem(query: string, options: RetrieveOptions): Promise<string> {
    try {
      // Get filesystem tools from MCP service
      const filesystemTools = mcpToolsService.getFilesystemTools();
      if (filesystemTools.length === 0) {
        // Store fallback info in userContext
        if (options.userContext) {
          const references = options.userContext.get("references") as any[] || [];
          references.push({
            source: 'filesystem',
            query,
            status: 'no_tools',
            note: 'MCP filesystem tools not available'
          });
          options.userContext.set("references", references);
        }
        return "Filesystem tools not available. Please ensure MCP filesystem server is configured.";
      }
      // Use basePath for search scope if provided
      const searchPath = this.basePath || process.cwd();
      console.log(`Searching filesystem in: ${searchPath} for query: "${query}"`);
      // Try to find relevant files by listing directories and searching file contents
      const searchResults: string[] = [];
      // Look for list_directory tool
      const listDirTool = filesystemTools.find(tool => 
        tool.name?.includes('list_directory') || tool.name?.includes('list_dir')
      );
      // Look for read_file tool  
      const readFileTool = filesystemTools.find(tool =>
        tool.name?.includes('read_file') || tool.name?.includes('read')
      );
      if (listDirTool) {
        try {
          // List files in the search directory
          const listResult = await listDirTool.execute({ path: searchPath });
          searchResults.push(`Directory listing for ${searchPath}:`);
          searchResults.push(listResult);
        } catch (error) {
          console.warn("Failed to list directory:", error);
        }
      }
      // If we have read capability, try to search file contents
      if (readFileTool && searchResults.length > 0) {
        try {
          // Look for common file types that might contain relevant info
          const commonFiles = ['README.md', 'package.json', '.env.example', 'tsconfig.json'];
          for (const fileName of commonFiles) {
            try {
              const filePath = `${searchPath}/${fileName}`;
              const content = await readFileTool.execute({ path: filePath });
              // Simple text search in file content
              if (content && typeof content === 'string' && 
                  content.toLowerCase().includes(query.toLowerCase())) {
                searchResults.push(`\n**Found in ${fileName}:**`);
                // Extract relevant lines (simple implementation)
                const lines = content.split('\n');
                const relevantLines = lines.filter(line => 
                  line.toLowerCase().includes(query.toLowerCase())
                ).slice(0, 3);
                searchResults.push(relevantLines.join('\n'));
              }
            } catch (error) {
              // File might not exist, continue with next file
              continue;
            }
          }
        } catch (error) {
          console.warn("Failed to search file contents:", error);
        }
      }
      // Store search results in userContext
      if (options.userContext) {
        const references = options.userContext.get("references") as any[] || [];
        references.push({
          source: 'filesystem',
          query,
          searchPath,
          status: 'completed',
          toolsUsed: filesystemTools.map(t => t.name),
          resultsCount: searchResults.length
        });
        options.userContext.set("references", references);
      }
      if (searchResults.length > 0) {
        return `## Filesystem Search Results\n\n${searchResults.join('\n')}`;
      } else {
        return `No files found containing "${query}" in ${searchPath}`;
      }
    } catch (error) {
      console.error("Filesystem search error:", error);
      // Store error in userContext
      if (options.userContext) {
        const references = options.userContext.get("references") as any[] || [];
        references.push({
          source: 'filesystem',
          query,
          status: 'error',
          error: error instanceof Error ? error.message : 'Unknown error'
        });
        options.userContext.set("references", references);
      }
      return `Error searching filesystem: ${error instanceof Error ? error.message : 'Unknown error'}`;
    }
  }
  private async searchDatabase(query: string, options: RetrieveOptions): Promise<string> {
    // TODO: Implement real database search using vector embeddings
    // This would use a vector database like Qdrant, Pinecone, or Supabase Vector
      // Store references in userContext if available
    if (options.userContext) {
      const references = options.userContext.get("references") as any[] || [];
      references.push({
        source: 'database',
        query,
        status: 'not_implemented',
        note: 'Requires vector database setup'
      });
      options.userContext.set("references", references);
    }
    return "Database search not yet implemented - requires vector database setup.";
  }
  private async searchAPI(query: string, options: RetrieveOptions): Promise<string> {
    try {
      // Get web search tools from MCP service (like Brave Search)
      const webTools = mcpToolsService.getWebTools();
      if (webTools.length === 0) {
        // Store fallback info in userContext
        if (options.userContext) {
          const references = options.userContext.get("references") as any[] || [];
          references.push({
            source: 'api',
            query,
            status: 'no_tools',
            note: 'MCP web search tools not available'
          });
          options.userContext.set("references", references);
        }
        return "Web search tools not available. Please ensure MCP web search server is configured.";
      }
      // Look for web search tool (Brave Search or similar)
      const searchTool = webTools.find(tool => 
        tool.name?.includes('search') || 
        tool.name?.includes('brave') ||
        tool.name?.includes('web')
      );
      if (!searchTool) {
        if (options.userContext) {
          const references = options.userContext.get("references") as any[] || [];
          references.push({
            source: 'api',
            query,
            status: 'no_search_tool',
            note: 'No web search tool found in MCP tools'
          });
          options.userContext.set("references", references);
        }
        return "No web search tool found in available MCP tools.";
      }
      console.log(`Searching web using ${searchTool.name} for query: "${query}"`);
      // Execute web search
      const searchResults = await searchTool.execute({ 
        query: query,
        count: 5 // Limit results
      });
      // Store search results in userContext
      if (options.userContext) {
        const references = options.userContext.get("references") as any[] || [];
        references.push({
          source: 'api',
          query,
          status: 'completed',
          toolUsed: searchTool.name,
          timestamp: new Date().toISOString()
        });
        options.userContext.set("references", references);
      }
      if (searchResults && typeof searchResults === 'string' && searchResults.length > 0) {
        return `## Web Search Results\n\n${searchResults}`;
      } else if (searchResults && typeof searchResults === 'object') {
        // Handle structured search results
        const formattedResults = JSON.stringify(searchResults, null, 2);
        return `## Web Search Results\n\n\`\`\`json\n${formattedResults}\n\`\`\``;
      } else {
        return `No web search results found for "${query}"`;
      }
    } catch (error) {
      console.error("API search error:", error);
      // Store error in userContext
      if (options.userContext) {
        const references = options.userContext.get("references") as any[] || [];
        references.push({
          source: 'api',
          query,
          status: 'error',
          error: error instanceof Error ? error.message : 'Unknown error'
        });
        options.userContext.set("references", references);
      }
      return `Error searching web: ${error instanceof Error ? error.message : 'Unknown error'}`;
    }
  }
}
/**
 * Memory-based Retriever - Real implementation using LibSQL
 * Searches through conversation history and stored memories
 */
export class MemoryRetriever extends BaseRetriever {
  constructor(
    private memoryStorage: LibSQLStorage,
    options?: { toolName?: string; toolDescription?: string }
  ) {
    super(options);
  }
  async retrieve(input: string | BaseMessage[], options: RetrieveOptions): Promise<string> {
    const query = typeof input === "string" ? input : (input[input.length - 1].content as string);
    console.log(`MemoryRetriever: Searching memory for "${query}"`);    // Track retrieval in userContext if available
    if (options.userContext) {
      const retrievals = options.userContext.get("memoryRetrievals") as any[] || [];
      retrievals.push({
        query,
        timestamp: new Date().toISOString(),
        retriever: 'MemoryRetriever'
      });
      options.userContext.set("memoryRetrievals", retrievals);
    }
    try {
      // Get userId from userContext or use default
      const userId = options.userContext?.get("userId") as string || "default";
      // Get recent conversations from LibSQL storage
      const conversations = await this.memoryStorage.getConversationsByUserId(userId, {
        limit: 10,
        orderBy: "updated_at",
        orderDirection: "DESC",
      });
      // Filter conversations that might be relevant to the query
      const queryLower = query.toLowerCase();
      const relevantMemories = conversations.filter((conv) => {
        const searchText = `${conv.title || ''} ${conv.metadata?.summary || ''}`.toLowerCase();
        return searchText.includes(queryLower) || 
              queryLower.split(' ').some(word => searchText.includes(word));
      });
      if (relevantMemories.length > 0) {
        // Get detailed messages for relevant conversations
        const memoryDetails = await Promise.all(
          relevantMemories.slice(0, 3).map(async (conv) => {
            const messages = await this.memoryStorage.getConversationMessages(conv.id, { limit: 5 });
            return {
              title: conv.title || `Conversation ${conv.id.slice(0, 8)}`,
              date: conv.updatedAt,
              summary: conv.metadata?.summary || messages.slice(-2).map(m => m.content).join(' '),
              messageCount: messages.length,
            };
          })
        );
        const memoryContext = memoryDetails
          .map((memory) => `**${memory.title}** (${memory.date})\nSummary: ${memory.summary}\nMessages: ${memory.messageCount}`)
          .join("\n\n");        // Store successful retrieval results in userContext
        if (options.userContext) {
          const references = options.userContext.get("references") as any[] || [];
          references.push(...memoryDetails.map(memory => ({
            title: memory.title,
            date: memory.date,
            type: 'conversation_memory',
            messageCount: memory.messageCount
          })));
          options.userContext.set("references", references);
          // Store retrieval metadata
          options.userContext.set("lastMemoryRetrieval", {
            query,
            memoriesFound: relevantMemories.length,
            userId,
            timestamp: new Date().toISOString()
          });
        }
        return `## Recent Relevant Memories\n\n${memoryContext}`;
      }
      // Store no results found in userContext
      if (options.userContext) {
        options.userContext.set("lastMemoryRetrieval", {
          query,
          memoriesFound: 0,
          userId,
          timestamp: new Date().toISOString()
        });
      }
      return "No relevant memories found in conversation history.";
    } catch (error) {
      console.error("Memory retrieval error:", error);
        // Store error in userContext if available
      if (options.userContext) {
        const errors = options.userContext.get("retrievalErrors") as any[] || [];
        errors.push({
          retriever: 'MemoryRetriever',
          error: error instanceof Error ? error.message : 'Unknown error',
          timestamp: new Date().toISOString()
        });
        options.userContext.set("retrievalErrors", errors);
      }
      return "Error accessing memory storage.";
    }
  }
}
/**
 * Retriever Service for managing multiple retrievers
 */
export class RetrieverService {
  private retrievers: Map<string, BaseRetriever> = new Map();
  /**
   * Register a retriever with a name
   */
  registerRetriever(name: string, retriever: BaseRetriever) {
    this.retrievers.set(name, retriever);
    console.log(`Registered retriever: ${name}`);
  }
  /**
   * Get a specific retriever by name
   */
  getRetriever(name: string): BaseRetriever | undefined {
    return this.retrievers.get(name);
  }
  /**
   * Get all registered retrievers
   */
  getAllRetrievers(): BaseRetriever[] {
    return Array.from(this.retrievers.values());
  }
  /**
   * Get retriever tools for use in agents
   */
  getRetrieverTools() {
    return Array.from(this.retrievers.values()).map(retriever => retriever.tool);
  }
}
// Pre-configured retrievers
export const documentRetriever = new DocumentRetriever(
  'filesystem',
  process.cwd(),
  {
    toolName: "search_docs",
    toolDescription: "Searches real documents using filesystem, database, or API sources.",
  }
);
export const retrieverService = new RetrieverService();
// Register default retrievers
retrieverService.registerRetriever("documents", documentRetriever);
</file>

<file path="voltagent/agents/mathAgent.ts">
import { Agent, createPrompt, createReasoningTools } from "@voltagent/core";
import { VercelAIProvider } from "@voltagent/vercel-ai";
import { google } from "../config/googleProvider";
import { calculatorTool } from "../tools";
import { createSubAgentHooks } from "../services/hooks";
import { memoryStorage } from "../services/memory";
// Create dynamic prompt for mathematical tasks
const mathPrompt = createPrompt({
  template: `You are a mathematical specialist. You can:
- Perform complex calculations and mathematical operations
- Solve algebraic, geometric, and calculus problems
- Analyze mathematical patterns and relationships
- Provide step-by-step mathematical explanations
- Handle statistical and financial calculations
Problem Type: {{problem_type}}
Complexity Level: {{complexity}}
Approach: {{approach}}
{{math_strategy}}
Always use 'think' to break down complex mathematical problems into steps. Use 'analyze' to verify calculations and ensure accuracy.`,
  variables: {
    problem_type: "general mathematics",
    complexity: "moderate",
    approach: "step-by-step",
    math_strategy: "Show work clearly and verify results. Use the calculator tool for precise computations."
  }
});
// Create reasoning tools for mathematical analysis
const mathReasoningTools = createReasoningTools({
  think: true,
  analyze: false,
  addInstructions: false,
  addFewShot: false
});
/**
 * Math Assistant Agent
 * Specialized agent for mathematical calculations and problem-solving
 * Uses Gemini Flash Lite for fast mathematical reasoning
 */
export const mathAgent = new Agent({
  name: "MathAssistant",
  purpose: "To perform mathematical calculations and solve complex math problems.",
  description: "Specialized agent for mathematical calculations and problem-solving with structured reasoning.",
  instructions: mathPrompt(),
  llm: new VercelAIProvider(),
  model: google("gemini-2.5-flash-lite-preview-06-17"),
  tools: [mathReasoningTools, calculatorTool],
  hooks: createSubAgentHooks("MathAssistant", "mathematical calculations", {
    verbose: true, // Set to true for debugging math operations
    performance: true,
    analytics: true,
    logPrefix: "[VoltAgent:Math]"
  }),
  markdown: true,
  // Memory for tracking calculation history and mathematical context
  memory: memoryStorage,
  thinkingConfig: {
    thinkingBudget: 0,
    includeThoughts: false
  },
  structuredOutputs: true // Enable structured outputs for better mathematical reasoning and results
});
</file>

<file path="voltagent/services/hooks.ts">
/**
 * Hooks Service for VoltAgent
 * Provides lifecycle hooks for agents with proper logging and context management
 * Enhanced with VoltAgent best practices for observability and error handling
 */
import { 
  createHooks, 
  type OnStartHookArgs, 
  type OnEndHookArgs, 
  type OnToolStartHookArgs, 
  type OnToolEndHookArgs, 
  type OnHandoffHookArgs,
  type VoltAgentError
} from "@voltagent/core";
/**
 * Hook configuration options for customizing behavior
 */
export interface HookConfig {
  /** Enable verbose logging with detailed context */
  verbose?: boolean;
  /** Enable performance monitoring with timing metrics */
  performance?: boolean;
  /** Enable tool usage analytics */
  analytics?: boolean;
  /** Prefix for log messages */
  logPrefix?: string;
  /** Custom operation ID generator */
  operationIdGenerator?: () => string;
}
/**
 * Create comprehensive hooks for agent lifecycle management
 * Includes logging, context tracking, and observability
 */
export const createAgentHooks = (agentName: string, config: HookConfig = {}) => {
  const {
    verbose = false,
    performance = true,
    analytics = true,
    logPrefix = "[VoltAgent]",
    operationIdGenerator = () => `op-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`
  } = config;
  return createHooks({
    /**
     * Called before the agent starts processing a request
     */
    onStart: async (args: OnStartHookArgs) => {
      const { agent, context } = args;
      // Use the agentName parameter
      const effectiveName = agentName || agent.name;
      // Generate unique operation ID
      const operationId = operationIdGenerator();
      const startTime = new Date().toISOString();
      // Initialize tracking data in userContext
      context.userContext.set("operationId", operationId);
      context.userContext.set("startTime", startTime);
      context.userContext.set("agentName", effectiveName);
      context.userContext.set("performanceMetrics", {
        startTime: Date.now(),
        toolExecutions: [],
        tokenUsage: 0
      });
      console.log(`üöÄ ${logPrefix} [${effectiveName}] Starting operation at ${startTime}`);
      console.log(`   Operation ID: ${operationId}`);
      if (verbose) {
        console.log(`   Agent ID: ${agent.id || 'N/A'}`);
        console.log(`   Context: ${JSON.stringify({ operationId: context.operationId }, null, 2)}`);
      }
    },    /**
     * Called after the agent finishes processing a request
     */
    onEnd: async (args: OnEndHookArgs) => {
      const { agent, output, error, context } = args;
      const operationId = context.userContext.get("operationId");
      const startTime = context.userContext.get("startTime");
      const performanceMetrics = context.userContext.get("performanceMetrics") || {};
      if (error) {
        console.error(`‚ùå ${logPrefix} [${agent.name}] Operation ${operationId} failed:`, error.message);
        // Enhanced error tracking with userContext
        context.userContext.set("error", {
          message: error.message,
          type: error.constructor.name,
          timestamp: new Date().toISOString(),
          details: verbose ? JSON.stringify(error) : undefined
        });
        // Log conversation context on error if available
        if (verbose) {
          console.error(`   Error Details:`, JSON.stringify(error, null, 2));
        }
      } else if (output) {
        const endTime = new Date().toISOString();
        const duration = startTime ? Date.now() - new Date(startTime).getTime() : 0;
        console.log(`‚úÖ ${logPrefix} [${agent.name}] Operation ${operationId} completed successfully`);
        // Enhanced success tracking
        context.userContext.set("endTime", endTime);
        context.userContext.set("success", true);
        context.userContext.set("duration", duration);
        // Performance logging
        if (performance) {
          console.log(`   Duration: ${duration}ms`);
        }
        // Token usage tracking (enhanced)
        if ("usage" in output && output.usage) {
          const tokenUsage = output.usage.totalTokens;
          console.log(`   Token Usage: ${tokenUsage} tokens`);
          context.userContext.set("tokenUsage", tokenUsage);
          if (analytics) {
            context.userContext.set("tokenBreakdown", {
              prompt: output.usage.promptTokens,
              completion: output.usage.completionTokens,
              total: tokenUsage
            });
          }
        }
        // Output type analysis
        if (verbose) {
          if ("text" in output && output.text) {
            console.log(`   Output type: text (${output.text.length} chars)`);
          } else if ("object" in output && output.object) {
            console.log(`   Output type: object (keys: ${Object.keys(output.object).join(", ")})`);
          }
        }
        // Enhanced operation tracking
        if (analytics) {
          const operationSummary = {
            operationId,
            agentName: agent.name,
            duration,
            tokenUsage: ("usage" in output && output.usage) ? output.usage.totalTokens : 0,
            success: true,
            timestamp: endTime
          };
          context.userContext.set("operationSummary", operationSummary);
          if (verbose) {
            console.log(`   Operation summary:`, JSON.stringify(operationSummary, null, 2));
          }
        }
        // Performance metrics summary
        if (performance && performanceMetrics.toolExecutions) {
          const toolCount = performanceMetrics.toolExecutions.length;
          if (toolCount > 0) {
            console.log(`   Tools executed: ${toolCount}`);
          }
        }
      }
    },/**
     * Called just before a tool's execute function is called
     */
    onToolStart: async (args: OnToolStartHookArgs) => {
      const { agent, tool, context } = args;
      const operationId = context.userContext.get("operationId");
      const performanceMetrics = context.userContext.get("performanceMetrics") || { toolExecutions: [] };
      console.log(`üîß ${logPrefix} [${agent.name}] Starting tool: ${tool.name} (${operationId})`);
      // Enhanced tool tracking
      const toolExecution = {
        name: tool.name,
        startTime: new Date().toISOString(),
        startTimestamp: Date.now()
      };
      // Track tool usage in userContext
      const toolsInProgress = context.userContext.get("toolsInProgress") || [];
      toolsInProgress.push(toolExecution);
      context.userContext.set("toolsInProgress", toolsInProgress);
      // Update performance metrics
      performanceMetrics.toolExecutions.push(toolExecution);
      context.userContext.set("performanceMetrics", performanceMetrics);
      if (verbose) {
        console.log(`   Tool description: ${tool.description || 'N/A'}`);
      }
    },
    /**
     * Called after a tool's execute function completes or throws
     */
    onToolEnd: async (args: OnToolEndHookArgs) => {
      const { agent, tool, output, error, context } = args;
      const operationId = context.userContext.get("operationId");
      const toolsInProgress = context.userContext.get("toolsInProgress") || [];
      const performanceMetrics = context.userContext.get("performanceMetrics") || { toolExecutions: [] };
      // Find and update the tool execution record
      const toolIndex = toolsInProgress.findIndex((t: any) => t.name === tool.name);
      if (toolIndex >= 0) {
        const toolExecution = toolsInProgress[toolIndex];
        const duration = Date.now() - toolExecution.startTimestamp;
        if (error) {
          console.error(`üí• ${logPrefix} [${agent.name}] Tool ${tool.name} failed: ${error.message} (${operationId})`);
          console.error(`   Duration: ${duration}ms`);
            // Enhanced tool error tracking
          const toolErrors = context.userContext.get("toolErrors") || [];
          toolErrors.push({
            toolName: tool.name,
            error: error.message,
            duration,
            timestamp: new Date().toISOString(),
            details: verbose ? JSON.stringify(error) : undefined
          });
          context.userContext.set("toolErrors", toolErrors);
          // Update tool execution record
          toolExecution.error = error.message;
          toolExecution.duration = duration;
        } else {
          console.log(`‚ö° ${logPrefix} [${agent.name}] Tool ${tool.name} completed successfully (${operationId})`);
          if (performance) {
            console.log(`   Duration: ${duration}ms`);
          }
          // Enhanced tool success tracking
          const completedTools = context.userContext.get("completedTools") || [];
          completedTools.push({
            name: tool.name,
            result: verbose ? output : (typeof output === 'string' ? output.slice(0, 100) + '...' : '[Object]'),
            duration,
            timestamp: new Date().toISOString()
          });
          context.userContext.set("completedTools", completedTools);
          // Update tool execution record
          toolExecution.success = true;
          toolExecution.duration = duration;
          if (verbose && output) {
            console.log(`   Result preview:`, typeof output === 'string' ? output.slice(0, 200) + '...' : JSON.stringify(output).slice(0, 200) + '...');
          }
        }
        // Remove from in-progress and update performance metrics
        toolsInProgress.splice(toolIndex, 1);
        context.userContext.set("toolsInProgress", toolsInProgress);
        context.userContext.set("performanceMetrics", performanceMetrics);
      }
    },    /**
     * Called when a task is handed off from a source agent to this agent
     */
    onHandoff: async (args: OnHandoffHookArgs) => {
      const { agent } = args;
      console.log(`üîÑ ${logPrefix} Task handed off to ${agent.name}`);
      if (verbose) {
        console.log(`   Handoff context: Task delegated to '${agent.name}'`);
      }
    },
  });
};
/**
 * Specialized hooks for supervisor agents with enhanced delegation tracking
 */
export const createSupervisorHooks = (supervisorName: string, config: HookConfig = {}) => {
  const { logPrefix = "[VoltAgent:Supervisor]", verbose = false, analytics = true } = config;
  return createHooks({
    onStart: async ({ agent, context }: OnStartHookArgs) => {
      console.log(`üëë ${logPrefix} [${supervisorName}/${agent.name}] Starting coordination operation`);
      // Enhanced supervisor tracking
      const supervisorContext = {
        supervisorOperationId: `sup-${Date.now()}-${Math.random().toString(36).substring(2, 6)}`,
        delegationCount: 0,
        subAgentResults: [],
        coordinationStartTime: Date.now()
      };
      Object.entries(supervisorContext).forEach(([key, value]) => {
        context.userContext.set(key, value);
      });
      if (verbose) {
        console.log(`   Supervisor Context: ${JSON.stringify(supervisorContext, null, 2)}`);
      }
    },
    onEnd: async ({ agent, output, error, context }: OnEndHookArgs) => {
      const delegationCount = context.userContext.get("delegationCount") || 0;
      const coordinationStartTime = context.userContext.get("coordinationStartTime");
      const duration = coordinationStartTime ? Date.now() - coordinationStartTime : 0;
      const subAgentResults = context.userContext.get("subAgentResults") || [];
      if (error) {
        console.error(`üëë‚ùå ${logPrefix} [${supervisorName}/${agent.name}] Coordination failed after ${delegationCount} delegations:`, error.message);
        console.error(`   Duration: ${duration}ms`);
        if (analytics) {
          context.userContext.set("supervisorMetrics", {
            success: false,
            delegationCount,
            duration,
            subAgentResults: subAgentResults.length,
            error: error.message
          });
        }
      } else if (output) {
        console.log(`üëë‚úÖ ${logPrefix} [${supervisorName}/${agent.name}] Coordination completed with ${delegationCount} delegations`);
        console.log(`   Duration: ${duration}ms`);
        console.log(`   SubAgent results: ${subAgentResults.length}`);
        if (analytics) {
          context.userContext.set("supervisorMetrics", {
            success: true,
            delegationCount,
            duration,
            subAgentResults: subAgentResults.length,
            totalTokens: ("usage" in output && output.usage) ? output.usage.totalTokens : 0
          });
        }
        if (verbose && subAgentResults.length > 0) {
          console.log(`   SubAgent breakdown:`, subAgentResults.map((r: any) => `${r.agent}: ${r.success ? '‚úÖ' : '‚ùå'}`).join(', '));
        }
      }
    },    onToolStart: async ({ tool, context }: OnToolStartHookArgs) => {
      // Only increment for the specific delegation tool
      if (tool.name === 'delegate_task') {
        const delegationCount = context.userContext.get("delegationCount") || 0;
        context.userContext.set("delegationCount", delegationCount + 1);
        console.log(`üëëüîÑ ${logPrefix} [${supervisorName}] Delegating task (delegation #${delegationCount + 1})`);
      }
    },
    onHandoff: async ({ agent }: OnHandoffHookArgs) => {
      console.log(`üëëü§ù ${logPrefix} [${supervisorName}] Handing off to ${agent.name}`);
      if (verbose) {
        console.log(`   Handoff: ${supervisorName} ‚Üí ${agent.name}`);
      }
    },
  });
};
/**
 * Specialized hooks for sub-agents with enhanced specialty tracking
 */
export const createSubAgentHooks = (subAgentName: string, specialty: string, config: HookConfig = {}) => {
  const { logPrefix = "[VoltAgent:SubAgent]", verbose = false, analytics = true } = config;
  return createHooks({
    onStart: async ({ agent, context }: OnStartHookArgs) => {
      const parentOp = context.userContext.get("supervisorOperationId");
      const delegationCount = context.userContext.get("delegationCount") || 0;
      // Enhanced sub-agent context
      context.userContext.set("subAgentSpecialty", specialty);
      context.userContext.set("subAgentStartTime", Date.now());
      context.userContext.set("subAgentName", subAgentName);
      console.log(`ü§ñ ${logPrefix} [${subAgentName}/${agent.name}] Handling ${specialty} task (delegation #${delegationCount}, parent: ${parentOp})`);
      if (verbose) {
        console.log(`   Specialty: ${specialty}`);
        console.log(`   Parent operation: ${parentOp}`);
      }
    },
    onEnd: async ({ agent, output, error, context }: OnEndHookArgs) => {
      const specialty = context.userContext.get("subAgentSpecialty");
      const startTime = context.userContext.get("subAgentStartTime");
      const duration = startTime ? Date.now() - startTime : 0;
      const delegationCount = context.userContext.get("delegationCount") || 0;
      if (error) {
        console.error(`ü§ñ‚ùå ${logPrefix} [${subAgentName}/${agent.name}] Failed ${specialty} task: ${error.message}`);
        console.error(`   Duration: ${duration}ms`);
        if (analytics) {
          // Track sub-agent result for supervisor
          const subAgentResults = context.userContext.get("subAgentResults") || [];
          subAgentResults.push({
            agent: subAgentName,
            specialty,
            success: false,
            duration,
            error: error.message,
            delegationNumber: delegationCount
          });
          context.userContext.set("subAgentResults", subAgentResults);
        }
      } else if (output) {
        console.log(`ü§ñ‚úÖ ${logPrefix} [${subAgentName}/${agent.name}] Completed ${specialty} task successfully`);
        console.log(`   Duration: ${duration}ms`);
        if (analytics) {
          // Track sub-agent result for supervisor
          const subAgentResults = context.userContext.get("subAgentResults") || [];
          subAgentResults.push({
            agent: subAgentName,
            specialty,
            success: true,
            duration,
            tokenUsage: ("usage" in output && output.usage) ? output.usage.totalTokens : 0,
            delegationNumber: delegationCount
          });
          context.userContext.set("subAgentResults", subAgentResults);
        }
        if (verbose && "usage" in output && output.usage) {
          console.log(`   Token usage: ${output.usage.totalTokens}`);
        }
      }
    },
  });
};
/**
 * Create hooks with conversation flow tracking (enhanced for UI integration)
 */
export const createConversationHooks = (agentName: string, config: HookConfig = {}) => {
  const { analytics = true, verbose = false } = config;
  return createHooks({
    onEnd: async ({ agent, output, error, context }: OnEndHookArgs) => {
      if (!analytics) return;
      // Enhanced conversation tracking following VoltAgent docs pattern
      if (!error && output) {
        const conversationData = {
          operationId: context.operationId,
          agentName: agentName || agent.name,
          usage: ("usage" in output && output.usage) ? output.usage : undefined,
          timestamp: new Date().toISOString(),
          success: true
        };
        // Store for potential UI integration or analytics
        context.userContext.set("conversationSnapshot", conversationData);
        if (verbose) {
          console.log(`üìä Conversation tracked for agent: ${agentName || agent.name}`);
        }
      }
    }
  });
};
/**
 * Default hooks for general agents with basic configuration
 */
export const defaultAgentHooks = createAgentHooks("DefaultAgent", { verbose: false, performance: true, analytics: true });
</file>

<file path="voltagent/agents/devAgent.ts">
import { Agent, createPrompt, createReasoningTools } from "@voltagent/core";
import { VercelAIProvider } from "@voltagent/vercel-ai";
import { google } from "../config/googleProvider";
import { mcpToolsService } from "../services/mcp";
import { createSubAgentHooks } from "../services/hooks";
import { memoryStorage } from "../services/memory";
import { MemoryRetriever } from "../services/retriever";
// Create dynamic prompt for development tasks
const developmentPrompt = createPrompt({
  template: `You are a software development specialist. You can:
- Manage Git repositories (commit, push, pull, merge, status, diff)
- Work with GitHub and GitLab (repos, issues, PRs, projects)
- Handle Docker containers and development environments
- Perform code analysis, review, and optimization
- Manage development workflows and CI/CD processes
- Debug issues and troubleshoot development problems
- Set up and configure development tools
Project Type: {{project_type}}
Development Phase: {{phase}}
Technology Stack: {{tech_stack}}
{{development_strategy}}
Always use 'think' to analyze requirements and plan development approach. Use 'analyze' to evaluate code quality and determine next steps. Follow best practices for version control and code quality.`,
  variables: {
    project_type: "web application",
    phase: "development",
    tech_stack: "modern web technologies",
    development_strategy: "Write clean, maintainable code following industry standards. Test thoroughly and document appropriately."
  }
});
// Create reasoning tools for development analysis
const devReasoningTools = createReasoningTools({
  think: true,
  analyze: true,
  addInstructions: true,
  addFewShot: true
});
/**
 * Development Agent
 * Handles code development, version control, DevOps, and development tools
 * Uses Git, GitHub, GitLab, Docker, and development MCP tools
 */
export const devAgent = new Agent({
  name: "Developer",
  purpose: "To handle software development tasks, including version control, DevOps, and code management.",
  description: "Specialized agent for software development, version control, and DevOps operations with structured problem-solving",
  instructions: developmentPrompt(),
  llm: new VercelAIProvider(),
  model: google("gemini-2.5-flash-lite-preview-06-17"),
  tools: [
    devReasoningTools, // Add reasoning tools for development analysis
    ...mcpToolsService.getToolsForAgent(['git', 'github', 'docker'])
  ],
  hooks: createSubAgentHooks("Developer", "development and DevOps", {
    verbose: true, // Set to true for debugging development operations
    performance: true,
    analytics: true,
    logPrefix: "[VoltAgent:Dev]"
  }),
  // Memory for tracking development context and project state
  memory: memoryStorage,
  markdown: true,
  thinkingConfig: {
    thinkingBudget: 0,
    includeThoughts: false
  },
  structuredOutputs: true, // Enable structured outputs for better development planning and execution
  functionCalls: true, // Enable function calls for better development planning and execution
  dynamicRetrieval: {
    mode: 'MODE_DYNAMIC',
    dynamicThreshold: 0.8
  },
  useSearchGrounding: true,
});
</file>

<file path="voltagent/agents/memoryAgent.ts">
import { Agent, createPrompt, createReasoningTools } from "@voltagent/core";
import { VercelAIProvider } from "@voltagent/vercel-ai";
import { google } from "../config/googleProvider";
import { mcpToolsService } from "../services/mcp";
import { createSubAgentHooks } from "../services/hooks";
import { memoryStorage } from "../services/memory";
import { MemoryRetriever } from "../services/retriever";
// Create dynamic prompt for knowledge management
const knowledgePrompt = createPrompt({
  template: `You are a knowledge management and memory specialist. You can:
- Store and retrieve information using memory systems
- Organize knowledge into searchable formats
- Perform sequential thinking and reasoning tasks
- Connect related information across different sources
- Maintain context and conversation history
- Create knowledge graphs and relationships
- Summarize and extract key insights from information
- Help with decision-making through structured analysis
Current Context: {{context}}
Knowledge Domain: {{domain}}
Task Type: {{task_type}}
{{analysis_strategy}}
Always use 'think' to analyze information requests before proceeding. Use 'analyze' to evaluate retrieved knowledge and determine if additional context is needed.`,
  variables: {
    context: "General knowledge management",
    domain: "multi-domain",
    task_type: "information processing",
    analysis_strategy: "Focus on accuracy and helpful organization of information. Cross-reference multiple sources when available."
  }
});
// Create reasoning tools for knowledge analysis
const memoryReasoningTools = createReasoningTools({
  think: true,
  analyze: true,
  addInstructions: true,
  addFewShot: true
});
/**
 * Memory and Knowledge Agent
 * Handles information storage, retrieval, and knowledge management
 * Uses memory, sequential thinking, and knowledge management MCP tools
 */
export const memoryAgent = new Agent({
  name: "KnowledgeKeeper",
  purpose: "To store, retrieve, and manage information and knowledge.",
  description: "Specialized agent for memory, knowledge management, and information processing with structured reasoning",
  instructions: knowledgePrompt(),
  llm: new VercelAIProvider(),
  model: google("gemini-2.5-flash-lite-preview-06-17"),
  tools: [
      memoryReasoningTools, // Add reasoning tools for knowledge analysis
      ...mcpToolsService.getToolsForAgent(['memory'])
    ],  
  markdown: true,
  hooks: createSubAgentHooks("KnowledgeKeeper", "memory and knowledge management", {
    verbose: true, // Set to true for debugging memory operations
    performance: true,
    analytics: true,
    logPrefix: "[VoltAgent:Memory]"
  }),
  // Memory for conversation context and knowledge storage
  memory: memoryStorage,
  // Retriever for accessing stored knowledge and conversations
  thinkingConfig: {
    thinkingBudget: 0,
    includeThoughts: false
  },
  structuredOutputs: true // Enable structured outputs for better knowledge organization and retrieval
});
</file>

<file path="voltagent/agents/supervisorAgent.ts">
import { Agent, createPrompt, createReasoningTools } from "@voltagent/core";
import { VercelAIProvider } from "@voltagent/vercel-ai";
import { google } from "../config/googleProvider";
import { mathAgent } from "./mathAgent";
import { fileAgent } from "./fileAgent";
import { webAgent } from "./webAgent";
import { devAgent } from "./devAgent";
import { dataAgent } from "./dataAgent";
import { commsAgent } from "./commsAgent";
import { memoryAgent } from "./memoryAgent";
import { createSupervisorHooks } from "../services/hooks";
import { memoryStorage } from "../services/memory";
import { MemoryRetriever } from "../services/retriever";
/**
 * Static system prompt for supervisor agent to avoid runtime modifications.
 * This prompt is defined statically to ensure system messages are set only at the beginning of the conversation.
 */
const supervisorPrompt = createPrompt({
  template: `You are the main supervisor coordinating a team of specialized agents:
üßÆ **MathAssistant** - Mathematical calculations and problem-solving
üìÅ **FileManager** - File operations, cloud storage, document management  
üåê **WebResearcher** - Web browsing, search, online research
üë®‚Äçüíª **Developer** - Code development, Git, GitHub, Docker, DevOps
üìä **DataManager** - Database operations, SQL queries, data analysis
üí¨ **Communicator** - Slack messaging, team communication, notifications
üß† **KnowledgeKeeper** - Memory storage, information retrieval, knowledge management
Current Context: No specific context
Task Complexity: standard
Delegate tasks to the most appropriate specialist based on the user's request. You can use multiple agents for complex tasks that span different domains.
Always use the 'think' tool first to analyze requests and plan delegation. For complex multi-step tasks, use 'analyze' to evaluate intermediate results before proceeding.`,
  variables: {
    context: "No specific context",
    complexity: "standard",
    delegation_strategy: "Delegate tasks to the most appropriate specialist based on the user's request. You can use multiple agents for complex tasks that span different domains."
  }
});
// Create reasoning tools for structured thinking
// Create reasoning tools for structured thinking
const reasoningToolkit = createReasoningTools({
  think: true,
  analyze: true,
  addInstructions: true,
  addFewShot: false
});
/**
 * Supervisor Agent
 * Main orchestrator that delegates tasks to specialized sub-agents
 * Uses Gemini Flash Lite for fast coordination and delegation
 */
export const supervisorAgent = new Agent({
  name: "Supervisor",
  purpose: "To coordinate and delegate tasks to specialized sub-agents based on user requests, ensuring efficient and accurate completion of complex workflows.",
  description: "Master orchestrator for complex multi-agent workflows with structured reasoning",
  instructions: supervisorPrompt(),
  llm: new VercelAIProvider(),
  model: google("gemini-2.5-flash-lite-preview-06-17"),
  tools: [reasoningToolkit, /* delegate_task is automatically added when subAgents are defined */],
  subAgents: [
    mathAgent,
    fileAgent,
    webAgent,
    devAgent,
    dataAgent,
    commsAgent,
    memoryAgent
  ],
  markdown: true,
  hooks: createSupervisorHooks("Supervisor", {
    verbose: true, // Set to true for debugging delegation
    performance: true,
    analytics: true,
    logPrefix: "[VoltAgent:Supervisor]"
  }),
  memory: memoryStorage,
  retriever: new MemoryRetriever(memoryStorage, {
    toolName: "search_conversation_history",
    toolDescription: "Search across conversation history and stored knowledge"
  }),
  thinkingConfig: {
    thinkingBudget: 0,
    includeThoughts: false
  },
  structuredOutputs: true, // Enable structured outputs for better task delegation and coordination
  dynamicRetrieval: {
    mode: 'MODE_DYNAMIC',
    dynamicThreshold: 0.8
  },
  useSearchGrounding: true,
  functionCalls: true // Enable function calls for better task delegation and coordination
});
</file>

<file path="voltagent/agents/commsAgent.ts">
import { Agent, createPrompt, createReasoningTools } from "@voltagent/core";
import { VercelAIProvider } from "@voltagent/vercel-ai";
import { google } from "../config/googleProvider";
import { mcpToolsService } from "../services/mcp";
import { createSubAgentHooks } from "../services/hooks";
import { memoryStorage } from "../services/memory";
import { MemoryRetriever } from "../services/retriever";
// Create dynamic prompt for communication tasks
const commsPrompt = createPrompt({
  template: `You are a communication and collaboration specialist. You can:
- Send messages and notifications via Slack
- Manage team communications and updates
- Schedule and coordinate meetings and events
- Handle automated notifications and alerts
- Facilitate team collaboration and information sharing
- Monitor communication channels for important updates
- Create and manage communication workflows
- Integrate with team productivity tools
Communication Type: {{comm_type}}
Urgency Level: {{urgency}}
Audience: {{audience}}
{{communication_strategy}}
Always use 'think' to plan communications before sending them. Use 'analyze' to evaluate message effectiveness and team responses. Always be professional and considerate in communications.`,
  variables: {
    comm_type: "team collaboration",
    urgency: "standard",
    audience: "team members",
    communication_strategy: "Focus on clear, professional communication. Consider timing and audience appropriateness."
  }
});
// Create reasoning tools for communication analysis
const commsReasoningTools = createReasoningTools({
  think: true,
  analyze: true,
  addInstructions: true,
  addFewShot: true
});
/**
 * Communication Agent
 * Handles team communication, notifications, and collaboration tools
 * Uses Slack and other communication MCP tools
 */
export const commsAgent = new Agent({
  name: "Communicator",
  purpose: "To handle team communication, send notifications, and manage collaboration tasks.",
  description: "Specialized agent for team communication, notifications, and collaboration with structured reasoning",
  instructions: commsPrompt(),
  llm: new VercelAIProvider(),
  model: google("gemini-2.5-flash-lite-preview-06-17"),
  tools: [
    commsReasoningTools, // Add reasoning tools for communication analysis
  ],
  markdown: true,
  hooks: createSubAgentHooks("Communicator", "communication and collaboration", {
    verbose: true, // Set to true for debugging communications
    performance: true,
    analytics: true,
    logPrefix: "[VoltAgent:Comms]"
  }),
  // Memory for tracking communication history and contacts
  memory: memoryStorage,
  thinkingConfig: {
    thinkingBudget: 0,
    includeThoughts: false
  },
  structuredOutputs: true // Enable structured outputs for better communication planning and execution
});
</file>

<file path="voltagent/agents/dataAgent.ts">
import { Agent, createPrompt, createReasoningTools } from "@voltagent/core";
import { VercelAIProvider } from "@voltagent/vercel-ai";
import { google } from "../config/googleProvider";
import { mcpToolsService } from "../services/mcp";
import { createSubAgentHooks } from "../services/hooks";
import { memoryStorage } from "../services/memory";
import { MemoryRetriever } from "../services/retriever";
// Create dynamic prompt for data management tasks
const dataPrompt = createPrompt({
  template: `You are a data management specialist. You can:
- Execute SQL queries on PostgreSQL and SQLite databases
- Analyze data patterns, trends, and insights
- Perform data cleaning, transformation, and validation
- Create and manage database schemas and tables
- Generate reports and data visualizations
- Handle data import/export operations
- Optimize database performance and queries
- Ensure data integrity and security
Data Source: {{data_source}}
Query Type: {{query_type}}
Analysis Focus: {{analysis}}
{{data_strategy}}
Always use 'think' to plan database operations and queries before execution. Use 'analyze' to verify query results and data integrity. Always validate queries before execution and backup important data.`,
  variables: {
    data_source: "multiple databases",
    query_type: "analytical queries",
    analysis: "data insights and patterns",
    data_strategy: "Focus on data integrity and security. Always validate operations before execution."
  }
});
// Create reasoning tools for data analysis
const dataReasoningTools = createReasoningTools({
  think: true,
  analyze: true,
  addInstructions: true,
  addFewShot: true
});
/**
 * Data Management Agent
 * Handles database operations, data analysis, and data processing
 * Uses PostgreSQL, SQLite, and data processing MCP tools
 */
export const dataAgent = new Agent({
  name: "DataManager",
  purpose: "To manage and analyze data from various sources, including databases and files.",
  description: "Specialized agent for database operations, data analysis, and data processing with structured reasoning",
  instructions: dataPrompt(),
  llm: new VercelAIProvider(),
  model: google("gemini-2.5-flash-lite-preview-06-17"),
  tools: [
    dataReasoningTools, // Add reasoning tools for data analysis
    ...mcpToolsService.getToolsForAgent(['postgres', 'cloud'])
],  
  hooks: createSubAgentHooks("DataManager", "database and data operations", {
    verbose: true, // Set to true for debugging data operations
    performance: true,
    analytics: true,
    logPrefix: "[VoltAgent:Data]"
  }),
  // Memory for tracking data operations and query history
  memory: memoryStorage,
  markdown: true,
  thinkingConfig: {
    thinkingBudget: 0,
    includeThoughts: false
  },
  structuredOutputs: true // Enable structured outputs for better data management and analysis
});
</file>

<file path="voltagent/agents/fileAgent.ts">
import { Agent, createPrompt, createReasoningTools } from "@voltagent/core";
import { VercelAIProvider } from "@voltagent/vercel-ai";
import { google } from "../config/googleProvider";
import { mcpToolsService } from "../services/mcp";
import { createSubAgentHooks } from "../services/hooks";
import { memoryStorage } from "../services/memory";
import { MemoryRetriever } from "../services/retriever";
// Create dynamic prompt for file management tasks
const filePrompt = createPrompt({
  template: `You are a file management specialist. You can:
- Read, write, create, delete, and move files and directories
- Search and organize files across local and cloud storage
- Manage SQLite databases and file-based data
- Upload/download files to/from cloud services
- Handle document processing and file conversions
- Maintain file organization and cleanup
Current Task: {{task_type}}
File Operation: {{operation}}
Safety Level: {{safety}}
{{file_strategy}}
Always use 'think' to plan file operations before executing them. Use 'analyze' to verify results and ensure file integrity. Always be careful with file operations and confirm destructive actions.`,
  variables: {
    task_type: "file management",
    operation: "general file operations", 
    safety: "high - confirm destructive actions",
    file_strategy: "Focus on safe file operations. Always backup important data before modifications."
  }
});
// Create reasoning tools for file analysis
const fileReasoningTools = createReasoningTools({
  think: true,
  analyze: true,
  addInstructions: true,
  addFewShot: true
});
/**
 * File Management Agent
 * Handles all file operations, cloud storage, and document management
 * Uses filesystem, Google Drive, and SQLite MCP tools
 */
export const fileAgent = new Agent({
  name: "FileManager",
  purpose: "To manage files and directories, including reading, writing, and organizing data across local and cloud storage.",
  description: "Specialized agent for file operations, cloud storage, and document management with structured reasoning",
  instructions: filePrompt(),
  llm: new VercelAIProvider(),
  model: google("gemini-2.5-flash-lite-preview-06-17"),
  tools: [
      fileReasoningTools, // Add reasoning tools for file analysis
      ...mcpToolsService.getToolsForAgent(['filesystem', 'cloud'])
    ],  
  hooks: createSubAgentHooks("FileManager", "file operations and storage", {
    verbose: true, // Set to true for debugging file operations
    performance: true,
    analytics: true,
    logPrefix: "[VoltAgent:File]"
  }),
  markdown: true,
  // Memory for tracking file operations and states
  memory: memoryStorage,
  thinkingConfig: {
    thinkingBudget: 0,
    includeThoughts: false
  },
  structuredOutputs: true // Enable structured outputs for better file management and retrieval
});
</file>

<file path="voltagent/agents/webAgent.ts">
import { Agent, createPrompt, createReasoningTools } from "@voltagent/core";
import { VercelAIProvider } from "@voltagent/vercel-ai";
import { google } from "../config/googleProvider";
import { mcpToolsService } from "../services/mcp";
import { createSubAgentHooks } from "../services/hooks";
import { memoryStorage } from "../services/memory";
import { MemoryRetriever } from "../services/retriever";
// Create dynamic prompt for web research
const researchPrompt = createPrompt({
  template: `You are a web research specialist. You can:
- Search the web using Brave Search for current information
- Browse websites and extract specific information
- Take screenshots of web pages for visual analysis
- Scrape and parse web content intelligently
- Conduct competitive research and market analysis
- Gather news, trends, and real-time information
- Store and recall research findings using memory tools
Research Focus: {{focus}}
Information Type: {{info_type}}
Quality Level: {{quality}}
{{research_strategy}}
Always use 'think' to plan your research approach before searching. Use 'analyze' to evaluate search results and determine if additional research is needed. Always respect robots.txt and website terms of service.`,
  variables: {
    focus: "comprehensive research",
    info_type: "factual and current",
    quality: "high-quality sources",
    research_strategy: "Focus on public information from reliable sources. Cross-reference information when possible."
  }
});
// Create reasoning tools for research analysis
const researchReasoningTools = createReasoningTools({
  think: true,
  analyze: true,
  addInstructions: true,
  addFewShot: true
});
/**
 * Web Research Agent
 * Handles web browsing, search, data extraction, and online research
 * Uses browser automation, web search, and memory MCP tools
 */
export const webAgent = new Agent({
  name: "WebResearcher",
  purpose: "To conduct web research, browse websites, and extract online information.",
  description: "Specialized agent for web research, browsing, and online data extraction with structured analysis",
  instructions: researchPrompt(),
  llm: new VercelAIProvider(),
  model: google("gemini-2.5-flash-lite-preview-06-17"),
  tools: [
    researchReasoningTools, // Add reasoning tools for research analysis
    ...mcpToolsService.getToolsForAgent(['web_search', 'browser'])
  ],  
  hooks: createSubAgentHooks("WebResearcher", "web research and browsing", {
    verbose: true, // Set to true for debugging web operations
    performance: true,
    analytics: true,
    logPrefix: "[VoltAgent:Web]"
  }),  // Memory for maintaining research context and findings
  memory: memoryStorage,
  markdown: true,
  thinkingConfig: {
    thinkingBudget: 0,
    includeThoughts: false
  },
  structuredOutputs: true, // Enable structured outputs for better research findings and summaries
  dynamicRetrieval: {
    mode: 'MODE_DYNAMIC',
    dynamicThreshold: 0.8
  },
  useSearchGrounding: true,
});
</file>

</files>
